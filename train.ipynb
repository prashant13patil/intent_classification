{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as data was not having labels created own dataset with provided datapoints.\n",
    "#As the is to predict intent, so only taken messages column from provided data in consideration.\n",
    "#manually labeled targets\n",
    "#as manual labeling will take too much time labeled only for few data points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.ExcelFile(\"Book1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sheet1', 'Sheet2']\n"
     ]
    }
   ],
   "source": [
    "print(data.sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Message   intent\n",
      "0        Youre about to GET LUCKY! Rise and shine. HAP...      NaN\n",
      "1        Rest up, tomorrows a BIG DAY.\\r\\n You&#039;re...  neutral\n",
      "2        Start PRESSING with FORWARD moving people!\\r\\...      NaN\n",
      "3                                                     NaN      NaN\n",
      "4        You have a habit of waking up every morning t...  neutral\n",
      "...                                                   ...      ...\n",
      "203674                           i want sell this page .    seller\n",
      "203675   Hello Guys !!!\\n I want to Buy Fresh US Email...    buyer\n",
      "203676       Anybody with good cc inbox me I want to buy     buyer\n",
      "203677   American diamond Rings , Price on Pics , Best...   seller\n",
      "203678   Do you want to buy Organic Dry Fruits for the...    buyer\n",
      "\n",
      "[203679 rows x 2 columns]\n",
      "                                              Message            intent\n",
      "0    Making Money Online may not be easy, but its ...           neutral\n",
      "1    For some this is UUUUGELY difficult, but very...           neutral\n",
      "2     Bitcoin is changing the world. Resistance is...           neutral\n",
      "3    Open plots for sales at shamshabad  FREE SITE...            seller\n",
      "4    I am selling a very good plot with the total ...            seller\n",
      "5    I am selling a very good plot with the total ...            seller\n",
      "6    Preparing ginger water is the easiest thing t...           neutral\n",
      "7    Product Name : Collar neck t-shirts(TV2)\\n  P...            seller\n",
      "8     hi guys  i want to buy skins cs go or accoun...             buyer\n",
      "9              i want to buy a knife fair trade only              buyer\n",
      "10   I have a buyer who want to buy my domain my d...             buyer\n",
      "11   who want to buy cvd or hpht diamonds please c...            seller\n",
      "12   Please like and follow and get the latest upd...           neutral\n",
      "13   I want to buy a fresh Non-Hosted Indian adsen...             buyer\n",
      "14   Kya koi company sunday ke din interview leti h?            neutral\n",
      "15   Need Whatsapp marketing software.. If you wan...            seller\n",
      "16  Top Mobiles 99 - Best Mobiles available in Ind...            seller\n",
      "17   Buy like a BULL, Sit like a BEAR, Watch like ...  buyer and seller\n",
      "18   42K Profit Booked in Lupin Intraday today &lt...  buyer and seller\n",
      "19   Who wants to buy or sell CBD Oil products wit...  buyer and seller\n",
      "20  Coinbase - Buy Bitcoin &amp; more. Secure Wall...  buyer and seller\n",
      "21   Let's welcome our new members: Vetri Selvan M...           neutral\n",
      "22  Feedbuzz  Children Fishing Funny Moments ! Fol...           neutral\n",
      "23   I want to sell my products on amazon, flipkar...            seller\n",
      "24                           i want sell this page .             seller\n",
      "25   Hello Guys !!!\\n I want to Buy Fresh US Email...             buyer\n",
      "26       Anybody with good cc inbox me I want to buy              buyer\n",
      "27   American diamond Rings , Price on Pics , Best...            seller\n",
      "28   Do you want to buy Organic Dry Fruits for the...             buyer\n"
     ]
    }
   ],
   "source": [
    "df = data.parse('Sheet1') \n",
    "test_df= data.parse('Sheet2')\n",
    "print(df)\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Message  intent\n",
      "count   195185     203\n",
      "unique  161398       4\n",
      "top             seller\n",
      "freq      7469      86\n",
      "                                                  Message  intent\n",
      "count                                                  29      29\n",
      "unique                                                 28       4\n",
      "top      I am selling a very good plot with the total ...  seller\n",
      "freq                                                    2      10\n"
     ]
    }
   ],
   "source": [
    "print(df.describe())\n",
    "print(test_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message      8494\n",
      "intent     203476\n",
      "dtype: int64\n",
      "Message    0\n",
      "intent     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check for null\n",
    "print(df.isnull().sum())\n",
    "print(test_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop if any\n",
    "df = df.dropna() \n",
    "  \n",
    "# To reset the indices  \n",
    "df = df.reset_index(drop = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Rest up, tomorrows a BIG DAY.\\r\\n You&#039;re...\n",
       "1       You have a habit of waking up every morning t...\n",
       "2       RIPE for the picking and GREAT for your PORTF...\n",
       "3       Merry Morning and Happy Wednesday Winners!!\\r...\n",
       "4       Clebrating with great team members and leader...\n",
       "                             ...                        \n",
       "198                             i want sell this page . \n",
       "199     Hello Guys !!!\\n I want to Buy Fresh US Email...\n",
       "200         Anybody with good cc inbox me I want to buy \n",
       "201     American diamond Rings , Price on Pics , Best...\n",
       "202     Do you want to buy Organic Dry Fruits for the...\n",
       "Name: Message, Length: 203, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Message\n",
      "intent                   \n",
      "buyer                  62\n",
      "buyer and seller       12\n",
      "neutral                43\n",
      "seller                 86\n",
      "                  Message\n",
      "intent                   \n",
      "buyer                   7\n",
      "buyer and seller        4\n",
      "neutral                 8\n",
      "seller                 10\n"
     ]
    }
   ],
   "source": [
    "#check for target frequency for each class\n",
    "print(df.groupby(\"intent\").count())\n",
    "print(test_df.groupby(\"intent\").count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22e67c7d948>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#density plot \n",
    "fig,ax = plt.subplots(1,1, figsize=(5,5))\n",
    "sns.countplot(x= df['intent'],hue='intent', data=df,ax = ax)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22e70a3d5c8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(1,1, figsize=(5,5))\n",
    "sns.countplot(x= test_df['intent'],hue='intent', data=test_df,ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message    202\n",
      "intent       4\n",
      "dtype: int64\n",
      "Message    28\n",
      "intent      4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Checks number of unique rows & columns\n",
    "print(df.nunique())\n",
    "print(test_df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove digits\n",
    "df['Message'] =df['Message'].str.replace('\\d+', '')\n",
    "test_df['Message'] =test_df['Message'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data cleaning\n",
    "#removing all newlines, spaces, special chars etc..\n",
    "punc = '''!()-[]{};:`+=-)˝˙ˇ ˜˚˚'\"\\/,<>/?#$%^&* .._~\\n\\r'''\n",
    "\n",
    "for i in range(len(df)):\n",
    "    for ele in df['Message'][i]:\n",
    "        ele.join(re.sub(r'\\b\\d+\\b','', ele))\n",
    "        #df['sent'][i] = ''.join([i for i in ele.split() if not i.isdigit()])\n",
    "        df['Message'][i] = df['Message'][i].lower()\n",
    "        if ele in punc:\n",
    "            df['Message'][i] = df['Message'][i].replace(ele, \" \")\n",
    "            df['Message'][i] = df['Message'][i].replace(\"  \", \" \")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "punc = '''!()-[]{};:`+=-)˝˙ˇ ˜˚˚'\"\\/,<>/?#$%^&* .._~\\n\\r'''\n",
    "\n",
    "for i in range(len(test_df)):\n",
    "    for ele in test_df['Message'][i]:\n",
    "        ele.join(re.sub(r'\\b\\d+\\b','', ele))\n",
    "        test_df['Message'][i] = test_df['Message'][i].lower()\n",
    "        if ele in punc:\n",
    "            test_df['Message'][i] = test_df['Message'][i].replace(ele, \" \")\n",
    "            test_df['Message'][i] = test_df['Message'][i].replace(\"  \", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text to lower case\n",
    "df[\"Message\"]= df.Message.map(lambda x: x.lower())\n",
    "test_df[\"Message\"]= test_df.Message.map(lambda x: x.lower())\n",
    "\n",
    "data1=df\n",
    "test_data = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['buyer', 'buyer and seller', 'neutral', 'seller'], dtype=object)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encoding for target labels\n",
    "from sklearn.preprocessing import OneHotEncoder as OHE\n",
    "\n",
    "y_encoder= OHE().fit(np.array(df.intent).reshape(-1,1))\n",
    "y_encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "ytr_encoded= y_encoder.transform(np.array(df.intent).reshape(-1,1)).toarray()\n",
    "yts_encoded= y_encoder.transform(np.array(test_df.intent).reshape(-1,1)).toarray()\n",
    "\n",
    "print(yts_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\PatilPra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding new column \"lower_text\" with lower case text\n",
    "df[\"lower_text\"]= df.Message.map(lambda x: x.lower())\n",
    "test_df[\"lower_text\"]= test_df.Message.map(lambda x: x.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding new column \"tokenized\" with tokens.\n",
    "df[\"tokenized\"]= df.lower_text.map(word_tokenize)\n",
    "test_df[\"tokenized\"]= test_df.lower_text.map(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing stop words\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "def remove_stop(strings, stop_list):\n",
    "    classed= [s for s in strings if s not in stop_list]\n",
    "    return classed\n",
    "\n",
    "stop= stopwords.words(\"english\")\n",
    "stop_punc= list(set(punctuation))+ stop\n",
    "\n",
    "df[\"selected\"] = df.tokenized.map(lambda df: remove_stop(df, stop_punc))\n",
    "test_df[\"selected\"] = test_df.tokenized.map(lambda test_df: remove_stop(test_df, stop_punc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "      <th>intent</th>\n",
       "      <th>lower_text</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>selected</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>making money online may not be easy but its n...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>making money online may not be easy but its n...</td>\n",
       "      <td>[making, money, online, may, not, be, easy, bu...</td>\n",
       "      <td>[making, money, online, may, easy, hard, eithe...</td>\n",
       "      <td>[make, money, onlin, may, easi, hard, either, ...</td>\n",
       "      <td>make money onlin may easi hard either discov s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for some this is uuuugely difficult but very ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>for some this is uuuugely difficult but very ...</td>\n",
       "      <td>[for, some, this, is, uuuugely, difficult, but...</td>\n",
       "      <td>[uuuugely, difficult, important, get, want, li...</td>\n",
       "      <td>[uuuug, difficult, import, get, want, life, ke...</td>\n",
       "      <td>uuuug difficult import get want life keep keep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bitcoin is changing the world resistance is f...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>bitcoin is changing the world resistance is f...</td>\n",
       "      <td>[bitcoin, is, changing, the, world, resistance...</td>\n",
       "      <td>[bitcoin, changing, world, resistance, futile,...</td>\n",
       "      <td>[bitcoin, chang, world, resist, futil, free, t...</td>\n",
       "      <td>bitcoin chang world resist futil free train am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>open plots for sales at shamshabad free site ...</td>\n",
       "      <td>seller</td>\n",
       "      <td>open plots for sales at shamshabad free site ...</td>\n",
       "      <td>[open, plots, for, sales, at, shamshabad, free...</td>\n",
       "      <td>[open, plots, sales, shamshabad, free, site, v...</td>\n",
       "      <td>[open, plot, sale, shamshabad, free, site, vis...</td>\n",
       "      <td>open plot sale shamshabad free site visit ac c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am selling a very good plot with the total ...</td>\n",
       "      <td>seller</td>\n",
       "      <td>i am selling a very good plot with the total ...</td>\n",
       "      <td>[i, am, selling, a, very, good, plot, with, th...</td>\n",
       "      <td>[selling, good, plot, total, area, sqft, akbar...</td>\n",
       "      <td>[sell, good, plot, total, area, sqft, akbar, p...</td>\n",
       "      <td>sell good plot total area sqft akbar pura area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i am selling a very good plot with the total ...</td>\n",
       "      <td>seller</td>\n",
       "      <td>i am selling a very good plot with the total ...</td>\n",
       "      <td>[i, am, selling, a, very, good, plot, with, th...</td>\n",
       "      <td>[selling, good, plot, total, area, sqft, akbar...</td>\n",
       "      <td>[sell, good, plot, total, area, sqft, akbar, p...</td>\n",
       "      <td>sell good plot total area sqft akbar pura area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>preparing ginger water is the easiest thing t...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>preparing ginger water is the easiest thing t...</td>\n",
       "      <td>[preparing, ginger, water, is, the, easiest, t...</td>\n",
       "      <td>[preparing, ginger, water, easiest, thing, hom...</td>\n",
       "      <td>[prepar, ginger, water, easiest, thing, home, ...</td>\n",
       "      <td>prepar ginger water easiest thing home excel r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>product name collar neck t shirts tv product ...</td>\n",
       "      <td>seller</td>\n",
       "      <td>product name collar neck t shirts tv product ...</td>\n",
       "      <td>[product, name, collar, neck, t, shirts, tv, p...</td>\n",
       "      <td>[product, name, collar, neck, shirts, tv, prod...</td>\n",
       "      <td>[product, name, collar, neck, shirt, tv, produ...</td>\n",
       "      <td>product name collar neck shirt tv product deta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hi guys i want to buy skins cs go or account ...</td>\n",
       "      <td>buyer</td>\n",
       "      <td>hi guys i want to buy skins cs go or account ...</td>\n",
       "      <td>[hi, guys, i, want, to, buy, skins, cs, go, or...</td>\n",
       "      <td>[hi, guys, want, buy, skins, cs, go, account, ...</td>\n",
       "      <td>[hi, guy, want, buy, skin, cs, go, account, cs...</td>\n",
       "      <td>hi guy want buy skin cs go account cs go go fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i want to buy a knife fair trade only</td>\n",
       "      <td>buyer</td>\n",
       "      <td>i want to buy a knife fair trade only</td>\n",
       "      <td>[i, want, to, buy, a, knife, fair, trade, only]</td>\n",
       "      <td>[want, buy, knife, fair, trade]</td>\n",
       "      <td>[want, buy, knife, fair, trade]</td>\n",
       "      <td>want buy knife fair trade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>i have a buyer who want to buy my domain my d...</td>\n",
       "      <td>buyer</td>\n",
       "      <td>i have a buyer who want to buy my domain my d...</td>\n",
       "      <td>[i, have, a, buyer, who, want, to, buy, my, do...</td>\n",
       "      <td>[buyer, want, buy, domain, domain, registered,...</td>\n",
       "      <td>[buyer, want, buy, domain, domain, regist, god...</td>\n",
       "      <td>buyer want buy domain domain regist godaddi ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>who want to buy cvd or hpht diamonds please c...</td>\n",
       "      <td>seller</td>\n",
       "      <td>who want to buy cvd or hpht diamonds please c...</td>\n",
       "      <td>[who, want, to, buy, cvd, or, hpht, diamonds, ...</td>\n",
       "      <td>[want, buy, cvd, hpht, diamonds, please, call]</td>\n",
       "      <td>[want, buy, cvd, hpht, diamond, pleas, call]</td>\n",
       "      <td>want buy cvd hpht diamond pleas call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>please like and follow and get the latest upd...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>please like and follow and get the latest upd...</td>\n",
       "      <td>[please, like, and, follow, and, get, the, lat...</td>\n",
       "      <td>[please, like, follow, get, latest, updates, v...</td>\n",
       "      <td>[pleas, like, follow, get, latest, updat, visi...</td>\n",
       "      <td>pleas like follow get latest updat vision miss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>i want to buy a fresh non hosted indian adsen...</td>\n",
       "      <td>buyer</td>\n",
       "      <td>i want to buy a fresh non hosted indian adsen...</td>\n",
       "      <td>[i, want, to, buy, a, fresh, non, hosted, indi...</td>\n",
       "      <td>[want, buy, fresh, non, hosted, indian, adsens...</td>\n",
       "      <td>[want, buy, fresh, non, host, indian, adsens, ...</td>\n",
       "      <td>want buy fresh non host indian adsens account ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>kya koi company sunday ke din interview leti h</td>\n",
       "      <td>neutral</td>\n",
       "      <td>kya koi company sunday ke din interview leti h</td>\n",
       "      <td>[kya, koi, company, sunday, ke, din, interview...</td>\n",
       "      <td>[kya, koi, company, sunday, ke, din, interview...</td>\n",
       "      <td>[kya, koi, compani, sunday, ke, din, interview...</td>\n",
       "      <td>kya koi compani sunday ke din interview leti h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>need whatsapp marketing software if you want ...</td>\n",
       "      <td>seller</td>\n",
       "      <td>need whatsapp marketing software if you want ...</td>\n",
       "      <td>[need, whatsapp, marketing, software, if, you,...</td>\n",
       "      <td>[need, whatsapp, marketing, software, want, se...</td>\n",
       "      <td>[need, whatsapp, market, softwar, want, sell, ...</td>\n",
       "      <td>need whatsapp market softwar want sell call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>top mobiles best mobiles available in india i ...</td>\n",
       "      <td>seller</td>\n",
       "      <td>top mobiles best mobiles available in india i ...</td>\n",
       "      <td>[top, mobiles, best, mobiles, available, in, i...</td>\n",
       "      <td>[top, mobiles, best, mobiles, available, india...</td>\n",
       "      <td>[top, mobil, best, mobil, avail, india, want, ...</td>\n",
       "      <td>top mobil best mobil avail india want sell ama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>buy like a bull sit like a bear watch like an...</td>\n",
       "      <td>buyer and seller</td>\n",
       "      <td>buy like a bull sit like a bear watch like an...</td>\n",
       "      <td>[buy, like, a, bull, sit, like, a, bear, watch...</td>\n",
       "      <td>[buy, like, bull, sit, like, bear, watch, like...</td>\n",
       "      <td>[buy, like, bull, sit, like, bear, watch, like...</td>\n",
       "      <td>buy like bull sit like bear watch like eagl in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>k profit booked in lupin intraday today lt</td>\n",
       "      <td>buyer and seller</td>\n",
       "      <td>k profit booked in lupin intraday today lt</td>\n",
       "      <td>[k, profit, booked, in, lupin, intraday, today...</td>\n",
       "      <td>[k, profit, booked, lupin, intraday, today, lt]</td>\n",
       "      <td>[k, profit, book, lupin, intraday, today, lt]</td>\n",
       "      <td>k profit book lupin intraday today lt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>who wants to buy or sell cbd oil products wit...</td>\n",
       "      <td>buyer and seller</td>\n",
       "      <td>who wants to buy or sell cbd oil products wit...</td>\n",
       "      <td>[who, wants, to, buy, or, sell, cbd, oil, prod...</td>\n",
       "      <td>[wants, buy, sell, cbd, oil, products, awesome...</td>\n",
       "      <td>[want, buy, sell, cbd, oil, product, awesom, c...</td>\n",
       "      <td>want buy sell cbd oil product awesom compani f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>coinbase buy bitcoin amp more secure wallet i ...</td>\n",
       "      <td>buyer and seller</td>\n",
       "      <td>coinbase buy bitcoin amp more secure wallet i ...</td>\n",
       "      <td>[coinbase, buy, bitcoin, amp, more, secure, wa...</td>\n",
       "      <td>[coinbase, buy, bitcoin, amp, secure, wallet, ...</td>\n",
       "      <td>[coinbas, buy, bitcoin, amp, secur, wallet, bu...</td>\n",
       "      <td>coinbas buy bitcoin amp secur wallet buy sell ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>let s welcome our new members vetri selvan m ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>let s welcome our new members vetri selvan m ...</td>\n",
       "      <td>[let, s, welcome, our, new, members, vetri, se...</td>\n",
       "      <td>[let, welcome, new, members, vetri, selvan, sa...</td>\n",
       "      <td>[let, welcom, new, member, vetri, selvan, sath...</td>\n",
       "      <td>let welcom new member vetri selvan sathi abhim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>feedbuzz children fishing funny moments follow...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>feedbuzz children fishing funny moments follow...</td>\n",
       "      <td>[feedbuzz, children, fishing, funny, moments, ...</td>\n",
       "      <td>[feedbuzz, children, fishing, funny, moments, ...</td>\n",
       "      <td>[feedbuzz, children, fish, funni, moment, foll...</td>\n",
       "      <td>feedbuzz children fish funni moment follow fore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>i want to sell my products on amazon flipkart...</td>\n",
       "      <td>seller</td>\n",
       "      <td>i want to sell my products on amazon flipkart...</td>\n",
       "      <td>[i, want, to, sell, my, products, on, amazon, ...</td>\n",
       "      <td>[want, sell, products, amazon, flipkart, gst, ...</td>\n",
       "      <td>[want, sell, product, amazon, flipkart, gst, h...</td>\n",
       "      <td>want sell product amazon flipkart gst help sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>i want sell this page</td>\n",
       "      <td>seller</td>\n",
       "      <td>i want sell this page</td>\n",
       "      <td>[i, want, sell, this, page]</td>\n",
       "      <td>[want, sell, page]</td>\n",
       "      <td>[want, sell, page]</td>\n",
       "      <td>want sell page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>hello guys i want to buy fresh us email traff...</td>\n",
       "      <td>buyer</td>\n",
       "      <td>hello guys i want to buy fresh us email traff...</td>\n",
       "      <td>[hello, guys, i, want, to, buy, fresh, us, ema...</td>\n",
       "      <td>[hello, guys, want, buy, fresh, us, email, tra...</td>\n",
       "      <td>[hello, guy, want, buy, fresh, us, email, traf...</td>\n",
       "      <td>hello guy want buy fresh us email traffic affi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>anybody with good cc inbox me i want to buy</td>\n",
       "      <td>buyer</td>\n",
       "      <td>anybody with good cc inbox me i want to buy</td>\n",
       "      <td>[anybody, with, good, cc, inbox, me, i, want, ...</td>\n",
       "      <td>[anybody, good, cc, inbox, want, buy]</td>\n",
       "      <td>[anybodi, good, cc, inbox, want, buy]</td>\n",
       "      <td>anybodi good cc inbox want buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>american diamond rings price on pics best qua...</td>\n",
       "      <td>seller</td>\n",
       "      <td>american diamond rings price on pics best qua...</td>\n",
       "      <td>[american, diamond, rings, price, on, pics, be...</td>\n",
       "      <td>[american, diamond, rings, price, pics, best, ...</td>\n",
       "      <td>[american, diamond, ring, price, pic, best, qu...</td>\n",
       "      <td>american diamond ring price pic best qualiti w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>do you want to buy organic dry fruits for the...</td>\n",
       "      <td>buyer</td>\n",
       "      <td>do you want to buy organic dry fruits for the...</td>\n",
       "      <td>[do, you, want, to, buy, organic, dry, fruits,...</td>\n",
       "      <td>[want, buy, organic, dry, fruits, cheapest, pr...</td>\n",
       "      <td>[want, buy, organ, dri, fruit, cheapest, price...</td>\n",
       "      <td>want buy organ dri fruit cheapest price love e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Message            intent  \\\n",
       "0    making money online may not be easy but its n...           neutral   \n",
       "1    for some this is uuuugely difficult but very ...           neutral   \n",
       "2    bitcoin is changing the world resistance is f...           neutral   \n",
       "3    open plots for sales at shamshabad free site ...            seller   \n",
       "4    i am selling a very good plot with the total ...            seller   \n",
       "5    i am selling a very good plot with the total ...            seller   \n",
       "6    preparing ginger water is the easiest thing t...           neutral   \n",
       "7    product name collar neck t shirts tv product ...            seller   \n",
       "8    hi guys i want to buy skins cs go or account ...             buyer   \n",
       "9              i want to buy a knife fair trade only              buyer   \n",
       "10   i have a buyer who want to buy my domain my d...             buyer   \n",
       "11   who want to buy cvd or hpht diamonds please c...            seller   \n",
       "12   please like and follow and get the latest upd...           neutral   \n",
       "13   i want to buy a fresh non hosted indian adsen...             buyer   \n",
       "14    kya koi company sunday ke din interview leti h            neutral   \n",
       "15   need whatsapp marketing software if you want ...            seller   \n",
       "16  top mobiles best mobiles available in india i ...            seller   \n",
       "17   buy like a bull sit like a bear watch like an...  buyer and seller   \n",
       "18        k profit booked in lupin intraday today lt   buyer and seller   \n",
       "19   who wants to buy or sell cbd oil products wit...  buyer and seller   \n",
       "20  coinbase buy bitcoin amp more secure wallet i ...  buyer and seller   \n",
       "21   let s welcome our new members vetri selvan m ...           neutral   \n",
       "22  feedbuzz children fishing funny moments follow...           neutral   \n",
       "23   i want to sell my products on amazon flipkart...            seller   \n",
       "24                             i want sell this page             seller   \n",
       "25   hello guys i want to buy fresh us email traff...             buyer   \n",
       "26       anybody with good cc inbox me i want to buy              buyer   \n",
       "27   american diamond rings price on pics best qua...            seller   \n",
       "28   do you want to buy organic dry fruits for the...             buyer   \n",
       "\n",
       "                                           lower_text  \\\n",
       "0    making money online may not be easy but its n...   \n",
       "1    for some this is uuuugely difficult but very ...   \n",
       "2    bitcoin is changing the world resistance is f...   \n",
       "3    open plots for sales at shamshabad free site ...   \n",
       "4    i am selling a very good plot with the total ...   \n",
       "5    i am selling a very good plot with the total ...   \n",
       "6    preparing ginger water is the easiest thing t...   \n",
       "7    product name collar neck t shirts tv product ...   \n",
       "8    hi guys i want to buy skins cs go or account ...   \n",
       "9              i want to buy a knife fair trade only    \n",
       "10   i have a buyer who want to buy my domain my d...   \n",
       "11   who want to buy cvd or hpht diamonds please c...   \n",
       "12   please like and follow and get the latest upd...   \n",
       "13   i want to buy a fresh non hosted indian adsen...   \n",
       "14    kya koi company sunday ke din interview leti h    \n",
       "15   need whatsapp marketing software if you want ...   \n",
       "16  top mobiles best mobiles available in india i ...   \n",
       "17   buy like a bull sit like a bear watch like an...   \n",
       "18        k profit booked in lupin intraday today lt    \n",
       "19   who wants to buy or sell cbd oil products wit...   \n",
       "20  coinbase buy bitcoin amp more secure wallet i ...   \n",
       "21   let s welcome our new members vetri selvan m ...   \n",
       "22  feedbuzz children fishing funny moments follow...   \n",
       "23   i want to sell my products on amazon flipkart...   \n",
       "24                             i want sell this page    \n",
       "25   hello guys i want to buy fresh us email traff...   \n",
       "26       anybody with good cc inbox me i want to buy    \n",
       "27   american diamond rings price on pics best qua...   \n",
       "28   do you want to buy organic dry fruits for the...   \n",
       "\n",
       "                                            tokenized  \\\n",
       "0   [making, money, online, may, not, be, easy, bu...   \n",
       "1   [for, some, this, is, uuuugely, difficult, but...   \n",
       "2   [bitcoin, is, changing, the, world, resistance...   \n",
       "3   [open, plots, for, sales, at, shamshabad, free...   \n",
       "4   [i, am, selling, a, very, good, plot, with, th...   \n",
       "5   [i, am, selling, a, very, good, plot, with, th...   \n",
       "6   [preparing, ginger, water, is, the, easiest, t...   \n",
       "7   [product, name, collar, neck, t, shirts, tv, p...   \n",
       "8   [hi, guys, i, want, to, buy, skins, cs, go, or...   \n",
       "9     [i, want, to, buy, a, knife, fair, trade, only]   \n",
       "10  [i, have, a, buyer, who, want, to, buy, my, do...   \n",
       "11  [who, want, to, buy, cvd, or, hpht, diamonds, ...   \n",
       "12  [please, like, and, follow, and, get, the, lat...   \n",
       "13  [i, want, to, buy, a, fresh, non, hosted, indi...   \n",
       "14  [kya, koi, company, sunday, ke, din, interview...   \n",
       "15  [need, whatsapp, marketing, software, if, you,...   \n",
       "16  [top, mobiles, best, mobiles, available, in, i...   \n",
       "17  [buy, like, a, bull, sit, like, a, bear, watch...   \n",
       "18  [k, profit, booked, in, lupin, intraday, today...   \n",
       "19  [who, wants, to, buy, or, sell, cbd, oil, prod...   \n",
       "20  [coinbase, buy, bitcoin, amp, more, secure, wa...   \n",
       "21  [let, s, welcome, our, new, members, vetri, se...   \n",
       "22  [feedbuzz, children, fishing, funny, moments, ...   \n",
       "23  [i, want, to, sell, my, products, on, amazon, ...   \n",
       "24                        [i, want, sell, this, page]   \n",
       "25  [hello, guys, i, want, to, buy, fresh, us, ema...   \n",
       "26  [anybody, with, good, cc, inbox, me, i, want, ...   \n",
       "27  [american, diamond, rings, price, on, pics, be...   \n",
       "28  [do, you, want, to, buy, organic, dry, fruits,...   \n",
       "\n",
       "                                             selected  \\\n",
       "0   [making, money, online, may, easy, hard, eithe...   \n",
       "1   [uuuugely, difficult, important, get, want, li...   \n",
       "2   [bitcoin, changing, world, resistance, futile,...   \n",
       "3   [open, plots, sales, shamshabad, free, site, v...   \n",
       "4   [selling, good, plot, total, area, sqft, akbar...   \n",
       "5   [selling, good, plot, total, area, sqft, akbar...   \n",
       "6   [preparing, ginger, water, easiest, thing, hom...   \n",
       "7   [product, name, collar, neck, shirts, tv, prod...   \n",
       "8   [hi, guys, want, buy, skins, cs, go, account, ...   \n",
       "9                     [want, buy, knife, fair, trade]   \n",
       "10  [buyer, want, buy, domain, domain, registered,...   \n",
       "11     [want, buy, cvd, hpht, diamonds, please, call]   \n",
       "12  [please, like, follow, get, latest, updates, v...   \n",
       "13  [want, buy, fresh, non, hosted, indian, adsens...   \n",
       "14  [kya, koi, company, sunday, ke, din, interview...   \n",
       "15  [need, whatsapp, marketing, software, want, se...   \n",
       "16  [top, mobiles, best, mobiles, available, india...   \n",
       "17  [buy, like, bull, sit, like, bear, watch, like...   \n",
       "18    [k, profit, booked, lupin, intraday, today, lt]   \n",
       "19  [wants, buy, sell, cbd, oil, products, awesome...   \n",
       "20  [coinbase, buy, bitcoin, amp, secure, wallet, ...   \n",
       "21  [let, welcome, new, members, vetri, selvan, sa...   \n",
       "22  [feedbuzz, children, fishing, funny, moments, ...   \n",
       "23  [want, sell, products, amazon, flipkart, gst, ...   \n",
       "24                                 [want, sell, page]   \n",
       "25  [hello, guys, want, buy, fresh, us, email, tra...   \n",
       "26              [anybody, good, cc, inbox, want, buy]   \n",
       "27  [american, diamond, rings, price, pics, best, ...   \n",
       "28  [want, buy, organic, dry, fruits, cheapest, pr...   \n",
       "\n",
       "                                              stemmed  \\\n",
       "0   [make, money, onlin, may, easi, hard, either, ...   \n",
       "1   [uuuug, difficult, import, get, want, life, ke...   \n",
       "2   [bitcoin, chang, world, resist, futil, free, t...   \n",
       "3   [open, plot, sale, shamshabad, free, site, vis...   \n",
       "4   [sell, good, plot, total, area, sqft, akbar, p...   \n",
       "5   [sell, good, plot, total, area, sqft, akbar, p...   \n",
       "6   [prepar, ginger, water, easiest, thing, home, ...   \n",
       "7   [product, name, collar, neck, shirt, tv, produ...   \n",
       "8   [hi, guy, want, buy, skin, cs, go, account, cs...   \n",
       "9                     [want, buy, knife, fair, trade]   \n",
       "10  [buyer, want, buy, domain, domain, regist, god...   \n",
       "11       [want, buy, cvd, hpht, diamond, pleas, call]   \n",
       "12  [pleas, like, follow, get, latest, updat, visi...   \n",
       "13  [want, buy, fresh, non, host, indian, adsens, ...   \n",
       "14  [kya, koi, compani, sunday, ke, din, interview...   \n",
       "15  [need, whatsapp, market, softwar, want, sell, ...   \n",
       "16  [top, mobil, best, mobil, avail, india, want, ...   \n",
       "17  [buy, like, bull, sit, like, bear, watch, like...   \n",
       "18      [k, profit, book, lupin, intraday, today, lt]   \n",
       "19  [want, buy, sell, cbd, oil, product, awesom, c...   \n",
       "20  [coinbas, buy, bitcoin, amp, secur, wallet, bu...   \n",
       "21  [let, welcom, new, member, vetri, selvan, sath...   \n",
       "22  [feedbuzz, children, fish, funni, moment, foll...   \n",
       "23  [want, sell, product, amazon, flipkart, gst, h...   \n",
       "24                                 [want, sell, page]   \n",
       "25  [hello, guy, want, buy, fresh, us, email, traf...   \n",
       "26              [anybodi, good, cc, inbox, want, buy]   \n",
       "27  [american, diamond, ring, price, pic, best, qu...   \n",
       "28  [want, buy, organ, dri, fruit, cheapest, price...   \n",
       "\n",
       "                                           normalized  \n",
       "0   make money onlin may easi hard either discov s...  \n",
       "1   uuuug difficult import get want life keep keep...  \n",
       "2   bitcoin chang world resist futil free train am...  \n",
       "3   open plot sale shamshabad free site visit ac c...  \n",
       "4   sell good plot total area sqft akbar pura area...  \n",
       "5   sell good plot total area sqft akbar pura area...  \n",
       "6   prepar ginger water easiest thing home excel r...  \n",
       "7   product name collar neck shirt tv product deta...  \n",
       "8   hi guy want buy skin cs go account cs go go fi...  \n",
       "9                           want buy knife fair trade  \n",
       "10  buyer want buy domain domain regist godaddi ta...  \n",
       "11               want buy cvd hpht diamond pleas call  \n",
       "12  pleas like follow get latest updat vision miss...  \n",
       "13  want buy fresh non host indian adsens account ...  \n",
       "14     kya koi compani sunday ke din interview leti h  \n",
       "15        need whatsapp market softwar want sell call  \n",
       "16  top mobil best mobil avail india want sell ama...  \n",
       "17  buy like bull sit like bear watch like eagl in...  \n",
       "18              k profit book lupin intraday today lt  \n",
       "19  want buy sell cbd oil product awesom compani f...  \n",
       "20  coinbas buy bitcoin amp secur wallet buy sell ...  \n",
       "21  let welcom new member vetri selvan sathi abhim...  \n",
       "22    feedbuzz children fish funni moment follow fore  \n",
       "23  want sell product amazon flipkart gst help sel...  \n",
       "24                                     want sell page  \n",
       "25  hello guy want buy fresh us email traffic affi...  \n",
       "26                     anybodi good cc inbox want buy  \n",
       "27  american diamond ring price pic best qualiti w...  \n",
       "28  want buy organ dri fruit cheapest price love e...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#perform stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "def normalize(text):\n",
    "    return \" \".join(text)\n",
    "\n",
    "stemmer= PorterStemmer()\n",
    "\n",
    "df[\"stemmed\"]= df.selected.map(lambda xs: [stemmer.stem(x) for x in xs])\n",
    "df[\"normalized\"]= df.stemmed.apply(normalize)\n",
    "test_df[\"stemmed\"]= test_df.selected.map(lambda xs: [stemmer.stem(x) for x in xs])\n",
    "test_df[\"normalized\"]= test_df.stemmed.apply(normalize)\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[64,\n",
       "  88,\n",
       "  74,\n",
       "  333,\n",
       "  203,\n",
       "  283,\n",
       "  433,\n",
       "  1039,\n",
       "  64,\n",
       "  234,\n",
       "  849,\n",
       "  1231,\n",
       "  88,\n",
       "  74,\n",
       "  337,\n",
       "  189,\n",
       "  10,\n",
       "  195],\n",
       " [47, 3, 415, 1230, 1230, 91, 272, 24, 4],\n",
       " [87, 180, 38, 42, 24, 4],\n",
       " [67,\n",
       "  23,\n",
       "  38,\n",
       "  375,\n",
       "  219,\n",
       "  604,\n",
       "  57,\n",
       "  329,\n",
       "  99,\n",
       "  389,\n",
       "  290,\n",
       "  33,\n",
       "  1018,\n",
       "  1201,\n",
       "  38,\n",
       "  375,\n",
       "  219,\n",
       "  53,\n",
       "  5,\n",
       "  67,\n",
       "  23,\n",
       "  38,\n",
       "  375,\n",
       "  219,\n",
       "  604,\n",
       "  57,\n",
       "  329,\n",
       "  99,\n",
       "  389,\n",
       "  290,\n",
       "  33,\n",
       "  1018,\n",
       "  1201,\n",
       "  38,\n",
       "  375,\n",
       "  219,\n",
       "  53,\n",
       "  5],\n",
       " [1, 7, 164, 164, 1174, 1177, 1, 8, 1282, 1026],\n",
       " [1, 7, 164, 164, 1174, 1177, 1, 8, 1282, 1026],\n",
       " [343,\n",
       "  584,\n",
       "  70,\n",
       "  209,\n",
       "  340,\n",
       "  964,\n",
       "  31,\n",
       "  163,\n",
       "  925,\n",
       "  52,\n",
       "  999,\n",
       "  5,\n",
       "  343,\n",
       "  584,\n",
       "  70,\n",
       "  209,\n",
       "  340,\n",
       "  964,\n",
       "  31,\n",
       "  163,\n",
       "  925,\n",
       "  52,\n",
       "  999,\n",
       "  5],\n",
       " [61,\n",
       "  83,\n",
       "  756,\n",
       "  61,\n",
       "  29,\n",
       "  685,\n",
       "  935,\n",
       "  105,\n",
       "  479,\n",
       "  8,\n",
       "  29,\n",
       "  605,\n",
       "  258,\n",
       "  605,\n",
       "  298,\n",
       "  1405,\n",
       "  8,\n",
       "  117,\n",
       "  99,\n",
       "  53,\n",
       "  29,\n",
       "  395,\n",
       "  13,\n",
       "  44,\n",
       "  804,\n",
       "  94,\n",
       "  61,\n",
       "  83,\n",
       "  756,\n",
       "  61,\n",
       "  29,\n",
       "  685,\n",
       "  935,\n",
       "  105,\n",
       "  479,\n",
       "  8,\n",
       "  29,\n",
       "  605,\n",
       "  258,\n",
       "  605,\n",
       "  298,\n",
       "  1405,\n",
       "  8,\n",
       "  117,\n",
       "  99,\n",
       "  53,\n",
       "  29,\n",
       "  395,\n",
       "  13,\n",
       "  44,\n",
       "  94,\n",
       "  5],\n",
       " [157, 79, 3, 2, 37, 9, 37, 37, 1073, 26, 1368, 286, 456, 73, 195, 772, 5],\n",
       " [3, 2, 376],\n",
       " [25,\n",
       "  3,\n",
       "  2,\n",
       "  45,\n",
       "  45,\n",
       "  1086,\n",
       "  552,\n",
       "  45,\n",
       "  190,\n",
       "  151,\n",
       "  1086,\n",
       "  55,\n",
       "  201,\n",
       "  190,\n",
       "  45,\n",
       "  1,\n",
       "  45,\n",
       "  25,\n",
       "  75,\n",
       "  704],\n",
       " [3, 2, 1517, 13, 44],\n",
       " [13,\n",
       "  12,\n",
       "  156,\n",
       "  47,\n",
       "  983,\n",
       "  954,\n",
       "  340,\n",
       "  505,\n",
       "  660,\n",
       "  47,\n",
       "  177,\n",
       "  22,\n",
       "  696,\n",
       "  704,\n",
       "  177,\n",
       "  100,\n",
       "  31,\n",
       "  15,\n",
       "  753,\n",
       "  391,\n",
       "  1230,\n",
       "  22,\n",
       "  112,\n",
       "  5],\n",
       " [3, 2, 228, 523, 71, 194, 361, 9, 475, 8, 59, 1065],\n",
       " [560, 1154, 62, 416, 1033],\n",
       " [21, 72, 34, 1215, 3, 1, 44],\n",
       " [309,\n",
       "  144,\n",
       "  48,\n",
       "  144,\n",
       "  33,\n",
       "  170,\n",
       "  3,\n",
       "  1,\n",
       "  160,\n",
       "  279,\n",
       "  148,\n",
       "  144,\n",
       "  10,\n",
       "  4,\n",
       "  11,\n",
       "  35,\n",
       "  73,\n",
       "  45,\n",
       "  83,\n",
       "  390,\n",
       "  1240,\n",
       "  711,\n",
       "  322,\n",
       "  71,\n",
       "  38,\n",
       "  71,\n",
       "  21,\n",
       "  380,\n",
       "  71,\n",
       "  314,\n",
       "  38,\n",
       "  9,\n",
       "  71,\n",
       "  108,\n",
       "  29,\n",
       "  403,\n",
       "  153,\n",
       "  148,\n",
       "  325,\n",
       "  1,\n",
       "  30,\n",
       "  175,\n",
       "  34,\n",
       "  155,\n",
       "  388,\n",
       "  1,\n",
       "  21,\n",
       "  175,\n",
       "  34,\n",
       "  1316,\n",
       "  498,\n",
       "  52,\n",
       "  155,\n",
       "  454,\n",
       "  21,\n",
       "  278,\n",
       "  279,\n",
       "  74,\n",
       "  596,\n",
       "  375,\n",
       "  170,\n",
       "  144,\n",
       "  190,\n",
       "  375,\n",
       "  48,\n",
       "  1063,\n",
       "  2,\n",
       "  1,\n",
       "  144,\n",
       "  351,\n",
       "  1059,\n",
       "  375,\n",
       "  226,\n",
       "  2],\n",
       " [2, 12, 1122, 510, 12, 1123, 280, 12, 1124, 1125, 1126],\n",
       " [20, 383, 133, 1127, 594, 32, 237],\n",
       " [3, 2, 1, 876, 877, 61, 202, 62, 38, 51, 878, 879, 483, 73, 96],\n",
       " [1023, 2, 87, 42, 359, 152, 2, 1, 87, 94, 428, 429],\n",
       " [221,\n",
       "  481,\n",
       "  6,\n",
       "  427,\n",
       "  1492,\n",
       "  1493,\n",
       "  1494,\n",
       "  1495,\n",
       "  1496,\n",
       "  1497,\n",
       "  1498,\n",
       "  1499,\n",
       "  1500,\n",
       "  1501,\n",
       "  1502,\n",
       "  1503,\n",
       "  1504,\n",
       "  1505,\n",
       "  1506,\n",
       "  1507,\n",
       "  1508,\n",
       "  5],\n",
       " [1509, 368, 1510, 1511, 277, 156, 1512],\n",
       " [3, 1, 61, 160, 722, 258, 22, 1, 1513, 3, 1, 61, 160, 722, 258, 22, 1, 258],\n",
       " [3, 1, 101],\n",
       " [68, 79, 3, 2, 228, 188, 414, 498, 279, 671, 39, 373, 516, 1514, 1515],\n",
       " [577, 7, 457, 18, 3, 2],\n",
       " [1516, 1517, 1518, 8, 408, 48, 118, 3, 2, 29, 384, 72, 18, 558],\n",
       " [3,\n",
       "  2,\n",
       "  141,\n",
       "  269,\n",
       "  270,\n",
       "  307,\n",
       "  8,\n",
       "  173,\n",
       "  723,\n",
       "  141,\n",
       "  724,\n",
       "  725,\n",
       "  124,\n",
       "  726,\n",
       "  81,\n",
       "  118,\n",
       "  90,\n",
       "  304,\n",
       "  8,\n",
       "  110,\n",
       "  51,\n",
       "  6,\n",
       "  266,\n",
       "  1,\n",
       "  141,\n",
       "  727,\n",
       "  271,\n",
       "  728,\n",
       "  42,\n",
       "  729,\n",
       "  38,\n",
       "  350,\n",
       "  90,\n",
       "  269,\n",
       "  270,\n",
       "  730,\n",
       "  731,\n",
       "  732,\n",
       "  733,\n",
       "  271,\n",
       "  734,\n",
       "  735,\n",
       "  405,\n",
       "  32,\n",
       "  8,\n",
       "  61,\n",
       "  736,\n",
       "  231,\n",
       "  5,\n",
       "  3,\n",
       "  2,\n",
       "  141,\n",
       "  269,\n",
       "  270,\n",
       "  307,\n",
       "  8,\n",
       "  173,\n",
       "  723,\n",
       "  141,\n",
       "  724,\n",
       "  725,\n",
       "  124,\n",
       "  726,\n",
       "  81,\n",
       "  118,\n",
       "  90,\n",
       "  304,\n",
       "  8,\n",
       "  110,\n",
       "  51,\n",
       "  6,\n",
       "  266,\n",
       "  1,\n",
       "  141,\n",
       "  727,\n",
       "  271,\n",
       "  728,\n",
       "  729,\n",
       "  38,\n",
       "  350,\n",
       "  90,\n",
       "  269,\n",
       "  270,\n",
       "  730,\n",
       "  731,\n",
       "  732,\n",
       "  733,\n",
       "  271,\n",
       "  734,\n",
       "  735,\n",
       "  405,\n",
       "  32,\n",
       "  8,\n",
       "  61,\n",
       "  736,\n",
       "  231,\n",
       "  5]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#assign each token from normalised column a unique number and apply to all rows.\n",
    "#all text get converted to respective unique value\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer= Tokenizer(num_words= 10000)\n",
    "tokenizer.fit_on_texts(df.normalized)\n",
    "\n",
    "\n",
    "tokenized_train= tokenizer.texts_to_sequences(df.normalized)\n",
    "tokenized_test= tokenizer.texts_to_sequences(test_df.normalized)\n",
    "tokenized_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1518"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total 1523 unique words are present in dataset\n",
    "tokenizer.word_index.keys().__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding sequences with 0 to make all the sentences to be same length.\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "train_padded= pad_sequences(tokenized_train, maxlen= 25, padding= \"pre\")\n",
    "test_padded= pad_sequences(tokenized_test, maxlen= 25, padding= \"pre\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 25)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function transform final processed text (columns padded) into 3D matrix (samples, steps, unique_words)\n",
    "#matrix contents one hot encoded words. Encoding was done for each step and based on unique words.\n",
    "\n",
    "def transform_x(data, tokenizer):\n",
    "    output_shape= [data.shape[0],\n",
    "                  data.shape[1],\n",
    "                  tokenizer.word_index.keys().__len__()]\n",
    "    results= np.zeros(output_shape)\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "        for ii in range(data.shape[1]):\n",
    "            results[i, ii, data[i,ii]-1]= 1\n",
    "    return results\n",
    "\n",
    "xtr_transformed= transform_x(train_padded, tokenizer)\n",
    "xts_transformed= transform_x(test_padded, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, BatchNormalization, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy as CC\n",
    "from tensorflow.keras.activations import relu, softmax\n",
    "from tensorflow.keras.initializers import he_uniform, glorot_uniform\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "\n",
    "class LSTMModel(object):\n",
    "    \n",
    "    def build_model(self, input_dim, output_shape, steps, dropout_rate, kernel_regularizer, bias_regularizer):\n",
    "        input_layer= Input(shape= (steps, input_dim))\n",
    "        \n",
    "        #make lstm_layer\n",
    "        lstm= LSTM(units= steps)(input_layer)\n",
    "        dense_1= Dense(output_shape, kernel_initializer= he_uniform(),\n",
    "                       bias_initializer= \"zeros\", \n",
    "                       kernel_regularizer= l2(l= kernel_regularizer),\n",
    "                       bias_regularizer= l2(l= bias_regularizer))(lstm)\n",
    "        x= BatchNormalization()(dense_1)\n",
    "        x= relu(x)\n",
    "        x= Dropout(rate= dropout_rate)(x)\n",
    "        o= Dense(output_shape, kernel_initializer= glorot_uniform(),\n",
    "                 bias_initializer= \"zeros\", \n",
    "                 kernel_regularizer= l2(l= kernel_regularizer), \n",
    "                 bias_regularizer= l2(l= bias_regularizer))(dense_1)\n",
    "        o= BatchNormalization()(o)\n",
    "        output= softmax(o, axis= 1)\n",
    "        \n",
    "        loss= CC()\n",
    "        metrics= AUC()\n",
    "        optimizer= Adam()\n",
    "        self.model= Model(inputs= [input_layer], outputs= [output])\n",
    "        self.model.compile(optimizer= optimizer, loss= loss, metrics= [metrics])\n",
    "        \n",
    "        \n",
    "    def train(self, x, y, validation_split, epochs):\n",
    "        self.model.fit(x, y, validation_split= validation_split, epochs= epochs)\n",
    "        self.model.save('my_model.h5')\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "1518\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "steps= xtr_transformed.shape[1]\n",
    "dim= xtr_transformed.shape[2]\n",
    "output_shape= ytr_encoded.shape[1]\n",
    "print(steps)\n",
    "print(dim)\n",
    "print(output_shape)\n",
    "model= LSTMModel()\n",
    "model.build_model(input_dim= dim,\n",
    "                  output_shape= output_shape,\n",
    "                  steps= steps, \n",
    "                  dropout_rate= 0.5, \n",
    "                  bias_regularizer= 0.3, \n",
    "                  kernel_regularizer= 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "6/6 [==============================] - 5s 841ms/step - loss: 5.6129 - auc: 0.5183 - val_loss: 5.3977 - val_auc: 0.5607\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 5.1990 - auc: 0.7125 - val_loss: 5.2821 - val_auc: 0.5415\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 0s 80ms/step - loss: 4.8956 - auc: 0.8477 - val_loss: 5.1693 - val_auc: 0.5736\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 1s 97ms/step - loss: 4.6385 - auc: 0.9302 - val_loss: 5.0618 - val_auc: 0.6106\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 4.4469 - auc: 0.9627 - val_loss: 4.9576 - val_auc: 0.6208\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 1s 92ms/step - loss: 4.2813 - auc: 0.9718 - val_loss: 4.8568 - val_auc: 0.5920\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 0s 66ms/step - loss: 4.1016 - auc: 0.9816 - val_loss: 4.7584 - val_auc: 0.5592\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 0s 77ms/step - loss: 3.9477 - auc: 0.9904 - val_loss: 4.6615 - val_auc: 0.5571\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 3.8052 - auc: 0.9972 - val_loss: 4.5685 - val_auc: 0.5447\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 1s 87ms/step - loss: 3.6781 - auc: 0.9968 - val_loss: 4.4784 - val_auc: 0.5239\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 0s 76ms/step - loss: 3.5613 - auc: 0.9996 - val_loss: 4.3958 - val_auc: 0.5273\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 1s 91ms/step - loss: 3.4552 - auc: 0.9998 - val_loss: 4.3202 - val_auc: 0.5124\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 3.3487 - auc: 0.9998 - val_loss: 4.2436 - val_auc: 0.5171\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 1s 115ms/step - loss: 3.2486 - auc: 0.9996 - val_loss: 4.1528 - val_auc: 0.5356\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 0s 78ms/step - loss: 3.1565 - auc: 0.9999 - val_loss: 4.0669 - val_auc: 0.5221\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 3.0791 - auc: 0.9994 - val_loss: 3.9901 - val_auc: 0.5169\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 1s 120ms/step - loss: 3.0000 - auc: 0.9999 - val_loss: 3.9169 - val_auc: 0.5003\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 0s 76ms/step - loss: 2.8903 - auc: 1.0000 - val_loss: 3.8555 - val_auc: 0.4995\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 1s 104ms/step - loss: 2.8335 - auc: 0.9999 - val_loss: 3.7715 - val_auc: 0.5426\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 2.7402 - auc: 1.0000 - val_loss: 3.6935 - val_auc: 0.5653\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 1s 98ms/step - loss: 2.6621 - auc: 1.0000 - val_loss: 3.6352 - val_auc: 0.5226\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 1s 102ms/step - loss: 2.5799 - auc: 1.0000 - val_loss: 3.5679 - val_auc: 0.5175\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 0s 73ms/step - loss: 2.5260 - auc: 0.9980 - val_loss: 3.4718 - val_auc: 0.5935\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 2.4824 - auc: 0.9978 - val_loss: 3.3933 - val_auc: 0.6422\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 0s 71ms/step - loss: 2.3750 - auc: 1.0000 - val_loss: 3.3247 - val_auc: 0.6805\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 2.3201 - auc: 1.0000 - val_loss: 3.2898 - val_auc: 0.5868\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 2.2550 - auc: 0.9997 - val_loss: 3.2387 - val_auc: 0.6031\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 1s 95ms/step - loss: 2.2028 - auc: 0.9999 - val_loss: 3.1633 - val_auc: 0.6289\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 0s 73ms/step - loss: 2.1443 - auc: 1.0000 - val_loss: 3.1000 - val_auc: 0.6571\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 2.1130 - auc: 0.9994 - val_loss: 3.0241 - val_auc: 0.6905\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 2.0416 - auc: 0.9999 - val_loss: 2.9832 - val_auc: 0.6547\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 1s 100ms/step - loss: 1.9844 - auc: 1.0000 - val_loss: 2.9251 - val_auc: 0.6959\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 0s 76ms/step - loss: 1.9539 - auc: 0.9997 - val_loss: 2.8786 - val_auc: 0.6778\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 1s 83ms/step - loss: 1.8834 - auc: 1.0000 - val_loss: 2.8292 - val_auc: 0.6746\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 1.8648 - auc: 0.9986 - val_loss: 2.7909 - val_auc: 0.6554\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 1s 106ms/step - loss: 1.8057 - auc: 1.0000 - val_loss: 2.7564 - val_auc: 0.6234\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 1s 204ms/step - loss: 1.7374 - auc: 1.0000 - val_loss: 2.6856 - val_auc: 0.6891\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 1s 133ms/step - loss: 1.6877 - auc: 1.0000 - val_loss: 2.6959 - val_auc: 0.5973\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 1s 124ms/step - loss: 1.6487 - auc: 1.0000 - val_loss: 2.5775 - val_auc: 0.7258\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 1s 121ms/step - loss: 1.6285 - auc: 0.9998 - val_loss: 2.5469 - val_auc: 0.6933\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 1s 135ms/step - loss: 1.5868 - auc: 0.9997 - val_loss: 2.5908 - val_auc: 0.5955\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 1s 202ms/step - loss: 1.5474 - auc: 1.0000 - val_loss: 2.5232 - val_auc: 0.6408\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 1s 169ms/step - loss: 1.5031 - auc: 0.9999 - val_loss: 2.4200 - val_auc: 0.7213\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 1s 99ms/step - loss: 1.4675 - auc: 0.9999 - val_loss: 2.3866 - val_auc: 0.6838\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 1s 210ms/step - loss: 1.4327 - auc: 0.9990 - val_loss: 2.3827 - val_auc: 0.6643\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 1s 85ms/step - loss: 1.4087 - auc: 1.0000 - val_loss: 2.3751 - val_auc: 0.6716\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 1s 100ms/step - loss: 1.3501 - auc: 1.0000 - val_loss: 2.3024 - val_auc: 0.6624\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 1s 118ms/step - loss: 1.3181 - auc: 1.0000 - val_loss: 2.3372 - val_auc: 0.6333\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 1.2883 - auc: 0.9999 - val_loss: 2.2733 - val_auc: 0.6590\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 1s 113ms/step - loss: 1.2738 - auc: 0.9998 - val_loss: 2.3170 - val_auc: 0.6683\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 1s 113ms/step - loss: 1.2442 - auc: 0.9994 - val_loss: 2.1817 - val_auc: 0.6577\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 1s 87ms/step - loss: 1.1895 - auc: 0.9999 - val_loss: 2.1729 - val_auc: 0.6547\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 1s 118ms/step - loss: 1.1768 - auc: 1.0000 - val_loss: 2.1622 - val_auc: 0.6552\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 1s 88ms/step - loss: 1.1657 - auc: 0.9997 - val_loss: 2.1402 - val_auc: 0.6566\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 1s 88ms/step - loss: 1.1106 - auc: 1.0000 - val_loss: 2.0774 - val_auc: 0.6645\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 1s 96ms/step - loss: 1.0841 - auc: 1.0000 - val_loss: 2.0733 - val_auc: 0.6624\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 1s 96ms/step - loss: 1.0860 - auc: 0.9998 - val_loss: 2.1320 - val_auc: 0.6180\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 1s 141ms/step - loss: 1.0291 - auc: 1.0000 - val_loss: 2.0625 - val_auc: 0.6460\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 1s 112ms/step - loss: 1.0216 - auc: 1.0000 - val_loss: 1.9932 - val_auc: 0.6683\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 1s 122ms/step - loss: 0.9872 - auc: 0.9998 - val_loss: 2.0601 - val_auc: 0.6397\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.9820 - auc: 1.0000 - val_loss: 2.1316 - val_auc: 0.5767\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 0.9544 - auc: 1.0000 - val_loss: 1.9595 - val_auc: 0.6454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/1000\n",
      "6/6 [==============================] - 1s 137ms/step - loss: 0.9315 - auc: 0.9999 - val_loss: 1.9859 - val_auc: 0.6456\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 1s 130ms/step - loss: 0.9001 - auc: 0.9999 - val_loss: 1.8861 - val_auc: 0.6656\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 1s 118ms/step - loss: 0.8678 - auc: 1.0000 - val_loss: 2.0442 - val_auc: 0.5820\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 1s 161ms/step - loss: 0.8796 - auc: 1.0000 - val_loss: 1.9095 - val_auc: 0.6368\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 1s 235ms/step - loss: 0.8694 - auc: 0.9998 - val_loss: 1.8833 - val_auc: 0.6668\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 1s 84ms/step - loss: 0.8444 - auc: 0.9997 - val_loss: 1.9334 - val_auc: 0.6131\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 1s 119ms/step - loss: 0.8058 - auc: 1.0000 - val_loss: 1.9173 - val_auc: 0.6172\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 0.8001 - auc: 1.0000 - val_loss: 1.9137 - val_auc: 0.6445\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 1s 115ms/step - loss: 0.7813 - auc: 1.0000 - val_loss: 1.7125 - val_auc: 0.7347\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 1s 101ms/step - loss: 0.7985 - auc: 0.9996 - val_loss: 2.1476 - val_auc: 0.5690\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 1s 128ms/step - loss: 0.8101 - auc: 1.0000 - val_loss: 2.1681 - val_auc: 0.4751\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 0s 75ms/step - loss: 0.7862 - auc: 0.9974 - val_loss: 1.8296 - val_auc: 0.5967\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 1s 113ms/step - loss: 0.7242 - auc: 1.0000 - val_loss: 1.8098 - val_auc: 0.6753\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 0s 72ms/step - loss: 0.7309 - auc: 0.9992 - val_loss: 1.6897 - val_auc: 0.6843\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 0.7096 - auc: 1.0000 - val_loss: 1.7743 - val_auc: 0.6135\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 1s 95ms/step - loss: 0.6958 - auc: 1.0000 - val_loss: 1.8304 - val_auc: 0.6228\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 0s 78ms/step - loss: 0.6688 - auc: 1.0000 - val_loss: 1.6787 - val_auc: 0.6726\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 1s 117ms/step - loss: 0.6604 - auc: 1.0000 - val_loss: 1.7561 - val_auc: 0.6421\n",
      "Epoch 81/1000\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.6342 - auc: 1.0000 - val_loss: 1.7105 - val_auc: 0.6343\n",
      "Epoch 82/1000\n",
      "6/6 [==============================] - 1s 159ms/step - loss: 0.6363 - auc: 1.0000 - val_loss: 1.6610 - val_auc: 0.6661\n",
      "Epoch 83/1000\n",
      "6/6 [==============================] - 1s 100ms/step - loss: 0.6283 - auc: 0.9999 - val_loss: 1.7653 - val_auc: 0.6076\n",
      "Epoch 84/1000\n",
      "6/6 [==============================] - 1s 109ms/step - loss: 0.6239 - auc: 0.9999 - val_loss: 1.8485 - val_auc: 0.6110\n",
      "Epoch 85/1000\n",
      "6/6 [==============================] - 1s 84ms/step - loss: 0.6427 - auc: 1.0000 - val_loss: 2.0090 - val_auc: 0.5789\n",
      "Epoch 86/1000\n",
      "6/6 [==============================] - 1s 111ms/step - loss: 0.5978 - auc: 0.9999 - val_loss: 1.6061 - val_auc: 0.6592\n",
      "Epoch 87/1000\n",
      "6/6 [==============================] - 0s 69ms/step - loss: 0.5976 - auc: 0.9998 - val_loss: 1.8220 - val_auc: 0.6365\n",
      "Epoch 88/1000\n",
      "6/6 [==============================] - 1s 103ms/step - loss: 0.5821 - auc: 0.9999 - val_loss: 1.7008 - val_auc: 0.6561\n",
      "Epoch 89/1000\n",
      "6/6 [==============================] - 0s 69ms/step - loss: 0.5712 - auc: 1.0000 - val_loss: 1.5791 - val_auc: 0.6585\n",
      "Epoch 90/1000\n",
      "6/6 [==============================] - 1s 89ms/step - loss: 0.5690 - auc: 0.9998 - val_loss: 1.8194 - val_auc: 0.5856\n",
      "Epoch 91/1000\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 0.5552 - auc: 1.0000 - val_loss: 1.6304 - val_auc: 0.6503\n",
      "Epoch 92/1000\n",
      "6/6 [==============================] - 1s 97ms/step - loss: 0.5354 - auc: 1.0000 - val_loss: 1.6441 - val_auc: 0.6190\n",
      "Epoch 93/1000\n",
      "6/6 [==============================] - 0s 81ms/step - loss: 0.5253 - auc: 1.0000 - val_loss: 1.7516 - val_auc: 0.5967\n",
      "Epoch 94/1000\n",
      "6/6 [==============================] - 0s 81ms/step - loss: 0.5277 - auc: 0.9990 - val_loss: 1.4879 - val_auc: 0.7379\n",
      "Epoch 95/1000\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 0.5120 - auc: 1.0000 - val_loss: 1.6872 - val_auc: 0.6184\n",
      "Epoch 96/1000\n",
      "6/6 [==============================] - 0s 73ms/step - loss: 0.5061 - auc: 1.0000 - val_loss: 1.6541 - val_auc: 0.6564\n",
      "Epoch 97/1000\n",
      "6/6 [==============================] - 1s 91ms/step - loss: 0.4881 - auc: 1.0000 - val_loss: 1.5525 - val_auc: 0.6488\n",
      "Epoch 98/1000\n",
      "6/6 [==============================] - 0s 76ms/step - loss: 0.4947 - auc: 1.0000 - val_loss: 1.8035 - val_auc: 0.6032\n",
      "Epoch 99/1000\n",
      "6/6 [==============================] - 1s 95ms/step - loss: 0.4879 - auc: 1.0000 - val_loss: 1.6485 - val_auc: 0.6256\n",
      "Epoch 100/1000\n",
      "6/6 [==============================] - 0s 75ms/step - loss: 0.4704 - auc: 1.0000 - val_loss: 1.4349 - val_auc: 0.7374\n",
      "Epoch 101/1000\n",
      "6/6 [==============================] - 1s 111ms/step - loss: 0.4570 - auc: 1.0000 - val_loss: 1.7393 - val_auc: 0.6405\n",
      "Epoch 102/1000\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 0.4612 - auc: 1.0000 - val_loss: 1.5538 - val_auc: 0.6698\n",
      "Epoch 103/1000\n",
      "6/6 [==============================] - 1s 84ms/step - loss: 0.4533 - auc: 1.0000 - val_loss: 1.5625 - val_auc: 0.6267\n",
      "Epoch 104/1000\n",
      "6/6 [==============================] - 0s 73ms/step - loss: 0.4372 - auc: 1.0000 - val_loss: 1.6103 - val_auc: 0.6179\n",
      "Epoch 105/1000\n",
      "6/6 [==============================] - 0s 82ms/step - loss: 0.4299 - auc: 1.0000 - val_loss: 1.4285 - val_auc: 0.7151\n",
      "Epoch 106/1000\n",
      "6/6 [==============================] - 0s 66ms/step - loss: 0.4247 - auc: 1.0000 - val_loss: 1.4733 - val_auc: 0.6817\n",
      "Epoch 107/1000\n",
      "6/6 [==============================] - 1s 98ms/step - loss: 0.4170 - auc: 1.0000 - val_loss: 1.6262 - val_auc: 0.6469\n",
      "Epoch 108/1000\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 0.4142 - auc: 1.0000 - val_loss: 1.4857 - val_auc: 0.6760\n",
      "Epoch 109/1000\n",
      "6/6 [==============================] - 1s 92ms/step - loss: 0.4238 - auc: 1.0000 - val_loss: 1.4308 - val_auc: 0.7029\n",
      "Epoch 110/1000\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.4078 - auc: 1.0000 - val_loss: 1.5031 - val_auc: 0.6726\n",
      "Epoch 111/1000\n",
      "6/6 [==============================] - 1s 95ms/step - loss: 0.3955 - auc: 1.0000 - val_loss: 1.5710 - val_auc: 0.5964\n",
      "Epoch 112/1000\n",
      "6/6 [==============================] - 1s 103ms/step - loss: 0.3847 - auc: 1.0000 - val_loss: 1.4737 - val_auc: 0.6605\n",
      "Epoch 113/1000\n",
      "6/6 [==============================] - 1s 90ms/step - loss: 0.3920 - auc: 0.9999 - val_loss: 1.7091 - val_auc: 0.6473\n",
      "Epoch 114/1000\n",
      "6/6 [==============================] - 1s 126ms/step - loss: 0.4400 - auc: 0.9983 - val_loss: 2.0506 - val_auc: 0.5728\n",
      "Epoch 115/1000\n",
      "6/6 [==============================] - 1s 129ms/step - loss: 0.3979 - auc: 1.0000 - val_loss: 1.5395 - val_auc: 0.5989\n",
      "Epoch 116/1000\n",
      "6/6 [==============================] - 1s 120ms/step - loss: 0.3887 - auc: 1.0000 - val_loss: 1.4516 - val_auc: 0.6782\n",
      "Epoch 117/1000\n",
      "6/6 [==============================] - 1s 103ms/step - loss: 0.3702 - auc: 1.0000 - val_loss: 1.3671 - val_auc: 0.7271\n",
      "Epoch 118/1000\n",
      "6/6 [==============================] - 1s 109ms/step - loss: 0.3752 - auc: 1.0000 - val_loss: 1.4915 - val_auc: 0.6727\n",
      "Epoch 119/1000\n",
      "6/6 [==============================] - 0s 77ms/step - loss: 0.3621 - auc: 1.0000 - val_loss: 1.6938 - val_auc: 0.5249\n",
      "Epoch 120/1000\n",
      "6/6 [==============================] - 1s 124ms/step - loss: 0.3613 - auc: 1.0000 - val_loss: 1.3983 - val_auc: 0.7195\n",
      "Epoch 121/1000\n",
      "6/6 [==============================] - 1s 152ms/step - loss: 0.3654 - auc: 1.0000 - val_loss: 1.4300 - val_auc: 0.6874\n",
      "Epoch 122/1000\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 0.3553 - auc: 1.0000 - val_loss: 1.3249 - val_auc: 0.7580\n",
      "Epoch 123/1000\n",
      "6/6 [==============================] - 0s 65ms/step - loss: 0.3472 - auc: 1.0000 - val_loss: 1.4384 - val_auc: 0.6774\n",
      "Epoch 124/1000\n",
      "6/6 [==============================] - 1s 105ms/step - loss: 0.3442 - auc: 1.0000 - val_loss: 1.3855 - val_auc: 0.7115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/1000\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.3308 - auc: 1.0000 - val_loss: 1.3344 - val_auc: 0.7405\n",
      "Epoch 126/1000\n",
      "6/6 [==============================] - 1s 105ms/step - loss: 0.3237 - auc: 1.0000 - val_loss: 1.4805 - val_auc: 0.6492\n",
      "Epoch 127/1000\n",
      "6/6 [==============================] - 1s 129ms/step - loss: 0.3357 - auc: 1.0000 - val_loss: 1.4329 - val_auc: 0.6893\n",
      "Epoch 128/1000\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 0.3447 - auc: 1.0000 - val_loss: 1.6486 - val_auc: 0.6472\n",
      "Epoch 129/1000\n",
      "6/6 [==============================] - 1s 90ms/step - loss: 0.3530 - auc: 1.0000 - val_loss: 1.4696 - val_auc: 0.6668\n",
      "Epoch 130/1000\n",
      "6/6 [==============================] - 0s 66ms/step - loss: 0.3125 - auc: 1.0000 - val_loss: 1.3880 - val_auc: 0.7143\n",
      "Epoch 131/1000\n",
      "6/6 [==============================] - 0s 73ms/step - loss: 0.3216 - auc: 1.0000 - val_loss: 1.6079 - val_auc: 0.6189\n",
      "Epoch 132/1000\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.3204 - auc: 1.0000 - val_loss: 1.2867 - val_auc: 0.7637\n",
      "Epoch 133/1000\n",
      "6/6 [==============================] - 1s 127ms/step - loss: 0.3065 - auc: 1.0000 - val_loss: 1.3541 - val_auc: 0.7232\n",
      "Epoch 134/1000\n",
      "6/6 [==============================] - 1s 111ms/step - loss: 0.3280 - auc: 1.0000 - val_loss: 1.3418 - val_auc: 0.7274\n",
      "Epoch 135/1000\n",
      "6/6 [==============================] - 1s 89ms/step - loss: 0.3053 - auc: 1.0000 - val_loss: 1.3155 - val_auc: 0.7412\n",
      "Epoch 136/1000\n",
      "6/6 [==============================] - 1s 108ms/step - loss: 0.2964 - auc: 1.0000 - val_loss: 1.3470 - val_auc: 0.7211\n",
      "Epoch 137/1000\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 0.2900 - auc: 1.0000 - val_loss: 1.3191 - val_auc: 0.7381\n",
      "Epoch 138/1000\n",
      "6/6 [==============================] - 1s 106ms/step - loss: 0.3035 - auc: 1.0000 - val_loss: 1.4285 - val_auc: 0.6708\n",
      "Epoch 139/1000\n",
      "6/6 [==============================] - 1s 92ms/step - loss: 0.2954 - auc: 1.0000 - val_loss: 1.5983 - val_auc: 0.6208\n",
      "Epoch 140/1000\n",
      "6/6 [==============================] - 1s 96ms/step - loss: 0.2866 - auc: 1.0000 - val_loss: 1.3428 - val_auc: 0.7147\n",
      "Epoch 141/1000\n",
      "6/6 [==============================] - 1s 158ms/step - loss: 0.2806 - auc: 1.0000 - val_loss: 1.4757 - val_auc: 0.6454\n",
      "Epoch 142/1000\n",
      "6/6 [==============================] - 1s 128ms/step - loss: 0.2864 - auc: 1.0000 - val_loss: 1.4690 - val_auc: 0.6700\n",
      "Epoch 143/1000\n",
      "6/6 [==============================] - 1s 115ms/step - loss: 0.3064 - auc: 1.0000 - val_loss: 1.8091 - val_auc: 0.6263\n",
      "Epoch 144/1000\n",
      "6/6 [==============================] - 0s 62ms/step - loss: 0.3090 - auc: 1.0000 - val_loss: 1.4155 - val_auc: 0.6722\n",
      "Epoch 145/1000\n",
      "6/6 [==============================] - 1s 101ms/step - loss: 0.2892 - auc: 0.9999 - val_loss: 1.5782 - val_auc: 0.5975\n",
      "Epoch 146/1000\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.2889 - auc: 1.0000 - val_loss: 1.3498 - val_auc: 0.7089\n",
      "Epoch 147/1000\n",
      "6/6 [==============================] - 1s 95ms/step - loss: 0.2885 - auc: 1.0000 - val_loss: 1.2949 - val_auc: 0.7523\n",
      "Epoch 148/1000\n",
      "6/6 [==============================] - 1s 145ms/step - loss: 0.2647 - auc: 1.0000 - val_loss: 1.3107 - val_auc: 0.7370\n",
      "Epoch 149/1000\n",
      "6/6 [==============================] - 0s 80ms/step - loss: 0.2650 - auc: 1.0000 - val_loss: 1.3935 - val_auc: 0.6788\n",
      "Epoch 150/1000\n",
      "6/6 [==============================] - 1s 105ms/step - loss: 0.2609 - auc: 1.0000 - val_loss: 1.4311 - val_auc: 0.6661\n",
      "Epoch 151/1000\n",
      "6/6 [==============================] - 1s 96ms/step - loss: 0.2653 - auc: 1.0000 - val_loss: 1.2614 - val_auc: 0.7612\n",
      "Epoch 152/1000\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 0.2626 - auc: 0.9999 - val_loss: 1.2862 - val_auc: 0.7449\n",
      "Epoch 153/1000\n",
      "6/6 [==============================] - 1s 131ms/step - loss: 0.2529 - auc: 1.0000 - val_loss: 1.3412 - val_auc: 0.7165\n",
      "Epoch 154/1000\n",
      "6/6 [==============================] - 1s 127ms/step - loss: 0.2544 - auc: 1.0000 - val_loss: 1.3307 - val_auc: 0.7246\n",
      "Epoch 155/1000\n",
      "6/6 [==============================] - 0s 72ms/step - loss: 0.2722 - auc: 0.9987 - val_loss: 1.3083 - val_auc: 0.7425\n",
      "Epoch 156/1000\n",
      "6/6 [==============================] - 1s 101ms/step - loss: 0.2679 - auc: 1.0000 - val_loss: 1.4789 - val_auc: 0.6629\n",
      "Epoch 157/1000\n",
      "6/6 [==============================] - 0s 72ms/step - loss: 0.2526 - auc: 1.0000 - val_loss: 1.3564 - val_auc: 0.7069\n",
      "Epoch 158/1000\n",
      "6/6 [==============================] - 1s 92ms/step - loss: 0.2668 - auc: 0.9999 - val_loss: 1.4934 - val_auc: 0.6484\n",
      "Epoch 159/1000\n",
      "6/6 [==============================] - 1s 96ms/step - loss: 0.2593 - auc: 1.0000 - val_loss: 1.4590 - val_auc: 0.6586\n",
      "Epoch 160/1000\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.2501 - auc: 0.9999 - val_loss: 1.3197 - val_auc: 0.7395\n",
      "Epoch 161/1000\n",
      "6/6 [==============================] - 1s 100ms/step - loss: 0.2606 - auc: 0.9999 - val_loss: 1.5140 - val_auc: 0.6377\n",
      "Epoch 162/1000\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 0.2473 - auc: 1.0000 - val_loss: 1.3003 - val_auc: 0.7434\n",
      "Epoch 163/1000\n",
      "6/6 [==============================] - 1s 103ms/step - loss: 0.2447 - auc: 1.0000 - val_loss: 1.3416 - val_auc: 0.7083\n",
      "Epoch 164/1000\n",
      "6/6 [==============================] - 0s 74ms/step - loss: 0.2366 - auc: 1.0000 - val_loss: 1.3925 - val_auc: 0.6840\n",
      "Epoch 165/1000\n",
      "6/6 [==============================] - 1s 127ms/step - loss: 0.2359 - auc: 1.0000 - val_loss: 1.4358 - val_auc: 0.6723\n",
      "Epoch 166/1000\n",
      "6/6 [==============================] - 1s 172ms/step - loss: 0.2506 - auc: 0.9999 - val_loss: 1.2827 - val_auc: 0.7437\n",
      "Epoch 167/1000\n",
      "6/6 [==============================] - 1s 107ms/step - loss: 0.2261 - auc: 1.0000 - val_loss: 1.3361 - val_auc: 0.7151\n",
      "Epoch 168/1000\n",
      "6/6 [==============================] - 0s 83ms/step - loss: 0.2286 - auc: 1.0000 - val_loss: 1.3624 - val_auc: 0.6974\n",
      "Epoch 169/1000\n",
      "6/6 [==============================] - 1s 107ms/step - loss: 0.2276 - auc: 1.0000 - val_loss: 1.3266 - val_auc: 0.7256\n",
      "Epoch 170/1000\n",
      "6/6 [==============================] - 1s 111ms/step - loss: 0.2305 - auc: 1.0000 - val_loss: 1.4019 - val_auc: 0.6720\n",
      "Epoch 171/1000\n",
      "6/6 [==============================] - 0s 70ms/step - loss: 0.2344 - auc: 1.0000 - val_loss: 1.4744 - val_auc: 0.6640\n",
      "Epoch 172/1000\n",
      "6/6 [==============================] - 1s 90ms/step - loss: 0.2330 - auc: 1.0000 - val_loss: 1.6743 - val_auc: 0.6411\n",
      "Epoch 173/1000\n",
      "6/6 [==============================] - 0s 72ms/step - loss: 0.2339 - auc: 1.0000 - val_loss: 1.3426 - val_auc: 0.7067\n",
      "Epoch 174/1000\n",
      "6/6 [==============================] - 1s 99ms/step - loss: 0.2172 - auc: 1.0000 - val_loss: 1.4607 - val_auc: 0.6529\n",
      "Epoch 175/1000\n",
      "6/6 [==============================] - 1s 87ms/step - loss: 0.2280 - auc: 1.0000 - val_loss: 1.3624 - val_auc: 0.6967\n",
      "Epoch 176/1000\n",
      "6/6 [==============================] - 1s 105ms/step - loss: 0.2342 - auc: 1.0000 - val_loss: 1.3408 - val_auc: 0.7162\n",
      "Epoch 177/1000\n",
      "6/6 [==============================] - 1s 91ms/step - loss: 0.2387 - auc: 0.9999 - val_loss: 1.4220 - val_auc: 0.6878\n",
      "Epoch 178/1000\n",
      "6/6 [==============================] - 0s 65ms/step - loss: 0.2250 - auc: 1.0000 - val_loss: 1.3847 - val_auc: 0.6950\n",
      "Epoch 179/1000\n",
      "6/6 [==============================] - 0s 74ms/step - loss: 0.2054 - auc: 1.0000 - val_loss: 1.3860 - val_auc: 0.6964\n",
      "Epoch 180/1000\n",
      "6/6 [==============================] - 0s 77ms/step - loss: 0.2127 - auc: 1.0000 - val_loss: 1.3418 - val_auc: 0.7196\n",
      "Epoch 181/1000\n",
      "6/6 [==============================] - 1s 109ms/step - loss: 0.2214 - auc: 0.9999 - val_loss: 1.3326 - val_auc: 0.7266\n",
      "Epoch 182/1000\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.2160 - auc: 1.0000 - val_loss: 1.3948 - val_auc: 0.6905\n",
      "Epoch 183/1000\n",
      "6/6 [==============================] - 1s 108ms/step - loss: 0.2024 - auc: 1.0000 - val_loss: 1.3543 - val_auc: 0.7215\n",
      "Epoch 184/1000\n",
      "6/6 [==============================] - 0s 65ms/step - loss: 0.2229 - auc: 0.9999 - val_loss: 1.3600 - val_auc: 0.7075\n",
      "Epoch 185/1000\n",
      "6/6 [==============================] - 1s 101ms/step - loss: 0.2194 - auc: 1.0000 - val_loss: 1.3130 - val_auc: 0.7345\n",
      "Epoch 186/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 70ms/step - loss: 0.2182 - auc: 0.9999 - val_loss: 1.3392 - val_auc: 0.7145\n",
      "Epoch 187/1000\n",
      "6/6 [==============================] - 1s 92ms/step - loss: 0.2076 - auc: 1.0000 - val_loss: 1.3483 - val_auc: 0.7373\n",
      "Epoch 188/1000\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.2168 - auc: 1.0000 - val_loss: 1.7713 - val_auc: 0.6262\n",
      "Epoch 189/1000\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 0.2300 - auc: 1.0000 - val_loss: 1.5444 - val_auc: 0.6312\n",
      "Epoch 190/1000\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 0.2200 - auc: 0.9999 - val_loss: 1.5692 - val_auc: 0.6444\n",
      "Epoch 191/1000\n",
      "6/6 [==============================] - 1s 110ms/step - loss: 0.3163 - auc: 0.9995 - val_loss: 2.3704 - val_auc: 0.5908\n",
      "Epoch 192/1000\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.3977 - auc: 1.0000 - val_loss: 1.9972 - val_auc: 0.6157\n",
      "Epoch 193/1000\n",
      "6/6 [==============================] - 1s 99ms/step - loss: 0.2867 - auc: 0.9996 - val_loss: 1.3718 - val_auc: 0.7118\n",
      "Epoch 194/1000\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 0.2419 - auc: 0.9997 - val_loss: 1.7506 - val_auc: 0.6367\n",
      "Epoch 195/1000\n",
      "6/6 [==============================] - 1s 97ms/step - loss: 0.2558 - auc: 0.9974 - val_loss: 1.8678 - val_auc: 0.5525\n",
      "Epoch 196/1000\n",
      "6/6 [==============================] - 1s 119ms/step - loss: 0.2167 - auc: 1.0000 - val_loss: 1.4913 - val_auc: 0.6584\n",
      "Epoch 197/1000\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.2208 - auc: 1.0000 - val_loss: 1.3666 - val_auc: 0.7209\n",
      "Epoch 198/1000\n",
      "6/6 [==============================] - 1s 121ms/step - loss: 0.2071 - auc: 1.0000 - val_loss: 1.3450 - val_auc: 0.7177\n",
      "Epoch 199/1000\n",
      "6/6 [==============================] - 1s 103ms/step - loss: 0.2346 - auc: 0.9998 - val_loss: 1.3576 - val_auc: 0.7231\n",
      "Epoch 200/1000\n",
      "6/6 [==============================] - 0s 75ms/step - loss: 0.2048 - auc: 1.0000 - val_loss: 1.3012 - val_auc: 0.7473\n",
      "Epoch 201/1000\n",
      "6/6 [==============================] - 1s 97ms/step - loss: 0.1953 - auc: 1.0000 - val_loss: 1.2882 - val_auc: 0.7514\n",
      "Epoch 202/1000\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.1811 - auc: 1.0000 - val_loss: 1.3283 - val_auc: 0.7265\n",
      "Epoch 203/1000\n",
      "6/6 [==============================] - 0s 71ms/step - loss: 0.2040 - auc: 1.0000 - val_loss: 1.3409 - val_auc: 0.7131\n",
      "Epoch 204/1000\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.2102 - auc: 1.0000 - val_loss: 1.3687 - val_auc: 0.6862\n",
      "Epoch 205/1000\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.2108 - auc: 0.9999 - val_loss: 1.2967 - val_auc: 0.7357\n",
      "Epoch 206/1000\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 0.1924 - auc: 1.0000 - val_loss: 1.3212 - val_auc: 0.7252\n",
      "Epoch 207/1000\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.2002 - auc: 1.0000 - val_loss: 1.3378 - val_auc: 0.7135\n",
      "Epoch 208/1000\n",
      "6/6 [==============================] - 1s 100ms/step - loss: 0.1945 - auc: 1.0000 - val_loss: 1.3343 - val_auc: 0.7210\n",
      "Epoch 209/1000\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.2420 - auc: 0.9997 - val_loss: 1.3602 - val_auc: 0.7200\n",
      "Epoch 210/1000\n",
      "6/6 [==============================] - 1s 92ms/step - loss: 0.2110 - auc: 1.0000 - val_loss: 1.3769 - val_auc: 0.7064\n",
      "Epoch 211/1000\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.1919 - auc: 1.0000 - val_loss: 1.3939 - val_auc: 0.7049\n",
      "Epoch 212/1000\n",
      "6/6 [==============================] - 1s 119ms/step - loss: 0.2024 - auc: 1.0000 - val_loss: 1.3983 - val_auc: 0.7091\n",
      "Epoch 213/1000\n",
      "6/6 [==============================] - 1s 114ms/step - loss: 0.1827 - auc: 1.0000 - val_loss: 1.4001 - val_auc: 0.7049\n",
      "Epoch 214/1000\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.1944 - auc: 1.0000 - val_loss: 1.3262 - val_auc: 0.7340\n",
      "Epoch 215/1000\n",
      "6/6 [==============================] - 1s 115ms/step - loss: 0.1744 - auc: 1.0000 - val_loss: 1.3040 - val_auc: 0.7552\n",
      "Epoch 216/1000\n",
      "6/6 [==============================] - 0s 75ms/step - loss: 0.2023 - auc: 1.0000 - val_loss: 1.3350 - val_auc: 0.7237\n",
      "Epoch 217/1000\n",
      "6/6 [==============================] - 1s 84ms/step - loss: 0.1773 - auc: 1.0000 - val_loss: 1.3270 - val_auc: 0.7295\n",
      "Epoch 218/1000\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.2010 - auc: 1.0000 - val_loss: 1.3062 - val_auc: 0.7388\n",
      "Epoch 219/1000\n",
      "6/6 [==============================] - 1s 84ms/step - loss: 0.1965 - auc: 0.9999 - val_loss: 1.3045 - val_auc: 0.7416\n",
      "Epoch 220/1000\n",
      "6/6 [==============================] - 0s 65ms/step - loss: 0.1945 - auc: 0.9999 - val_loss: 1.3345 - val_auc: 0.7296\n",
      "Epoch 221/1000\n",
      "6/6 [==============================] - 1s 95ms/step - loss: 0.1762 - auc: 1.0000 - val_loss: 1.3238 - val_auc: 0.7319\n",
      "Epoch 222/1000\n",
      "6/6 [==============================] - 0s 69ms/step - loss: 0.1869 - auc: 1.0000 - val_loss: 1.3969 - val_auc: 0.6986\n",
      "Epoch 223/1000\n",
      "6/6 [==============================] - 1s 90ms/step - loss: 0.1835 - auc: 1.0000 - val_loss: 1.7050 - val_auc: 0.6136\n",
      "Epoch 224/1000\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.1906 - auc: 1.0000 - val_loss: 1.3798 - val_auc: 0.7180\n",
      "Epoch 225/1000\n",
      "6/6 [==============================] - 1s 133ms/step - loss: 0.1917 - auc: 0.9999 - val_loss: 1.4131 - val_auc: 0.6938\n",
      "Epoch 226/1000\n",
      "6/6 [==============================] - 1s 151ms/step - loss: 0.1948 - auc: 1.0000 - val_loss: 1.9682 - val_auc: 0.5755\n",
      "Epoch 227/1000\n",
      "6/6 [==============================] - 1s 89ms/step - loss: 0.2011 - auc: 1.0000 - val_loss: 1.5413 - val_auc: 0.6528\n",
      "Epoch 228/1000\n",
      "6/6 [==============================] - 0s 82ms/step - loss: 0.1727 - auc: 1.0000 - val_loss: 1.2555 - val_auc: 0.7674\n",
      "Epoch 229/1000\n",
      "6/6 [==============================] - 1s 96ms/step - loss: 0.1841 - auc: 1.0000 - val_loss: 1.2896 - val_auc: 0.7534\n",
      "Epoch 230/1000\n",
      "6/6 [==============================] - 0s 83ms/step - loss: 0.1911 - auc: 1.0000 - val_loss: 1.3412 - val_auc: 0.7307\n",
      "Epoch 231/1000\n",
      "6/6 [==============================] - 1s 85ms/step - loss: 0.1884 - auc: 0.9999 - val_loss: 1.3251 - val_auc: 0.7382\n",
      "Epoch 232/1000\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 0.1699 - auc: 1.0000 - val_loss: 1.3103 - val_auc: 0.7537\n",
      "Epoch 233/1000\n",
      "6/6 [==============================] - 1s 110ms/step - loss: 0.1647 - auc: 1.0000 - val_loss: 1.3104 - val_auc: 0.7488\n",
      "Epoch 234/1000\n",
      "6/6 [==============================] - 0s 74ms/step - loss: 0.1898 - auc: 1.0000 - val_loss: 1.4324 - val_auc: 0.6831\n",
      "Epoch 235/1000\n",
      "6/6 [==============================] - 0s 69ms/step - loss: 0.1676 - auc: 1.0000 - val_loss: 1.5079 - val_auc: 0.6633\n",
      "Epoch 236/1000\n",
      "6/6 [==============================] - 0s 81ms/step - loss: 0.1693 - auc: 1.0000 - val_loss: 1.3723 - val_auc: 0.7200\n",
      "Epoch 237/1000\n",
      "6/6 [==============================] - 1s 96ms/step - loss: 0.1639 - auc: 1.0000 - val_loss: 1.2761 - val_auc: 0.7578\n",
      "Epoch 238/1000\n",
      "6/6 [==============================] - 1s 175ms/step - loss: 0.1661 - auc: 1.0000 - val_loss: 1.3056 - val_auc: 0.7435\n",
      "Epoch 239/1000\n",
      "6/6 [==============================] - 1s 119ms/step - loss: 0.1706 - auc: 1.0000 - val_loss: 1.3279 - val_auc: 0.7384\n",
      "Epoch 240/1000\n",
      "6/6 [==============================] - 1s 111ms/step - loss: 0.1658 - auc: 1.0000 - val_loss: 1.2778 - val_auc: 0.7587\n",
      "Epoch 241/1000\n",
      "6/6 [==============================] - 1s 97ms/step - loss: 0.1938 - auc: 1.0000 - val_loss: 1.3117 - val_auc: 0.7392\n",
      "Epoch 242/1000\n",
      "6/6 [==============================] - 1s 114ms/step - loss: 0.1709 - auc: 1.0000 - val_loss: 1.4062 - val_auc: 0.7017\n",
      "Epoch 243/1000\n",
      "6/6 [==============================] - 1s 95ms/step - loss: 0.1591 - auc: 1.0000 - val_loss: 1.3675 - val_auc: 0.7262\n",
      "Epoch 244/1000\n",
      "6/6 [==============================] - 1s 91ms/step - loss: 0.1853 - auc: 0.9999 - val_loss: 1.2824 - val_auc: 0.7742\n",
      "Epoch 245/1000\n",
      "6/6 [==============================] - 1s 90ms/step - loss: 0.1842 - auc: 0.9999 - val_loss: 1.3499 - val_auc: 0.7335\n",
      "Epoch 246/1000\n",
      "6/6 [==============================] - 0s 78ms/step - loss: 0.1612 - auc: 1.0000 - val_loss: 1.4215 - val_auc: 0.6959\n",
      "Epoch 247/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 97ms/step - loss: 0.1621 - auc: 1.0000 - val_loss: 1.4756 - val_auc: 0.7102\n",
      "Epoch 248/1000\n",
      "6/6 [==============================] - 1s 113ms/step - loss: 0.1796 - auc: 1.0000 - val_loss: 1.5195 - val_auc: 0.6580\n",
      "Epoch 249/1000\n",
      "6/6 [==============================] - 1s 87ms/step - loss: 0.1630 - auc: 1.0000 - val_loss: 1.6649 - val_auc: 0.6161\n",
      "Epoch 250/1000\n",
      "6/6 [==============================] - 1s 90ms/step - loss: 0.1773 - auc: 1.0000 - val_loss: 1.4921 - val_auc: 0.6783\n",
      "Epoch 251/1000\n",
      "6/6 [==============================] - 0s 70ms/step - loss: 0.1607 - auc: 1.0000 - val_loss: 1.2905 - val_auc: 0.7609\n",
      "Epoch 252/1000\n",
      "6/6 [==============================] - 0s 83ms/step - loss: 0.1646 - auc: 1.0000 - val_loss: 1.2483 - val_auc: 0.7699\n",
      "Epoch 253/1000\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 0.1662 - auc: 1.0000 - val_loss: 1.3065 - val_auc: 0.7541\n",
      "Epoch 254/1000\n",
      "6/6 [==============================] - 0s 80ms/step - loss: 0.1638 - auc: 1.0000 - val_loss: 1.3134 - val_auc: 0.7542\n",
      "Epoch 255/1000\n",
      "6/6 [==============================] - 0s 71ms/step - loss: 0.1612 - auc: 1.0000 - val_loss: 1.3234 - val_auc: 0.7453\n",
      "Epoch 256/1000\n",
      "6/6 [==============================] - 1s 85ms/step - loss: 0.1810 - auc: 0.9998 - val_loss: 1.3267 - val_auc: 0.7430\n",
      "Epoch 257/1000\n",
      "6/6 [==============================] - 0s 72ms/step - loss: 0.1580 - auc: 1.0000 - val_loss: 1.2971 - val_auc: 0.7518\n",
      "Epoch 258/1000\n",
      "6/6 [==============================] - 0s 70ms/step - loss: 0.1673 - auc: 1.0000 - val_loss: 1.3458 - val_auc: 0.7321\n",
      "Epoch 259/1000\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.1606 - auc: 1.0000 - val_loss: 1.3926 - val_auc: 0.7079\n",
      "Epoch 260/1000\n",
      "6/6 [==============================] - 1s 84ms/step - loss: 0.1475 - auc: 1.0000 - val_loss: 1.3358 - val_auc: 0.7333\n",
      "Epoch 261/1000\n",
      "6/6 [==============================] - 1s 101ms/step - loss: 0.1551 - auc: 1.0000 - val_loss: 1.3079 - val_auc: 0.7463\n",
      "Epoch 262/1000\n",
      "6/6 [==============================] - 1s 178ms/step - loss: 0.1626 - auc: 1.0000 - val_loss: 1.3140 - val_auc: 0.7427\n",
      "Epoch 263/1000\n",
      "6/6 [==============================] - 1s 185ms/step - loss: 0.1552 - auc: 1.0000 - val_loss: 1.3539 - val_auc: 0.7311\n",
      "Epoch 264/1000\n",
      "6/6 [==============================] - 1s 183ms/step - loss: 0.1542 - auc: 1.0000 - val_loss: 1.3884 - val_auc: 0.7233\n",
      "Epoch 265/1000\n",
      "6/6 [==============================] - 1s 131ms/step - loss: 0.1416 - auc: 1.0000 - val_loss: 1.3416 - val_auc: 0.7357\n",
      "Epoch 266/1000\n",
      "6/6 [==============================] - 1s 144ms/step - loss: 0.1476 - auc: 1.0000 - val_loss: 1.3102 - val_auc: 0.7423\n",
      "Epoch 267/1000\n",
      "6/6 [==============================] - 1s 126ms/step - loss: 0.1519 - auc: 1.0000 - val_loss: 1.2943 - val_auc: 0.7552\n",
      "Epoch 268/1000\n",
      "6/6 [==============================] - 1s 145ms/step - loss: 0.1773 - auc: 0.9997 - val_loss: 1.2977 - val_auc: 0.7540\n",
      "Epoch 269/1000\n",
      "6/6 [==============================] - 1s 139ms/step - loss: 0.1568 - auc: 1.0000 - val_loss: 1.5717 - val_auc: 0.6453\n",
      "Epoch 270/1000\n",
      "6/6 [==============================] - 1s 104ms/step - loss: 0.1736 - auc: 1.0000 - val_loss: 1.7087 - val_auc: 0.6103\n",
      "Epoch 271/1000\n",
      "6/6 [==============================] - 1s 98ms/step - loss: 0.1526 - auc: 1.0000 - val_loss: 1.4955 - val_auc: 0.6696\n",
      "Epoch 272/1000\n",
      "6/6 [==============================] - 1s 100ms/step - loss: 0.1470 - auc: 1.0000 - val_loss: 1.2631 - val_auc: 0.7660\n",
      "Epoch 273/1000\n",
      "6/6 [==============================] - 0s 71ms/step - loss: 0.1508 - auc: 1.0000 - val_loss: 1.2598 - val_auc: 0.7695\n",
      "Epoch 274/1000\n",
      "6/6 [==============================] - 1s 94ms/step - loss: 0.1443 - auc: 1.0000 - val_loss: 1.3074 - val_auc: 0.7449\n",
      "Epoch 275/1000\n",
      "6/6 [==============================] - 0s 68ms/step - loss: 0.1371 - auc: 1.0000 - val_loss: 1.3442 - val_auc: 0.7309\n",
      "Epoch 276/1000\n",
      "6/6 [==============================] - 1s 92ms/step - loss: 0.1506 - auc: 1.0000 - val_loss: 1.2912 - val_auc: 0.7489\n",
      "Epoch 277/1000\n",
      "6/6 [==============================] - 1s 129ms/step - loss: 0.1385 - auc: 1.0000 - val_loss: 1.2970 - val_auc: 0.7494\n",
      "Epoch 278/1000\n",
      "6/6 [==============================] - 1s 148ms/step - loss: 0.1372 - auc: 1.0000 - val_loss: 1.3119 - val_auc: 0.7439\n",
      "Epoch 279/1000\n",
      "6/6 [==============================] - 0s 76ms/step - loss: 0.1433 - auc: 1.0000 - val_loss: 1.3296 - val_auc: 0.7390\n",
      "Epoch 280/1000\n",
      "6/6 [==============================] - 1s 121ms/step - loss: 0.1422 - auc: 1.0000 - val_loss: 1.3262 - val_auc: 0.7418\n",
      "Epoch 281/1000\n",
      "6/6 [==============================] - 1s 104ms/step - loss: 0.1413 - auc: 1.0000 - val_loss: 1.2960 - val_auc: 0.7532\n",
      "Epoch 282/1000\n",
      "6/6 [==============================] - 1s 89ms/step - loss: 0.1487 - auc: 1.0000 - val_loss: 1.3087 - val_auc: 0.7456\n",
      "Epoch 283/1000\n",
      "6/6 [==============================] - 1s 111ms/step - loss: 0.1623 - auc: 1.0000 - val_loss: 1.3252 - val_auc: 0.7426\n",
      "Epoch 284/1000\n",
      "6/6 [==============================] - 1s 85ms/step - loss: 0.1548 - auc: 1.0000 - val_loss: 1.3350 - val_auc: 0.7431\n",
      "Epoch 285/1000\n",
      "6/6 [==============================] - 1s 97ms/step - loss: 0.1475 - auc: 1.0000 - val_loss: 1.5206 - val_auc: 0.6791\n",
      "Epoch 286/1000\n",
      "6/6 [==============================] - 1s 105ms/step - loss: 0.1682 - auc: 1.0000 - val_loss: 2.2242 - val_auc: 0.6165\n",
      "Epoch 287/1000\n",
      "6/6 [==============================] - 1s 96ms/step - loss: 0.2224 - auc: 0.9985 - val_loss: 1.9214 - val_auc: 0.6434\n",
      "Epoch 288/1000\n",
      "6/6 [==============================] - 1s 110ms/step - loss: 0.1687 - auc: 0.9999 - val_loss: 1.4536 - val_auc: 0.7118\n",
      "Epoch 289/1000\n",
      "6/6 [==============================] - 1s 111ms/step - loss: 0.1481 - auc: 1.0000 - val_loss: 1.6512 - val_auc: 0.6466\n",
      "Epoch 290/1000\n",
      "6/6 [==============================] - 1s 85ms/step - loss: 0.1632 - auc: 1.0000 - val_loss: 1.8968 - val_auc: 0.5565\n",
      "Epoch 291/1000\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 0.1705 - auc: 1.0000 - val_loss: 1.7010 - val_auc: 0.6108\n",
      "Epoch 292/1000\n",
      "6/6 [==============================] - 1s 97ms/step - loss: 0.1555 - auc: 1.0000 - val_loss: 1.4031 - val_auc: 0.7128\n",
      "Epoch 293/1000\n",
      "6/6 [==============================] - 0s 78ms/step - loss: 0.1674 - auc: 1.0000 - val_loss: 1.3619 - val_auc: 0.7147\n",
      "Epoch 294/1000\n",
      "6/6 [==============================] - 1s 107ms/step - loss: 0.1452 - auc: 1.0000 - val_loss: 1.3569 - val_auc: 0.7165\n",
      "Epoch 295/1000\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.1420 - auc: 1.0000 - val_loss: 1.3591 - val_auc: 0.7622\n",
      "Epoch 296/1000\n",
      "6/6 [==============================] - 1s 94ms/step - loss: 0.1436 - auc: 1.0000 - val_loss: 1.3005 - val_auc: 0.7537\n",
      "Epoch 297/1000\n",
      "6/6 [==============================] - 0s 62ms/step - loss: 0.1440 - auc: 1.0000 - val_loss: 1.3655 - val_auc: 0.7280\n",
      "Epoch 298/1000\n",
      "6/6 [==============================] - 1s 103ms/step - loss: 0.1451 - auc: 1.0000 - val_loss: 1.3572 - val_auc: 0.7359\n",
      "Epoch 299/1000\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 0.1478 - auc: 1.0000 - val_loss: 1.3352 - val_auc: 0.7502\n",
      "Epoch 300/1000\n",
      "6/6 [==============================] - 1s 92ms/step - loss: 0.1358 - auc: 1.0000 - val_loss: 1.3471 - val_auc: 0.7326\n",
      "Epoch 301/1000\n",
      "6/6 [==============================] - 0s 66ms/step - loss: 0.1627 - auc: 0.9999 - val_loss: 1.3305 - val_auc: 0.7462\n",
      "Epoch 302/1000\n",
      "6/6 [==============================] - 1s 127ms/step - loss: 0.1573 - auc: 1.0000 - val_loss: 1.3228 - val_auc: 0.7575\n",
      "Epoch 303/1000\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1329 - auc: 1.000 - 1s 89ms/step - loss: 0.1338 - auc: 1.0000 - val_loss: 1.3068 - val_auc: 0.7565\n",
      "Epoch 304/1000\n",
      "6/6 [==============================] - 1s 108ms/step - loss: 0.1479 - auc: 0.9999 - val_loss: 1.2858 - val_auc: 0.7686\n",
      "Epoch 305/1000\n",
      "6/6 [==============================] - 1s 92ms/step - loss: 0.1385 - auc: 1.0000 - val_loss: 1.3309 - val_auc: 0.7533\n",
      "Epoch 306/1000\n",
      "6/6 [==============================] - 0s 66ms/step - loss: 0.1272 - auc: 1.0000 - val_loss: 1.4932 - val_auc: 0.6848\n",
      "Epoch 307/1000\n",
      "6/6 [==============================] - 1s 85ms/step - loss: 0.1396 - auc: 1.0000 - val_loss: 1.5081 - val_auc: 0.6813\n",
      "Epoch 308/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 55ms/step - loss: 0.1500 - auc: 1.0000 - val_loss: 1.4274 - val_auc: 0.7035\n",
      "Epoch 309/1000\n",
      "6/6 [==============================] - 1s 108ms/step - loss: 0.1370 - auc: 1.0000 - val_loss: 1.4077 - val_auc: 0.7180\n",
      "Epoch 310/1000\n",
      "6/6 [==============================] - 1s 97ms/step - loss: 0.1383 - auc: 1.0000 - val_loss: 1.4902 - val_auc: 0.6818\n",
      "Epoch 311/1000\n",
      "6/6 [==============================] - 1s 97ms/step - loss: 0.1424 - auc: 1.0000 - val_loss: 1.3808 - val_auc: 0.7344\n",
      "Epoch 312/1000\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.1330 - auc: 1.0000 - val_loss: 1.3209 - val_auc: 0.7510\n",
      "Epoch 313/1000\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 0.1400 - auc: 1.0000 - val_loss: 1.3108 - val_auc: 0.7591\n",
      "Epoch 314/1000\n",
      "6/6 [==============================] - 1s 88ms/step - loss: 0.1347 - auc: 1.0000 - val_loss: 1.3248 - val_auc: 0.7558\n",
      "Epoch 315/1000\n",
      "6/6 [==============================] - 0s 71ms/step - loss: 0.1439 - auc: 0.9999 - val_loss: 1.3265 - val_auc: 0.7540\n",
      "Epoch 316/1000\n",
      "6/6 [==============================] - 1s 114ms/step - loss: 0.1288 - auc: 1.0000 - val_loss: 1.3265 - val_auc: 0.7521\n",
      "Epoch 317/1000\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 0.1378 - auc: 1.0000 - val_loss: 1.3343 - val_auc: 0.7471\n",
      "Epoch 318/1000\n",
      "6/6 [==============================] - 1s 89ms/step - loss: 0.1511 - auc: 0.9999 - val_loss: 1.3741 - val_auc: 0.7366\n",
      "Epoch 319/1000\n",
      "6/6 [==============================] - 0s 62ms/step - loss: 0.1234 - auc: 1.0000 - val_loss: 1.5686 - val_auc: 0.6783\n",
      "Epoch 320/1000\n",
      "6/6 [==============================] - 1s 109ms/step - loss: 0.1484 - auc: 1.0000 - val_loss: 1.5193 - val_auc: 0.6823\n",
      "Epoch 321/1000\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.1506 - auc: 0.9999 - val_loss: 1.3516 - val_auc: 0.7321\n",
      "Epoch 322/1000\n",
      "6/6 [==============================] - 1s 85ms/step - loss: 0.1358 - auc: 1.0000 - val_loss: 1.3979 - val_auc: 0.7184\n",
      "Epoch 323/1000\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 0.1293 - auc: 1.0000 - val_loss: 1.4149 - val_auc: 0.7273\n",
      "Epoch 324/1000\n",
      "6/6 [==============================] - 1s 145ms/step - loss: 0.1285 - auc: 1.0000 - val_loss: 1.3879 - val_auc: 0.7400\n",
      "Epoch 325/1000\n",
      "6/6 [==============================] - 1s 112ms/step - loss: 0.1262 - auc: 1.0000 - val_loss: 1.3485 - val_auc: 0.7530\n",
      "Epoch 326/1000\n",
      "6/6 [==============================] - 1s 117ms/step - loss: 0.1174 - auc: 1.0000 - val_loss: 1.3752 - val_auc: 0.7342\n",
      "Epoch 327/1000\n",
      "6/6 [==============================] - 1s 85ms/step - loss: 0.1190 - auc: 1.0000 - val_loss: 1.4171 - val_auc: 0.7284\n",
      "Epoch 328/1000\n",
      "6/6 [==============================] - 1s 100ms/step - loss: 0.1225 - auc: 1.0000 - val_loss: 1.4084 - val_auc: 0.7397\n",
      "Epoch 329/1000\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.1293 - auc: 1.0000 - val_loss: 1.4128 - val_auc: 0.7376\n",
      "Epoch 330/1000\n",
      "6/6 [==============================] - 0s 83ms/step - loss: 0.1327 - auc: 1.0000 - val_loss: 1.5583 - val_auc: 0.6892\n",
      "Epoch 331/1000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.1275 - auc: 1.0000 - val_loss: 1.4934 - val_auc: 0.6995\n",
      "Epoch 332/1000\n",
      "6/6 [==============================] - 0s 73ms/step - loss: 0.1286 - auc: 1.0000 - val_loss: 1.3993 - val_auc: 0.7176\n",
      "Epoch 333/1000\n",
      "6/6 [==============================] - 0s 66ms/step - loss: 0.1205 - auc: 1.0000 - val_loss: 1.3047 - val_auc: 0.7584\n",
      "Epoch 334/1000\n",
      "6/6 [==============================] - 1s 90ms/step - loss: 0.1322 - auc: 1.0000 - val_loss: 1.3231 - val_auc: 0.7493\n",
      "Epoch 335/1000\n",
      "6/6 [==============================] - 0s 66ms/step - loss: 0.1214 - auc: 1.0000 - val_loss: 1.4283 - val_auc: 0.7154\n",
      "Epoch 336/1000\n",
      "6/6 [==============================] - 1s 114ms/step - loss: 0.1267 - auc: 1.0000 - val_loss: 1.3600 - val_auc: 0.7384\n",
      "Epoch 337/1000\n",
      "6/6 [==============================] - 0s 65ms/step - loss: 0.1516 - auc: 0.9999 - val_loss: 1.3523 - val_auc: 0.7523\n",
      "Epoch 338/1000\n",
      "6/6 [==============================] - 1s 121ms/step - loss: 0.1196 - auc: 1.0000 - val_loss: 1.3772 - val_auc: 0.7386\n",
      "Epoch 339/1000\n",
      "6/6 [==============================] - 1s 94ms/step - loss: 0.1199 - auc: 1.0000 - val_loss: 1.4310 - val_auc: 0.7219\n",
      "Epoch 340/1000\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.1173 - auc: 1.0000 - val_loss: 1.4016 - val_auc: 0.7341\n",
      "Epoch 341/1000\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.1202 - auc: 1.0000 - val_loss: 1.3939 - val_auc: 0.7397\n",
      "Epoch 342/1000\n",
      "6/6 [==============================] - 0s 72ms/step - loss: 0.1292 - auc: 1.0000 - val_loss: 1.3902 - val_auc: 0.7406\n",
      "Epoch 343/1000\n",
      "6/6 [==============================] - 1s 165ms/step - loss: 0.1225 - auc: 1.0000 - val_loss: 1.3780 - val_auc: 0.7527\n",
      "Epoch 344/1000\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 0.1262 - auc: 1.0000 - val_loss: 1.3722 - val_auc: 0.7579\n",
      "Epoch 345/1000\n",
      "6/6 [==============================] - 1s 100ms/step - loss: 0.1311 - auc: 1.0000 - val_loss: 1.4129 - val_auc: 0.7413\n",
      "Epoch 346/1000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.1470 - auc: 1.0000 - val_loss: 1.3962 - val_auc: 0.7452\n",
      "Epoch 347/1000\n",
      "6/6 [==============================] - 1s 99ms/step - loss: 0.1158 - auc: 1.0000 - val_loss: 1.4056 - val_auc: 0.7411\n",
      "Epoch 348/1000\n",
      "6/6 [==============================] - 1s 114ms/step - loss: 0.1215 - auc: 1.0000 - val_loss: 1.4344 - val_auc: 0.7313\n",
      "Epoch 349/1000\n",
      "6/6 [==============================] - 0s 66ms/step - loss: 0.1329 - auc: 1.0000 - val_loss: 1.4696 - val_auc: 0.7135\n",
      "Epoch 350/1000\n",
      "6/6 [==============================] - 1s 92ms/step - loss: 0.1143 - auc: 1.0000 - val_loss: 1.5005 - val_auc: 0.7027\n",
      "Epoch 351/1000\n",
      "6/6 [==============================] - 0s 68ms/step - loss: 0.1319 - auc: 0.9999 - val_loss: 1.4357 - val_auc: 0.7258\n",
      "Epoch 352/1000\n",
      "6/6 [==============================] - 1s 121ms/step - loss: 0.1180 - auc: 1.0000 - val_loss: 1.4023 - val_auc: 0.7440\n",
      "Epoch 353/1000\n",
      "6/6 [==============================] - 0s 72ms/step - loss: 0.1164 - auc: 1.0000 - val_loss: 1.4341 - val_auc: 0.7305\n",
      "Epoch 354/1000\n",
      "6/6 [==============================] - 1s 90ms/step - loss: 0.1160 - auc: 1.0000 - val_loss: 1.4308 - val_auc: 0.7312\n",
      "Epoch 355/1000\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 0.1142 - auc: 1.0000 - val_loss: 1.4052 - val_auc: 0.7406\n",
      "Epoch 356/1000\n",
      "6/6 [==============================] - 0s 74ms/step - loss: 0.1149 - auc: 1.0000 - val_loss: 1.4583 - val_auc: 0.7213\n",
      "Epoch 357/1000\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.1143 - auc: 1.0000 - val_loss: 1.5067 - val_auc: 0.7059\n",
      "Epoch 358/1000\n",
      "6/6 [==============================] - 1s 91ms/step - loss: 0.1427 - auc: 1.0000 - val_loss: 1.4397 - val_auc: 0.7228\n",
      "Epoch 359/1000\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.1210 - auc: 1.0000 - val_loss: 1.4181 - val_auc: 0.7319\n",
      "Epoch 360/1000\n",
      "6/6 [==============================] - 1s 88ms/step - loss: 0.1255 - auc: 0.9999 - val_loss: 1.4077 - val_auc: 0.7372\n",
      "Epoch 361/1000\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.1185 - auc: 1.0000 - val_loss: 1.4046 - val_auc: 0.7384\n",
      "Epoch 362/1000\n",
      "6/6 [==============================] - 1s 101ms/step - loss: 0.1061 - auc: 1.0000 - val_loss: 1.4952 - val_auc: 0.6986\n",
      "Epoch 363/1000\n",
      "6/6 [==============================] - 0s 71ms/step - loss: 0.1171 - auc: 1.0000 - val_loss: 1.4324 - val_auc: 0.7244\n",
      "Epoch 364/1000\n",
      "6/6 [==============================] - 1s 89ms/step - loss: 0.1376 - auc: 0.9999 - val_loss: 1.5102 - val_auc: 0.7448\n",
      "Epoch 365/1000\n",
      "6/6 [==============================] - 0s 70ms/step - loss: 0.1133 - auc: 1.0000 - val_loss: 1.4510 - val_auc: 0.7404\n",
      "Epoch 366/1000\n",
      "6/6 [==============================] - 0s 80ms/step - loss: 0.1248 - auc: 1.0000 - val_loss: 1.4129 - val_auc: 0.7291\n",
      "Epoch 367/1000\n",
      "6/6 [==============================] - 0s 77ms/step - loss: 0.1262 - auc: 1.0000 - val_loss: 1.3901 - val_auc: 0.7428\n",
      "Epoch 368/1000\n",
      "6/6 [==============================] - 0s 68ms/step - loss: 0.1062 - auc: 1.0000 - val_loss: 1.3866 - val_auc: 0.7493\n",
      "Epoch 369/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 60ms/step - loss: 0.1075 - auc: 1.0000 - val_loss: 1.4190 - val_auc: 0.7291\n",
      "Epoch 370/1000\n",
      "6/6 [==============================] - 0s 69ms/step - loss: 0.1103 - auc: 1.0000 - val_loss: 1.4615 - val_auc: 0.7150\n",
      "Epoch 371/1000\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.1102 - auc: 1.0000 - val_loss: 1.4420 - val_auc: 0.7275\n",
      "Epoch 372/1000\n",
      "6/6 [==============================] - 1s 118ms/step - loss: 0.1088 - auc: 1.0000 - val_loss: 1.4260 - val_auc: 0.7326\n",
      "Epoch 373/1000\n",
      "6/6 [==============================] - 1s 113ms/step - loss: 0.1125 - auc: 1.0000 - val_loss: 1.4520 - val_auc: 0.7243\n",
      "Epoch 374/1000\n",
      "6/6 [==============================] - 1s 164ms/step - loss: 0.1073 - auc: 1.0000 - val_loss: 1.4370 - val_auc: 0.7251\n",
      "Epoch 375/1000\n",
      "6/6 [==============================] - 1s 133ms/step - loss: 0.1110 - auc: 1.0000 - val_loss: 1.4200 - val_auc: 0.7396\n",
      "Epoch 376/1000\n",
      "6/6 [==============================] - 1s 106ms/step - loss: 0.1450 - auc: 0.9998 - val_loss: 1.8125 - val_auc: 0.6209\n",
      "Epoch 377/1000\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 0.1333 - auc: 1.0000 - val_loss: 1.7029 - val_auc: 0.6428\n",
      "Epoch 378/1000\n",
      "6/6 [==============================] - 1s 90ms/step - loss: 0.1120 - auc: 1.0000 - val_loss: 1.4589 - val_auc: 0.7260\n",
      "Epoch 379/1000\n",
      "6/6 [==============================] - 0s 70ms/step - loss: 0.1369 - auc: 0.9999 - val_loss: 1.4474 - val_auc: 0.7319\n",
      "Epoch 380/1000\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 0.1060 - auc: 1.0000 - val_loss: 1.5289 - val_auc: 0.6998\n",
      "Epoch 381/1000\n",
      "6/6 [==============================] - 0s 66ms/step - loss: 0.1132 - auc: 1.0000 - val_loss: 1.5015 - val_auc: 0.7123\n",
      "Epoch 382/1000\n",
      "6/6 [==============================] - 0s 72ms/step - loss: 0.1096 - auc: 1.0000 - val_loss: 1.4461 - val_auc: 0.7310\n",
      "Epoch 383/1000\n",
      "6/6 [==============================] - 0s 70ms/step - loss: 0.1075 - auc: 1.0000 - val_loss: 1.4610 - val_auc: 0.7343\n",
      "Epoch 384/1000\n",
      "6/6 [==============================] - 1s 83ms/step - loss: 0.1069 - auc: 1.0000 - val_loss: 1.4354 - val_auc: 0.7360\n",
      "Epoch 385/1000\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.1170 - auc: 1.0000 - val_loss: 1.4422 - val_auc: 0.7372\n",
      "Epoch 386/1000\n",
      "6/6 [==============================] - 0s 75ms/step - loss: 0.1105 - auc: 1.0000 - val_loss: 1.4591 - val_auc: 0.7310\n",
      "Epoch 387/1000\n",
      "6/6 [==============================] - 0s 80ms/step - loss: 0.1114 - auc: 1.0000 - val_loss: 1.4911 - val_auc: 0.7197\n",
      "Epoch 388/1000\n",
      "6/6 [==============================] - 1s 83ms/step - loss: 0.1141 - auc: 1.0000 - val_loss: 1.4920 - val_auc: 0.7215\n",
      "Epoch 389/1000\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.1237 - auc: 1.0000 - val_loss: 1.5168 - val_auc: 0.7158\n",
      "Epoch 390/1000\n",
      "6/6 [==============================] - 0s 73ms/step - loss: 0.1038 - auc: 1.0000 - val_loss: 1.5076 - val_auc: 0.7177\n",
      "Epoch 391/1000\n",
      "6/6 [==============================] - 0s 75ms/step - loss: 0.1208 - auc: 1.0000 - val_loss: 1.4913 - val_auc: 0.7230\n",
      "Epoch 392/1000\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.1030 - auc: 1.0000 - val_loss: 1.5163 - val_auc: 0.7118\n",
      "Epoch 393/1000\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.1048 - auc: 1.0000 - val_loss: 1.4964 - val_auc: 0.7204\n",
      "Epoch 394/1000\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.1015 - auc: 1.0000 - val_loss: 1.5057 - val_auc: 0.7204\n",
      "Epoch 395/1000\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 0.1200 - auc: 0.9999 - val_loss: 1.5121 - val_auc: 0.7182\n",
      "Epoch 396/1000\n",
      "6/6 [==============================] - 0s 72ms/step - loss: 0.0997 - auc: 1.0000 - val_loss: 1.5286 - val_auc: 0.7164\n",
      "Epoch 397/1000\n",
      "6/6 [==============================] - 1s 127ms/step - loss: 0.0991 - auc: 1.0000 - val_loss: 1.5065 - val_auc: 0.7154\n",
      "Epoch 398/1000\n",
      "6/6 [==============================] - 1s 112ms/step - loss: 0.1027 - auc: 1.0000 - val_loss: 1.5070 - val_auc: 0.7169\n",
      "Epoch 399/1000\n",
      "6/6 [==============================] - 1s 89ms/step - loss: 0.1043 - auc: 1.0000 - val_loss: 1.6023 - val_auc: 0.6959\n",
      "Epoch 400/1000\n",
      "6/6 [==============================] - 1s 101ms/step - loss: 0.1063 - auc: 1.0000 - val_loss: 1.6045 - val_auc: 0.6939\n",
      "Epoch 401/1000\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.0996 - auc: 1.0000 - val_loss: 1.5146 - val_auc: 0.7353\n",
      "Epoch 402/1000\n",
      "6/6 [==============================] - 0s 82ms/step - loss: 0.1156 - auc: 1.0000 - val_loss: 1.5211 - val_auc: 0.7081\n",
      "Epoch 403/1000\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 0.0998 - auc: 1.0000 - val_loss: 1.5890 - val_auc: 0.7068\n",
      "Epoch 404/1000\n",
      "6/6 [==============================] - 1s 94ms/step - loss: 0.1161 - auc: 1.0000 - val_loss: 1.4777 - val_auc: 0.7512\n",
      "Epoch 405/1000\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 0.1155 - auc: 1.0000 - val_loss: 1.5385 - val_auc: 0.7324\n",
      "Epoch 406/1000\n",
      "6/6 [==============================] - 1s 142ms/step - loss: 0.1151 - auc: 1.0000 - val_loss: 1.7733 - val_auc: 0.6622\n",
      "Epoch 407/1000\n",
      "6/6 [==============================] - 1s 94ms/step - loss: 0.1192 - auc: 1.0000 - val_loss: 1.7781 - val_auc: 0.6678\n",
      "Epoch 408/1000\n",
      "6/6 [==============================] - 1s 101ms/step - loss: 0.1139 - auc: 1.0000 - val_loss: 1.6226 - val_auc: 0.7470\n",
      "Epoch 409/1000\n",
      "6/6 [==============================] - 1s 90ms/step - loss: 0.1024 - auc: 1.0000 - val_loss: 1.5764 - val_auc: 0.7010\n",
      "Epoch 410/1000\n",
      "6/6 [==============================] - 0s 80ms/step - loss: 0.1175 - auc: 1.0000 - val_loss: 1.5179 - val_auc: 0.7182\n",
      "Epoch 411/1000\n",
      "6/6 [==============================] - 1s 135ms/step - loss: 0.1109 - auc: 1.0000 - val_loss: 1.4177 - val_auc: 0.7505\n",
      "Epoch 412/1000\n",
      "6/6 [==============================] - 1s 134ms/step - loss: 0.1043 - auc: 1.0000 - val_loss: 1.3945 - val_auc: 0.7650\n",
      "Epoch 413/1000\n",
      "6/6 [==============================] - 1s 95ms/step - loss: 0.1035 - auc: 1.0000 - val_loss: 1.4474 - val_auc: 0.7487\n",
      "Epoch 414/1000\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 0.0997 - auc: 1.0000 - val_loss: 1.4857 - val_auc: 0.7388\n",
      "Epoch 415/1000\n",
      "6/6 [==============================] - 1s 90ms/step - loss: 0.1194 - auc: 0.9999 - val_loss: 1.4671 - val_auc: 0.7406\n",
      "Epoch 416/1000\n",
      "6/6 [==============================] - 0s 76ms/step - loss: 0.1071 - auc: 1.0000 - val_loss: 1.4605 - val_auc: 0.7497\n",
      "Epoch 417/1000\n",
      "6/6 [==============================] - 1s 97ms/step - loss: 0.1110 - auc: 1.0000 - val_loss: 1.4958 - val_auc: 0.7282\n",
      "Epoch 418/1000\n",
      "6/6 [==============================] - 0s 69ms/step - loss: 0.1072 - auc: 1.0000 - val_loss: 1.4682 - val_auc: 0.7399\n",
      "Epoch 419/1000\n",
      "6/6 [==============================] - 0s 62ms/step - loss: 0.1021 - auc: 1.0000 - val_loss: 1.6871 - val_auc: 0.6583\n",
      "Epoch 420/1000\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.1473 - auc: 0.9986 - val_loss: 2.3346 - val_auc: 0.6314\n",
      "Epoch 421/1000\n",
      "6/6 [==============================] - 1s 89ms/step - loss: 0.3378 - auc: 0.9786 - val_loss: 1.4219 - val_auc: 0.7043\n",
      "Epoch 422/1000\n",
      "6/6 [==============================] - 0s 70ms/step - loss: 0.2554 - auc: 0.9948 - val_loss: 1.8775 - val_auc: 0.6628\n",
      "Epoch 423/1000\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 0.2115 - auc: 0.9992 - val_loss: 1.7959 - val_auc: 0.6665\n",
      "Epoch 424/1000\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.2083 - auc: 0.9995 - val_loss: 1.5800 - val_auc: 0.6981\n",
      "Epoch 425/1000\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 0.1731 - auc: 0.9996 - val_loss: 1.6503 - val_auc: 0.6677\n",
      "Epoch 426/1000\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 0.1635 - auc: 0.9987 - val_loss: 1.6619 - val_auc: 0.6547\n",
      "Epoch 427/1000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.1416 - auc: 0.9999 - val_loss: 1.5318 - val_auc: 0.7057\n",
      "Epoch 428/1000\n",
      "6/6 [==============================] - 0s 75ms/step - loss: 0.1419 - auc: 0.9998 - val_loss: 1.5056 - val_auc: 0.7317\n",
      "Epoch 429/1000\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.1147 - auc: 1.0000 - val_loss: 1.4736 - val_auc: 0.7241\n",
      "Epoch 430/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 102ms/step - loss: 0.1110 - auc: 1.0000 - val_loss: 1.5142 - val_auc: 0.7176\n",
      "Epoch 431/1000\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 0.1094 - auc: 1.0000 - val_loss: 1.4925 - val_auc: 0.7266\n",
      "Epoch 432/1000\n",
      "6/6 [==============================] - 1s 89ms/step - loss: 0.1243 - auc: 0.9999 - val_loss: 1.4457 - val_auc: 0.7370\n",
      "Epoch 433/1000\n",
      "6/6 [==============================] - 1s 142ms/step - loss: 0.1116 - auc: 1.0000 - val_loss: 1.4348 - val_auc: 0.7369\n",
      "Epoch 434/1000\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.1089 - auc: 1.0000 - val_loss: 1.4928 - val_auc: 0.7151\n",
      "Epoch 435/1000\n",
      "6/6 [==============================] - 0s 81ms/step - loss: 0.1090 - auc: 1.0000 - val_loss: 1.4795 - val_auc: 0.7245\n",
      "Epoch 436/1000\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.1364 - auc: 0.9998 - val_loss: 1.5236 - val_auc: 0.7066\n",
      "Epoch 437/1000\n",
      "6/6 [==============================] - 0s 74ms/step - loss: 0.1154 - auc: 1.0000 - val_loss: 1.4892 - val_auc: 0.7217\n",
      "Epoch 438/1000\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.1147 - auc: 1.0000 - val_loss: 1.4631 - val_auc: 0.7224\n",
      "Epoch 439/1000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.1149 - auc: 1.0000 - val_loss: 1.4380 - val_auc: 0.7326\n",
      "Epoch 440/1000\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.1092 - auc: 1.0000 - val_loss: 1.4140 - val_auc: 0.7556\n",
      "Epoch 441/1000\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.1014 - auc: 1.0000 - val_loss: 1.4371 - val_auc: 0.7455\n",
      "Epoch 442/1000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.1053 - auc: 1.0000 - val_loss: 1.4742 - val_auc: 0.7310\n",
      "Epoch 443/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.1049 - auc: 1.0000 - val_loss: 1.4531 - val_auc: 0.7352\n",
      "Epoch 444/1000\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.1096 - auc: 1.0000 - val_loss: 1.4376 - val_auc: 0.7439\n",
      "Epoch 445/1000\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.1025 - auc: 1.0000 - val_loss: 1.4383 - val_auc: 0.7363\n",
      "Epoch 446/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.1135 - auc: 0.9999 - val_loss: 1.4494 - val_auc: 0.7310\n",
      "Epoch 447/1000\n",
      "6/6 [==============================] - 0s 65ms/step - loss: 0.0967 - auc: 1.0000 - val_loss: 1.4732 - val_auc: 0.7191\n",
      "Epoch 448/1000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.1016 - auc: 1.0000 - val_loss: 1.4762 - val_auc: 0.7099\n",
      "Epoch 449/1000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.1083 - auc: 1.0000 - val_loss: 1.7201 - val_auc: 0.6466\n",
      "Epoch 450/1000\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.1147 - auc: 1.0000 - val_loss: 1.4392 - val_auc: 0.7205\n",
      "Epoch 451/1000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.1076 - auc: 1.0000 - val_loss: 1.4005 - val_auc: 0.7496\n",
      "Epoch 452/1000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.1009 - auc: 1.0000 - val_loss: 1.4234 - val_auc: 0.7225\n",
      "Epoch 453/1000\n",
      "6/6 [==============================] - 1s 83ms/step - loss: 0.0966 - auc: 1.0000 - val_loss: 1.4052 - val_auc: 0.7369\n",
      "Epoch 454/1000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0977 - auc: 1.0000 - val_loss: 1.4904 - val_auc: 0.7589\n",
      "Epoch 455/1000\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.1164 - auc: 1.0000 - val_loss: 1.6223 - val_auc: 0.6756\n",
      "Epoch 456/1000\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 0.1048 - auc: 1.0000 - val_loss: 1.8780 - val_auc: 0.6377\n",
      "Epoch 457/1000\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.1052 - auc: 1.0000 - val_loss: 1.6910 - val_auc: 0.6734\n",
      "Epoch 458/1000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.1070 - auc: 1.0000 - val_loss: 1.5840 - val_auc: 0.7224\n",
      "Epoch 459/1000\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 0.1037 - auc: 1.0000 - val_loss: 1.5593 - val_auc: 0.7337\n",
      "Epoch 460/1000\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0960 - auc: 1.0000 - val_loss: 1.4981 - val_auc: 0.7417\n",
      "Epoch 461/1000\n",
      "6/6 [==============================] - 1s 92ms/step - loss: 0.1059 - auc: 1.0000 - val_loss: 1.5183 - val_auc: 0.7268\n",
      "Epoch 462/1000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0921 - auc: 1.0000 - val_loss: 1.5308 - val_auc: 0.7246\n",
      "Epoch 463/1000\n",
      "6/6 [==============================] - 1s 101ms/step - loss: 0.1017 - auc: 1.0000 - val_loss: 1.5024 - val_auc: 0.7286\n",
      "Epoch 464/1000\n",
      "6/6 [==============================] - 0s 81ms/step - loss: 0.1089 - auc: 0.9999 - val_loss: 1.4780 - val_auc: 0.7322\n",
      "Epoch 465/1000\n",
      "6/6 [==============================] - 1s 227ms/step - loss: 0.0983 - auc: 1.0000 - val_loss: 1.4608 - val_auc: 0.7358\n",
      "Epoch 466/1000\n",
      "6/6 [==============================] - 1s 101ms/step - loss: 0.1014 - auc: 1.0000 - val_loss: 1.4891 - val_auc: 0.7175\n",
      "Epoch 467/1000\n",
      "6/6 [==============================] - 1s 114ms/step - loss: 0.0905 - auc: 1.0000 - val_loss: 1.4111 - val_auc: 0.7603\n",
      "Epoch 468/1000\n",
      "6/6 [==============================] - 0s 73ms/step - loss: 0.0936 - auc: 1.0000 - val_loss: 1.3887 - val_auc: 0.7752\n",
      "Epoch 469/1000\n",
      "6/6 [==============================] - 0s 73ms/step - loss: 0.0942 - auc: 1.0000 - val_loss: 1.4292 - val_auc: 0.7595\n",
      "Epoch 470/1000\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.1020 - auc: 1.0000 - val_loss: 1.4431 - val_auc: 0.7539\n",
      "Epoch 471/1000\n",
      "6/6 [==============================] - 1s 109ms/step - loss: 0.1024 - auc: 1.0000 - val_loss: 1.4638 - val_auc: 0.7321\n",
      "Epoch 472/1000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.1188 - auc: 0.9999 - val_loss: 1.4681 - val_auc: 0.7240\n",
      "Epoch 473/1000\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.1012 - auc: 1.0000 - val_loss: 1.4405 - val_auc: 0.7433\n",
      "Epoch 474/1000\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.1053 - auc: 1.0000 - val_loss: 1.4808 - val_auc: 0.7188\n",
      "Epoch 475/1000\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.1035 - auc: 1.0000 - val_loss: 1.6064 - val_auc: 0.6857\n",
      "Epoch 476/1000\n",
      "6/6 [==============================] - 1s 184ms/step - loss: 0.1127 - auc: 1.0000 - val_loss: 1.5938 - val_auc: 0.7574\n",
      "Epoch 477/1000\n",
      "6/6 [==============================] - 1s 137ms/step - loss: 0.1186 - auc: 0.9999 - val_loss: 1.4379 - val_auc: 0.7571\n",
      "Epoch 478/1000\n",
      "6/6 [==============================] - 1s 127ms/step - loss: 0.0928 - auc: 1.0000 - val_loss: 1.5077 - val_auc: 0.7217\n",
      "Epoch 479/1000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.1003 - auc: 1.0000 - val_loss: 1.5876 - val_auc: 0.7132\n",
      "Epoch 480/1000\n",
      "6/6 [==============================] - 0s 74ms/step - loss: 0.1141 - auc: 0.9999 - val_loss: 1.6035 - val_auc: 0.7164\n",
      "Epoch 481/1000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.1097 - auc: 0.9999 - val_loss: 1.5592 - val_auc: 0.7288\n",
      "Epoch 482/1000\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.1006 - auc: 1.0000 - val_loss: 1.5338 - val_auc: 0.7374\n",
      "Epoch 483/1000\n",
      "6/6 [==============================] - 0s 76ms/step - loss: 0.0960 - auc: 1.0000 - val_loss: 1.5168 - val_auc: 0.7345\n",
      "Epoch 484/1000\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0873 - auc: 1.000 - 0s 52ms/step - loss: 0.0891 - auc: 1.0000 - val_loss: 1.5408 - val_auc: 0.7312\n",
      "Epoch 485/1000\n",
      "6/6 [==============================] - 0s 75ms/step - loss: 0.1063 - auc: 1.0000 - val_loss: 1.6205 - val_auc: 0.7145\n",
      "Epoch 486/1000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0969 - auc: 1.0000 - val_loss: 1.6118 - val_auc: 0.7168\n",
      "Epoch 487/1000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.1044 - auc: 1.0000 - val_loss: 1.4897 - val_auc: 0.7566\n",
      "Epoch 488/1000\n",
      "6/6 [==============================] - 1s 91ms/step - loss: 0.0944 - auc: 1.0000 - val_loss: 1.4796 - val_auc: 0.7540\n",
      "Epoch 489/1000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0913 - auc: 1.0000 - val_loss: 1.5592 - val_auc: 0.7300\n",
      "Epoch 490/1000\n",
      "6/6 [==============================] - 0s 71ms/step - loss: 0.0964 - auc: 1.0000 - val_loss: 1.7527 - val_auc: 0.6991\n",
      "Epoch 491/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0900 - auc: 1.0000 - val_loss: 1.8203 - val_auc: 0.6960\n",
      "Epoch 492/1000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0902 - auc: 1.0000 - val_loss: 1.8075 - val_auc: 0.6970\n",
      "Epoch 493/1000\n",
      "6/6 [==============================] - 0s 80ms/step - loss: 0.0856 - auc: 1.0000 - val_loss: 1.7334 - val_auc: 0.7095\n",
      "Epoch 494/1000\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0923 - auc: 1.0000 - val_loss: 1.6567 - val_auc: 0.7170\n",
      "Epoch 495/1000\n",
      "6/6 [==============================] - 1s 87ms/step - loss: 0.1063 - auc: 1.0000 - val_loss: 1.6031 - val_auc: 0.7235\n",
      "Epoch 496/1000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0937 - auc: 1.0000 - val_loss: 1.5441 - val_auc: 0.7207\n",
      "Epoch 497/1000\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.0940 - auc: 1.0000 - val_loss: 1.5535 - val_auc: 0.7153\n",
      "Epoch 498/1000\n",
      "6/6 [==============================] - 0s 78ms/step - loss: 0.1177 - auc: 0.9999 - val_loss: 1.5468 - val_auc: 0.7230\n",
      "Epoch 499/1000\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0944 - auc: 1.0000 - val_loss: 1.5060 - val_auc: 0.7371\n",
      "Epoch 500/1000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0926 - auc: 1.0000 - val_loss: 1.5129 - val_auc: 0.7443\n",
      "Epoch 501/1000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0962 - auc: 1.0000 - val_loss: 1.5395 - val_auc: 0.7368\n",
      "Epoch 502/1000\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 0.0873 - auc: 1.0000 - val_loss: 1.5199 - val_auc: 0.7424\n",
      "Epoch 503/1000\n",
      "6/6 [==============================] - 1s 87ms/step - loss: 0.0922 - auc: 1.0000 - val_loss: 1.5206 - val_auc: 0.7423\n",
      "Epoch 504/1000\n",
      "6/6 [==============================] - 1s 99ms/step - loss: 0.0919 - auc: 1.0000 - val_loss: 1.5259 - val_auc: 0.7388\n",
      "Epoch 505/1000\n",
      "6/6 [==============================] - 1s 177ms/step - loss: 0.0877 - auc: 1.0000 - val_loss: 1.5374 - val_auc: 0.7346\n",
      "Epoch 506/1000\n",
      "6/6 [==============================] - 1s 121ms/step - loss: 0.0898 - auc: 1.0000 - val_loss: 1.5508 - val_auc: 0.7620\n",
      "Epoch 507/1000\n",
      "6/6 [==============================] - 1s 98ms/step - loss: 0.1184 - auc: 0.9999 - val_loss: 2.1626 - val_auc: 0.6295\n",
      "Epoch 508/1000\n",
      "6/6 [==============================] - 1s 91ms/step - loss: 0.1111 - auc: 1.0000 - val_loss: 1.8408 - val_auc: 0.6590\n",
      "Epoch 509/1000\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 0.1010 - auc: 1.0000 - val_loss: 1.6899 - val_auc: 0.7029\n",
      "Epoch 510/1000\n",
      "6/6 [==============================] - 1s 94ms/step - loss: 0.0891 - auc: 1.0000 - val_loss: 1.7342 - val_auc: 0.7076\n",
      "Epoch 511/1000\n",
      "6/6 [==============================] - 1s 89ms/step - loss: 0.0857 - auc: 1.0000 - val_loss: 1.7320 - val_auc: 0.7020\n",
      "Epoch 512/1000\n",
      "6/6 [==============================] - 1s 96ms/step - loss: 0.1047 - auc: 1.0000 - val_loss: 1.7502 - val_auc: 0.6967\n",
      "Epoch 513/1000\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0827 - auc: 1.0000 - val_loss: 1.7171 - val_auc: 0.7032\n",
      "Epoch 514/1000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.1115 - auc: 0.9999 - val_loss: 1.7097 - val_auc: 0.7345\n",
      "Epoch 515/1000\n",
      "6/6 [==============================] - 0s 73ms/step - loss: 0.1620 - auc: 0.9958 - val_loss: 2.2771 - val_auc: 0.5976\n",
      "Epoch 516/1000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.1674 - auc: 0.9985 - val_loss: 2.2973 - val_auc: 0.5926\n",
      "Epoch 517/1000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.1133 - auc: 0.9999 - val_loss: 1.7093 - val_auc: 0.6510\n",
      "Epoch 518/1000\n",
      "6/6 [==============================] - 1s 87ms/step - loss: 0.1170 - auc: 1.0000 - val_loss: 1.4627 - val_auc: 0.7173\n",
      "Epoch 519/1000\n",
      "6/6 [==============================] - 0s 74ms/step - loss: 0.0973 - auc: 1.0000 - val_loss: 1.6353 - val_auc: 0.7017\n",
      "Epoch 520/1000\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.1043 - auc: 0.9999 - val_loss: 1.6251 - val_auc: 0.7088\n",
      "Epoch 521/1000\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.1038 - auc: 1.0000 - val_loss: 1.4434 - val_auc: 0.7518\n",
      "Epoch 522/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0934 - auc: 1.0000 - val_loss: 1.3797 - val_auc: 0.7650\n",
      "Epoch 523/1000\n",
      "6/6 [==============================] - 0s 74ms/step - loss: 0.0903 - auc: 1.0000 - val_loss: 1.3310 - val_auc: 0.7762\n",
      "Epoch 524/1000\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0939 - auc: 1.0000 - val_loss: 1.3381 - val_auc: 0.7789\n",
      "Epoch 525/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0885 - auc: 1.0000 - val_loss: 1.3352 - val_auc: 0.7726\n",
      "Epoch 526/1000\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0817 - auc: 1.0000 - val_loss: 1.3319 - val_auc: 0.7729\n",
      "Epoch 527/1000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0817 - auc: 1.0000 - val_loss: 1.3390 - val_auc: 0.7712\n",
      "Epoch 528/1000\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.1001 - auc: 0.9999 - val_loss: 1.3571 - val_auc: 0.7695\n",
      "Epoch 529/1000\n",
      "6/6 [==============================] - 0s 72ms/step - loss: 0.0912 - auc: 1.0000 - val_loss: 1.3722 - val_auc: 0.7635\n",
      "Epoch 530/1000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0974 - auc: 1.0000 - val_loss: 1.6480 - val_auc: 0.6998\n",
      "Epoch 531/1000\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.1030 - auc: 0.9999 - val_loss: 1.7207 - val_auc: 0.6955\n",
      "Epoch 532/1000\n",
      "6/6 [==============================] - 1s 84ms/step - loss: 0.1017 - auc: 1.0000 - val_loss: 1.5804 - val_auc: 0.7169\n",
      "Epoch 533/1000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.1081 - auc: 1.0000 - val_loss: 1.4607 - val_auc: 0.7509\n",
      "Epoch 534/1000\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0878 - auc: 1.0000 - val_loss: 1.3847 - val_auc: 0.7689\n",
      "Epoch 535/1000\n",
      "6/6 [==============================] - 0s 78ms/step - loss: 0.0899 - auc: 1.0000 - val_loss: 1.3643 - val_auc: 0.7735\n",
      "Epoch 536/1000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0909 - auc: 1.0000 - val_loss: 1.3835 - val_auc: 0.7702\n",
      "Epoch 537/1000\n",
      "6/6 [==============================] - 1s 84ms/step - loss: 0.0936 - auc: 1.0000 - val_loss: 1.4331 - val_auc: 0.7657\n",
      "Epoch 538/1000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0816 - auc: 1.0000 - val_loss: 1.4915 - val_auc: 0.7692\n",
      "Epoch 539/1000\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0797 - auc: 1.0000 - val_loss: 1.4607 - val_auc: 0.7715\n",
      "Epoch 540/1000\n",
      "6/6 [==============================] - 0s 80ms/step - loss: 0.0890 - auc: 1.0000 - val_loss: 1.4371 - val_auc: 0.7717\n",
      "Epoch 541/1000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0847 - auc: 1.0000 - val_loss: 1.4234 - val_auc: 0.7585\n",
      "Epoch 542/1000\n",
      "6/6 [==============================] - 1s 140ms/step - loss: 0.0970 - auc: 0.9999 - val_loss: 1.4258 - val_auc: 0.7531\n",
      "Epoch 543/1000\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0817 - auc: 1.0000 - val_loss: 1.4229 - val_auc: 0.7524\n",
      "Epoch 544/1000\n",
      "6/6 [==============================] - 1s 90ms/step - loss: 0.1148 - auc: 0.9998 - val_loss: 1.4214 - val_auc: 0.7602\n",
      "Epoch 545/1000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0766 - auc: 1.0000 - val_loss: 1.4155 - val_auc: 0.7596\n",
      "Epoch 546/1000\n",
      "6/6 [==============================] - 0s 76ms/step - loss: 0.0876 - auc: 1.0000 - val_loss: 1.4194 - val_auc: 0.7581\n",
      "Epoch 547/1000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0814 - auc: 1.0000 - val_loss: 1.4059 - val_auc: 0.7623\n",
      "Epoch 548/1000\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0792 - auc: 1.0000 - val_loss: 1.3826 - val_auc: 0.7727\n",
      "Epoch 549/1000\n",
      "6/6 [==============================] - 0s 66ms/step - loss: 0.1011 - auc: 1.0000 - val_loss: 1.3904 - val_auc: 0.7719\n",
      "Epoch 550/1000\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0869 - auc: 1.0000 - val_loss: 1.3985 - val_auc: 0.7680\n",
      "Epoch 551/1000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0800 - auc: 1.0000 - val_loss: 1.3985 - val_auc: 0.7676\n",
      "Epoch 552/1000\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.0771 - auc: 1.0000 - val_loss: 1.4146 - val_auc: 0.7571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 553/1000\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0802 - auc: 1.0000 - val_loss: 1.4421 - val_auc: 0.7518\n",
      "Epoch 554/1000\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0848 - auc: 1.0000 - val_loss: 1.4631 - val_auc: 0.7492\n",
      "Epoch 555/1000\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.0759 - auc: 1.0000 - val_loss: 1.4504 - val_auc: 0.7537\n",
      "Epoch 556/1000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0747 - auc: 1.0000 - val_loss: 1.4394 - val_auc: 0.7526\n",
      "Epoch 557/1000\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0768 - auc: 1.0000 - val_loss: 1.4250 - val_auc: 0.7551\n",
      "Epoch 558/1000\n",
      "6/6 [==============================] - 0s 69ms/step - loss: 0.0879 - auc: 1.0000 - val_loss: 1.4186 - val_auc: 0.7679\n",
      "Epoch 559/1000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0792 - auc: 1.0000 - val_loss: 1.4143 - val_auc: 0.7695\n",
      "Epoch 560/1000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0844 - auc: 1.0000 - val_loss: 1.4109 - val_auc: 0.7724\n",
      "Epoch 561/1000\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.0842 - auc: 1.0000 - val_loss: 1.4178 - val_auc: 0.7720\n",
      "Epoch 562/1000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0840 - auc: 1.0000 - val_loss: 1.4488 - val_auc: 0.7706\n",
      "Epoch 563/1000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0970 - auc: 1.0000 - val_loss: 1.4149 - val_auc: 0.7516\n",
      "Epoch 564/1000\n",
      "6/6 [==============================] - 0s 65ms/step - loss: 0.0834 - auc: 1.0000 - val_loss: 1.5058 - val_auc: 0.7262\n",
      "Epoch 565/1000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0839 - auc: 1.0000 - val_loss: 1.5204 - val_auc: 0.7257\n",
      "Epoch 566/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0889 - auc: 1.0000 - val_loss: 1.5171 - val_auc: 0.7256\n",
      "Epoch 567/1000\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.0831 - auc: 1.0000 - val_loss: 1.4910 - val_auc: 0.7281\n",
      "Epoch 568/1000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0765 - auc: 1.0000 - val_loss: 1.4625 - val_auc: 0.7375\n",
      "Epoch 569/1000\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0883 - auc: 1.0000 - val_loss: 1.4488 - val_auc: 0.7488\n",
      "Epoch 570/1000\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0805 - auc: 1.0000 - val_loss: 1.4449 - val_auc: 0.7539\n",
      "Epoch 571/1000\n",
      "6/6 [==============================] - 0s 71ms/step - loss: 0.0757 - auc: 1.0000 - val_loss: 1.4528 - val_auc: 0.7522\n",
      "Epoch 572/1000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0762 - auc: 1.0000 - val_loss: 1.4705 - val_auc: 0.7446\n",
      "Epoch 573/1000\n",
      "6/6 [==============================] - 1s 144ms/step - loss: 0.0822 - auc: 1.0000 - val_loss: 1.4511 - val_auc: 0.7455\n",
      "Epoch 574/1000\n",
      "6/6 [==============================] - 1s 102ms/step - loss: 0.0791 - auc: 1.0000 - val_loss: 1.4377 - val_auc: 0.7532\n",
      "Epoch 575/1000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0791 - auc: 1.0000 - val_loss: 1.4488 - val_auc: 0.7552\n",
      "Epoch 576/1000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0841 - auc: 1.0000 - val_loss: 1.4983 - val_auc: 0.7470\n",
      "Epoch 577/1000\n",
      "6/6 [==============================] - 0s 73ms/step - loss: 0.0775 - auc: 1.0000 - val_loss: 1.5757 - val_auc: 0.7392\n",
      "Epoch 578/1000\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0859 - auc: 1.0000 - val_loss: 1.6435 - val_auc: 0.7352\n",
      "Epoch 579/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0762 - auc: 1.0000 - val_loss: 1.6687 - val_auc: 0.7313\n",
      "Epoch 580/1000\n",
      "6/6 [==============================] - 0s 69ms/step - loss: 0.0795 - auc: 1.0000 - val_loss: 1.6393 - val_auc: 0.7358\n",
      "Epoch 581/1000\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0883 - auc: 1.0000 - val_loss: 1.5860 - val_auc: 0.7400\n",
      "Epoch 582/1000\n",
      "6/6 [==============================] - 0s 65ms/step - loss: 0.0838 - auc: 1.0000 - val_loss: 1.5609 - val_auc: 0.7418\n",
      "Epoch 583/1000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0810 - auc: 1.0000 - val_loss: 1.6570 - val_auc: 0.7232\n",
      "Epoch 584/1000\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.0958 - auc: 0.9999 - val_loss: 1.6495 - val_auc: 0.7265\n",
      "Epoch 585/1000\n",
      "6/6 [==============================] - 0s 71ms/step - loss: 0.0825 - auc: 1.0000 - val_loss: 1.5228 - val_auc: 0.7464\n",
      "Epoch 586/1000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0768 - auc: 1.0000 - val_loss: 1.4969 - val_auc: 0.7516\n",
      "Epoch 587/1000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0749 - auc: 1.0000 - val_loss: 1.4970 - val_auc: 0.7561\n",
      "Epoch 588/1000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0810 - auc: 1.0000 - val_loss: 1.5550 - val_auc: 0.7426\n",
      "Epoch 589/1000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0855 - auc: 1.0000 - val_loss: 1.6498 - val_auc: 0.7318\n",
      "Epoch 590/1000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.1004 - auc: 1.0000 - val_loss: 1.6359 - val_auc: 0.7396\n",
      "Epoch 591/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0791 - auc: 1.0000 - val_loss: 1.6013 - val_auc: 0.7381\n",
      "Epoch 592/1000\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.0863 - auc: 1.0000 - val_loss: 1.5807 - val_auc: 0.7409\n",
      "Epoch 593/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0755 - auc: 1.0000 - val_loss: 1.6003 - val_auc: 0.7348\n",
      "Epoch 594/1000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0785 - auc: 1.0000 - val_loss: 1.5922 - val_auc: 0.7376\n",
      "Epoch 595/1000\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.0732 - auc: 1.0000 - val_loss: 1.5193 - val_auc: 0.7508\n",
      "Epoch 596/1000\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0834 - auc: 1.0000 - val_loss: 1.5111 - val_auc: 0.7488\n",
      "Epoch 597/1000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0809 - auc: 1.0000 - val_loss: 1.4939 - val_auc: 0.7464\n",
      "Epoch 598/1000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0778 - auc: 1.0000 - val_loss: 1.5059 - val_auc: 0.7456\n",
      "Epoch 599/1000\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 0.0834 - auc: 1.0000 - val_loss: 1.5199 - val_auc: 0.7450\n",
      "Epoch 600/1000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0754 - auc: 1.0000 - val_loss: 1.5425 - val_auc: 0.7500\n",
      "Epoch 601/1000\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0822 - auc: 1.0000 - val_loss: 1.5696 - val_auc: 0.7513\n",
      "Epoch 602/1000\n",
      "6/6 [==============================] - 0s 68ms/step - loss: 0.0801 - auc: 1.0000 - val_loss: 1.5581 - val_auc: 0.7548\n",
      "Epoch 603/1000\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0829 - auc: 1.0000 - val_loss: 1.5863 - val_auc: 0.7517\n",
      "Epoch 604/1000\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0752 - auc: 1.0000 - val_loss: 1.5988 - val_auc: 0.7367\n",
      "Epoch 605/1000\n",
      "6/6 [==============================] - 0s 74ms/step - loss: 0.0810 - auc: 1.0000 - val_loss: 1.6207 - val_auc: 0.7394\n",
      "Epoch 606/1000\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0750 - auc: 1.0000 - val_loss: 1.6208 - val_auc: 0.7425\n",
      "Epoch 607/1000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0791 - auc: 1.0000 - val_loss: 1.6198 - val_auc: 0.7411\n",
      "Epoch 608/1000\n",
      "6/6 [==============================] - 0s 72ms/step - loss: 0.0764 - auc: 1.0000 - val_loss: 1.6110 - val_auc: 0.7428\n",
      "Epoch 609/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0770 - auc: 1.0000 - val_loss: 1.6149 - val_auc: 0.7440\n",
      "Epoch 610/1000\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0728 - auc: 1.0000 - val_loss: 1.6220 - val_auc: 0.7419\n",
      "Epoch 611/1000\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0838 - auc: 1.0000 - val_loss: 1.6331 - val_auc: 0.7386\n",
      "Epoch 612/1000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0784 - auc: 1.0000 - val_loss: 1.6141 - val_auc: 0.7461\n",
      "Epoch 613/1000\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0772 - auc: 1.0000 - val_loss: 1.6468 - val_auc: 0.7341\n",
      "Epoch 614/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0892 - auc: 0.9999 - val_loss: 1.6323 - val_auc: 0.7323\n",
      "Epoch 615/1000\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0779 - auc: 1.0000 - val_loss: 1.6240 - val_auc: 0.7300\n",
      "Epoch 616/1000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0732 - auc: 1.0000 - val_loss: 1.6051 - val_auc: 0.7322\n",
      "Epoch 617/1000\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0759 - auc: 1.0000 - val_loss: 1.7192 - val_auc: 0.7018\n",
      "Epoch 618/1000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0810 - auc: 1.0000 - val_loss: 1.6538 - val_auc: 0.7033\n",
      "Epoch 619/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0723 - auc: 1.0000 - val_loss: 1.5705 - val_auc: 0.7126\n",
      "Epoch 620/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0813 - auc: 1.0000 - val_loss: 1.5156 - val_auc: 0.7326\n",
      "Epoch 621/1000\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 0.0848 - auc: 1.0000 - val_loss: 1.5232 - val_auc: 0.7436\n",
      "Epoch 622/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0694 - auc: 1.0000 - val_loss: 1.5422 - val_auc: 0.7432\n",
      "Epoch 623/1000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0794 - auc: 1.0000 - val_loss: 1.5916 - val_auc: 0.7305\n",
      "Epoch 624/1000\n",
      "6/6 [==============================] - 0s 71ms/step - loss: 0.0724 - auc: 1.0000 - val_loss: 1.6753 - val_auc: 0.7252\n",
      "Epoch 625/1000\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0821 - auc: 1.0000 - val_loss: 1.7682 - val_auc: 0.7107\n",
      "Epoch 626/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0738 - auc: 1.0000 - val_loss: 1.7288 - val_auc: 0.7212\n",
      "Epoch 627/1000\n",
      "6/6 [==============================] - 0s 74ms/step - loss: 0.0688 - auc: 1.0000 - val_loss: 1.6907 - val_auc: 0.7600\n",
      "Epoch 628/1000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0721 - auc: 1.0000 - val_loss: 1.6594 - val_auc: 0.7566\n",
      "Epoch 629/1000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0779 - auc: 1.0000 - val_loss: 1.6437 - val_auc: 0.7415\n",
      "Epoch 630/1000\n",
      "6/6 [==============================] - 0s 65ms/step - loss: 0.0791 - auc: 1.0000 - val_loss: 1.6890 - val_auc: 0.7281\n",
      "Epoch 631/1000\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.0716 - auc: 1.0000 - val_loss: 1.7154 - val_auc: 0.7218\n",
      "Epoch 632/1000\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 0.0730 - auc: 1.0000 - val_loss: 1.7418 - val_auc: 0.7209\n",
      "Epoch 633/1000\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.0712 - auc: 1.0000 - val_loss: 1.7550 - val_auc: 0.7133\n",
      "Epoch 634/1000\n",
      "6/6 [==============================] - 0s 81ms/step - loss: 0.0917 - auc: 0.9999 - val_loss: 1.7683 - val_auc: 0.7144\n",
      "Epoch 635/1000\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.0743 - auc: 1.0000 - val_loss: 1.7751 - val_auc: 0.7114\n",
      "Epoch 636/1000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0769 - auc: 1.0000 - val_loss: 1.7854 - val_auc: 0.7118\n",
      "Epoch 637/1000\n",
      "6/6 [==============================] - 0s 83ms/step - loss: 0.0765 - auc: 1.0000 - val_loss: 1.7299 - val_auc: 0.7202\n",
      "Epoch 638/1000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0783 - auc: 1.0000 - val_loss: 1.6622 - val_auc: 0.7246\n",
      "Epoch 639/1000\n",
      "6/6 [==============================] - 0s 72ms/step - loss: 0.0680 - auc: 1.0000 - val_loss: 2.0326 - val_auc: 0.6437\n",
      "Epoch 640/1000\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0977 - auc: 0.9999 - val_loss: 1.9629 - val_auc: 0.6647\n",
      "Epoch 641/1000\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0807 - auc: 1.0000 - val_loss: 1.6844 - val_auc: 0.7406\n",
      "Epoch 642/1000\n",
      "6/6 [==============================] - 1s 113ms/step - loss: 0.0886 - auc: 0.9999 - val_loss: 1.6404 - val_auc: 0.7597\n",
      "Epoch 643/1000\n",
      "6/6 [==============================] - 0s 70ms/step - loss: 0.0708 - auc: 1.0000 - val_loss: 1.6314 - val_auc: 0.7437\n",
      "Epoch 644/1000\n",
      "6/6 [==============================] - 0s 83ms/step - loss: 0.0731 - auc: 1.0000 - val_loss: 1.6041 - val_auc: 0.7754\n",
      "Epoch 645/1000\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0709 - auc: 1.0000 - val_loss: 1.5951 - val_auc: 0.7664\n",
      "Epoch 646/1000\n",
      "6/6 [==============================] - 0s 71ms/step - loss: 0.0740 - auc: 1.0000 - val_loss: 1.5917 - val_auc: 0.7450\n",
      "Epoch 647/1000\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.0887 - auc: 0.9999 - val_loss: 1.6195 - val_auc: 0.7373\n",
      "Epoch 648/1000\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0722 - auc: 1.0000 - val_loss: 1.6180 - val_auc: 0.7457\n",
      "Epoch 649/1000\n",
      "6/6 [==============================] - 0s 74ms/step - loss: 0.0832 - auc: 0.9999 - val_loss: 1.6756 - val_auc: 0.7367\n",
      "Epoch 650/1000\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0680 - auc: 1.0000 - val_loss: 1.7578 - val_auc: 0.7226\n",
      "Epoch 651/1000\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0701 - auc: 1.0000 - val_loss: 1.8190 - val_auc: 0.7107\n",
      "Epoch 652/1000\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 0.0769 - auc: 1.0000 - val_loss: 1.8501 - val_auc: 0.7099\n",
      "Epoch 653/1000\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0709 - auc: 1.0000 - val_loss: 1.7882 - val_auc: 0.7137\n",
      "Epoch 654/1000\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0724 - auc: 1.0000 - val_loss: 1.6977 - val_auc: 0.7500\n",
      "Epoch 655/1000\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.0691 - auc: 1.0000 - val_loss: 1.6484 - val_auc: 0.7496\n",
      "Epoch 656/1000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0812 - auc: 1.0000 - val_loss: 1.7141 - val_auc: 0.7197\n",
      "Epoch 657/1000\n",
      "6/6 [==============================] - 0s 72ms/step - loss: 0.0676 - auc: 1.0000 - val_loss: 1.7777 - val_auc: 0.7085\n",
      "Epoch 658/1000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0967 - auc: 0.9999 - val_loss: 1.8012 - val_auc: 0.7083\n",
      "Epoch 659/1000\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0665 - auc: 1.0000 - val_loss: 1.7698 - val_auc: 0.7093\n",
      "Epoch 660/1000\n",
      "6/6 [==============================] - 1s 126ms/step - loss: 0.0694 - auc: 1.0000 - val_loss: 1.7596 - val_auc: 0.7138\n",
      "Epoch 661/1000\n",
      "6/6 [==============================] - 1s 106ms/step - loss: 0.0693 - auc: 1.0000 - val_loss: 1.7880 - val_auc: 0.7146\n",
      "Epoch 662/1000\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.0843 - auc: 0.9999 - val_loss: 1.8023 - val_auc: 0.7192\n",
      "Epoch 663/1000\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.0783 - auc: 1.0000 - val_loss: 1.8513 - val_auc: 0.7055\n",
      "Epoch 664/1000\n",
      "6/6 [==============================] - 0s 77ms/step - loss: 0.0707 - auc: 1.0000 - val_loss: 1.7886 - val_auc: 0.7225\n",
      "Epoch 665/1000\n",
      "6/6 [==============================] - 0s 65ms/step - loss: 0.0872 - auc: 0.9999 - val_loss: 1.6689 - val_auc: 0.7517\n",
      "Epoch 666/1000\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0681 - auc: 1.0000 - val_loss: 1.6351 - val_auc: 0.7616\n",
      "Epoch 667/1000\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0734 - auc: 1.0000 - val_loss: 1.6607 - val_auc: 0.7543\n",
      "Epoch 668/1000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0765 - auc: 1.0000 - val_loss: 1.8616 - val_auc: 0.7189\n",
      "Epoch 669/1000\n",
      "6/6 [==============================] - 1s 90ms/step - loss: 0.0766 - auc: 1.0000 - val_loss: 2.0349 - val_auc: 0.6800\n",
      "Epoch 670/1000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0648 - auc: 1.0000 - val_loss: 2.0682 - val_auc: 0.6780\n",
      "Epoch 671/1000\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.0910 - auc: 0.9999 - val_loss: 2.0385 - val_auc: 0.6817\n",
      "Epoch 672/1000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0669 - auc: 1.0000 - val_loss: 1.8940 - val_auc: 0.6943\n",
      "Epoch 673/1000\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0668 - auc: 1.0000 - val_loss: 1.7178 - val_auc: 0.7342\n",
      "Epoch 674/1000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0694 - auc: 1.0000 - val_loss: 1.6888 - val_auc: 0.7408\n",
      "Epoch 675/1000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0728 - auc: 1.0000 - val_loss: 1.7158 - val_auc: 0.7317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 676/1000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0688 - auc: 1.0000 - val_loss: 1.8120 - val_auc: 0.7151\n",
      "Epoch 677/1000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0645 - auc: 1.0000 - val_loss: 1.8188 - val_auc: 0.7209\n",
      "Epoch 678/1000\n",
      "6/6 [==============================] - 0s 75ms/step - loss: 0.0766 - auc: 1.0000 - val_loss: 1.8873 - val_auc: 0.6952\n",
      "Epoch 679/1000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0681 - auc: 1.0000 - val_loss: 2.1801 - val_auc: 0.6501\n",
      "Epoch 680/1000\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0912 - auc: 0.9999 - val_loss: 2.1249 - val_auc: 0.6692\n",
      "Epoch 681/1000\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 0.0850 - auc: 0.9999 - val_loss: 1.8695 - val_auc: 0.7194\n",
      "Epoch 682/1000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0713 - auc: 1.0000 - val_loss: 2.0619 - val_auc: 0.6273\n",
      "Epoch 683/1000\n",
      "6/6 [==============================] - 0s 82ms/step - loss: 0.0850 - auc: 1.0000 - val_loss: 3.0480 - val_auc: 0.5629\n",
      "Epoch 684/1000\n",
      "6/6 [==============================] - 1s 106ms/step - loss: 0.0914 - auc: 1.0000 - val_loss: 2.2612 - val_auc: 0.6012\n",
      "Epoch 685/1000\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 0.0833 - auc: 1.0000 - val_loss: 2.4313 - val_auc: 0.6108\n",
      "Epoch 686/1000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0931 - auc: 0.9999 - val_loss: 2.0825 - val_auc: 0.6583\n",
      "Epoch 687/1000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0723 - auc: 1.0000 - val_loss: 1.8712 - val_auc: 0.6981\n",
      "Epoch 688/1000\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 0.0681 - auc: 1.0000 - val_loss: 1.7307 - val_auc: 0.7219\n",
      "Epoch 689/1000\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0765 - auc: 1.0000 - val_loss: 1.6813 - val_auc: 0.7457\n",
      "Epoch 690/1000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0691 - auc: 1.0000 - val_loss: 1.8481 - val_auc: 0.7366\n",
      "Epoch 691/1000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0739 - auc: 1.0000 - val_loss: 1.9142 - val_auc: 0.7201\n",
      "Epoch 692/1000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0660 - auc: 1.0000 - val_loss: 1.8193 - val_auc: 0.7302\n",
      "Epoch 693/1000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0645 - auc: 1.0000 - val_loss: 1.7555 - val_auc: 0.7346\n",
      "Epoch 694/1000\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.0641 - auc: 1.0000 - val_loss: 1.5704 - val_auc: 0.7604\n",
      "Epoch 695/1000\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.0689 - auc: 1.0000 - val_loss: 1.5043 - val_auc: 0.7649\n",
      "Epoch 696/1000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0670 - auc: 1.0000 - val_loss: 1.5292 - val_auc: 0.7573\n",
      "Epoch 697/1000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0813 - auc: 0.9999 - val_loss: 1.5432 - val_auc: 0.7550\n",
      "Epoch 698/1000\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0681 - auc: 1.0000 - val_loss: 1.5325 - val_auc: 0.7598\n",
      "Epoch 699/1000\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0745 - auc: 1.0000 - val_loss: 1.5354 - val_auc: 0.7583\n",
      "Epoch 700/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0667 - auc: 1.0000 - val_loss: 1.5281 - val_auc: 0.7607\n",
      "Epoch 701/1000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0653 - auc: 1.0000 - val_loss: 1.5513 - val_auc: 0.7571\n",
      "Epoch 702/1000\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.0693 - auc: 1.0000 - val_loss: 1.5749 - val_auc: 0.7515\n",
      "Epoch 703/1000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0778 - auc: 0.9999 - val_loss: 1.5609 - val_auc: 0.7484\n",
      "Epoch 704/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0619 - auc: 1.0000 - val_loss: 1.5498 - val_auc: 0.7568\n",
      "Epoch 705/1000\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.0691 - auc: 1.0000 - val_loss: 1.5121 - val_auc: 0.7647\n",
      "Epoch 706/1000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0699 - auc: 1.0000 - val_loss: 1.4634 - val_auc: 0.7766\n",
      "Epoch 707/1000\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0711 - auc: 1.0000 - val_loss: 1.4505 - val_auc: 0.7840\n",
      "Epoch 708/1000\n",
      "6/6 [==============================] - 0s 65ms/step - loss: 0.0702 - auc: 1.0000 - val_loss: 1.4419 - val_auc: 0.7835\n",
      "Epoch 709/1000\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0821 - auc: 0.9999 - val_loss: 1.4794 - val_auc: 0.7786\n",
      "Epoch 710/1000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0731 - auc: 1.0000 - val_loss: 1.5571 - val_auc: 0.7621\n",
      "Epoch 711/1000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0656 - auc: 1.0000 - val_loss: 1.5362 - val_auc: 0.7473\n",
      "Epoch 712/1000\n",
      "6/6 [==============================] - 0s 68ms/step - loss: 0.0657 - auc: 1.0000 - val_loss: 1.4993 - val_auc: 0.7568\n",
      "Epoch 713/1000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0695 - auc: 1.0000 - val_loss: 1.4925 - val_auc: 0.7613\n",
      "Epoch 714/1000\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0646 - auc: 1.0000 - val_loss: 1.4895 - val_auc: 0.7578\n",
      "Epoch 715/1000\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.0661 - auc: 1.0000 - val_loss: 1.5037 - val_auc: 0.7636\n",
      "Epoch 716/1000\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0709 - auc: 1.0000 - val_loss: 1.5170 - val_auc: 0.7647\n",
      "Epoch 717/1000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0722 - auc: 1.0000 - val_loss: 1.5102 - val_auc: 0.7784\n",
      "Epoch 718/1000\n",
      "6/6 [==============================] - 0s 80ms/step - loss: 0.0713 - auc: 1.0000 - val_loss: 1.5085 - val_auc: 0.7817\n",
      "Epoch 719/1000\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0738 - auc: 1.0000 - val_loss: 1.5144 - val_auc: 0.7782\n",
      "Epoch 720/1000\n",
      "6/6 [==============================] - 0s 82ms/step - loss: 0.0703 - auc: 1.0000 - val_loss: 1.5160 - val_auc: 0.7749\n",
      "Epoch 721/1000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0722 - auc: 1.0000 - val_loss: 1.5391 - val_auc: 0.7666\n",
      "Epoch 722/1000\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0665 - auc: 1.0000 - val_loss: 1.5777 - val_auc: 0.7540\n",
      "Epoch 723/1000\n",
      "6/6 [==============================] - 0s 74ms/step - loss: 0.0658 - auc: 1.0000 - val_loss: 1.6441 - val_auc: 0.7421\n",
      "Epoch 724/1000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0702 - auc: 1.0000 - val_loss: 1.6820 - val_auc: 0.7372\n",
      "Epoch 725/1000\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0695 - auc: 1.0000 - val_loss: 1.6558 - val_auc: 0.7392\n",
      "Epoch 726/1000\n",
      "6/6 [==============================] - 0s 70ms/step - loss: 0.0667 - auc: 1.0000 - val_loss: 1.7172 - val_auc: 0.7147\n",
      "Epoch 727/1000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0665 - auc: 1.0000 - val_loss: 1.8326 - val_auc: 0.6954\n",
      "Epoch 728/1000\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.0647 - auc: 1.0000 - val_loss: 1.7615 - val_auc: 0.7230\n",
      "Epoch 729/1000\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0715 - auc: 1.0000 - val_loss: 1.7087 - val_auc: 0.7392\n",
      "Epoch 730/1000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0698 - auc: 1.0000 - val_loss: 1.7110 - val_auc: 0.7574\n",
      "Epoch 731/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0660 - auc: 1.0000 - val_loss: 1.6876 - val_auc: 0.7713\n",
      "Epoch 732/1000\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0696 - auc: 1.0000 - val_loss: 1.7563 - val_auc: 0.7549\n",
      "Epoch 733/1000\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0725 - auc: 1.0000 - val_loss: 2.5395 - val_auc: 0.5873\n",
      "Epoch 734/1000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0800 - auc: 1.0000 - val_loss: 2.1422 - val_auc: 0.6074\n",
      "Epoch 735/1000\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0756 - auc: 1.0000 - val_loss: 2.0122 - val_auc: 0.6251\n",
      "Epoch 736/1000\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0743 - auc: 1.0000 - val_loss: 1.9171 - val_auc: 0.6871\n",
      "Epoch 737/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0677 - auc: 1.0000 - val_loss: 1.9970 - val_auc: 0.7202\n",
      "Epoch 738/1000\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0796 - auc: 0.9999 - val_loss: 2.4201 - val_auc: 0.6813\n",
      "Epoch 739/1000\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0880 - auc: 0.9999 - val_loss: 2.4163 - val_auc: 0.6606\n",
      "Epoch 740/1000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0658 - auc: 1.0000 - val_loss: 2.1480 - val_auc: 0.6481\n",
      "Epoch 741/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0822 - auc: 0.9999 - val_loss: 1.8459 - val_auc: 0.7121\n",
      "Epoch 742/1000\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.0651 - auc: 1.0000 - val_loss: 1.5554 - val_auc: 0.7486\n",
      "Epoch 743/1000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0758 - auc: 1.0000 - val_loss: 1.5385 - val_auc: 0.7564\n",
      "Epoch 744/1000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0649 - auc: 1.0000 - val_loss: 1.6541 - val_auc: 0.7247\n",
      "Epoch 745/1000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0660 - auc: 1.0000 - val_loss: 1.7117 - val_auc: 0.7083\n",
      "Epoch 746/1000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0658 - auc: 1.0000 - val_loss: 1.6576 - val_auc: 0.7231\n",
      "Epoch 747/1000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0602 - auc: 1.0000 - val_loss: 1.5968 - val_auc: 0.7438\n",
      "Epoch 748/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0696 - auc: 1.0000 - val_loss: 1.5881 - val_auc: 0.7543\n",
      "Epoch 749/1000\n",
      "6/6 [==============================] - 0s 65ms/step - loss: 0.0653 - auc: 1.0000 - val_loss: 1.6159 - val_auc: 0.7509\n",
      "Epoch 750/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0665 - auc: 1.0000 - val_loss: 1.6156 - val_auc: 0.7540\n",
      "Epoch 751/1000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0654 - auc: 1.0000 - val_loss: 1.6074 - val_auc: 0.7598\n",
      "Epoch 752/1000\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 0.0698 - auc: 1.0000 - val_loss: 1.6201 - val_auc: 0.7541\n",
      "Epoch 753/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0758 - auc: 1.0000 - val_loss: 1.6659 - val_auc: 0.7477\n",
      "Epoch 754/1000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0911 - auc: 0.9999 - val_loss: 1.6857 - val_auc: 0.7419\n",
      "Epoch 755/1000\n",
      "6/6 [==============================] - 0s 71ms/step - loss: 0.0700 - auc: 1.0000 - val_loss: 1.6696 - val_auc: 0.7515\n",
      "Epoch 756/1000\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0802 - auc: 1.0000 - val_loss: 1.6621 - val_auc: 0.7445\n",
      "Epoch 757/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0635 - auc: 1.0000 - val_loss: 1.7561 - val_auc: 0.7250\n",
      "Epoch 758/1000\n",
      "6/6 [==============================] - 1s 91ms/step - loss: 0.0598 - auc: 1.0000 - val_loss: 1.7728 - val_auc: 0.7184\n",
      "Epoch 759/1000\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 0.0672 - auc: 1.0000 - val_loss: 1.7146 - val_auc: 0.7397\n",
      "Epoch 760/1000\n",
      "6/6 [==============================] - 0s 83ms/step - loss: 0.0692 - auc: 1.0000 - val_loss: 1.7007 - val_auc: 0.7530\n",
      "Epoch 761/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0643 - auc: 1.0000 - val_loss: 1.7494 - val_auc: 0.7688\n",
      "Epoch 762/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0620 - auc: 1.0000 - val_loss: 1.7765 - val_auc: 0.7574\n",
      "Epoch 763/1000\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.0614 - auc: 1.0000 - val_loss: 1.7346 - val_auc: 0.7494\n",
      "Epoch 764/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0612 - auc: 1.0000 - val_loss: 1.7595 - val_auc: 0.7332\n",
      "Epoch 765/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0650 - auc: 1.0000 - val_loss: 1.7743 - val_auc: 0.7370\n",
      "Epoch 766/1000\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.0701 - auc: 1.0000 - val_loss: 1.8133 - val_auc: 0.7270\n",
      "Epoch 767/1000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0803 - auc: 0.9999 - val_loss: 1.8026 - val_auc: 0.7314\n",
      "Epoch 768/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0636 - auc: 1.0000 - val_loss: 1.7567 - val_auc: 0.7453\n",
      "Epoch 769/1000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0683 - auc: 1.0000 - val_loss: 1.7777 - val_auc: 0.7453\n",
      "Epoch 770/1000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0582 - auc: 1.0000 - val_loss: 1.7598 - val_auc: 0.7465\n",
      "Epoch 771/1000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0686 - auc: 1.0000 - val_loss: 1.7492 - val_auc: 0.7341\n",
      "Epoch 772/1000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0625 - auc: 1.0000 - val_loss: 1.7492 - val_auc: 0.7364\n",
      "Epoch 773/1000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0584 - auc: 1.0000 - val_loss: 1.7535 - val_auc: 0.7413\n",
      "Epoch 774/1000\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0612 - auc: 1.0000 - val_loss: 1.7561 - val_auc: 0.7406\n",
      "Epoch 775/1000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0602 - auc: 1.0000 - val_loss: 1.7629 - val_auc: 0.7436\n",
      "Epoch 776/1000\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0666 - auc: 1.0000 - val_loss: 1.7679 - val_auc: 0.7491\n",
      "Epoch 777/1000\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.0797 - auc: 0.9999 - val_loss: 1.7500 - val_auc: 0.7610\n",
      "Epoch 778/1000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0590 - auc: 1.0000 - val_loss: 1.7248 - val_auc: 0.7610\n",
      "Epoch 779/1000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0659 - auc: 1.0000 - val_loss: 1.9371 - val_auc: 0.6961\n",
      "Epoch 780/1000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0800 - auc: 0.9999 - val_loss: 2.8014 - val_auc: 0.6120\n",
      "Epoch 781/1000\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.1630 - auc: 0.9948 - val_loss: 2.5811 - val_auc: 0.6311\n",
      "Epoch 782/1000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.1005 - auc: 0.9998 - val_loss: 1.9696 - val_auc: 0.6963\n",
      "Epoch 783/1000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0629 - auc: 1.0000 - val_loss: 1.9290 - val_auc: 0.7252\n",
      "Epoch 784/1000\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.0673 - auc: 1.0000 - val_loss: 2.0183 - val_auc: 0.7417\n",
      "Epoch 785/1000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0605 - auc: 1.0000 - val_loss: 1.9344 - val_auc: 0.7438\n",
      "Epoch 786/1000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0577 - auc: 1.0000 - val_loss: 1.8679 - val_auc: 0.7377\n",
      "Epoch 787/1000\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.0705 - auc: 1.0000 - val_loss: 1.8991 - val_auc: 0.7302\n",
      "Epoch 788/1000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0598 - auc: 1.0000 - val_loss: 1.9044 - val_auc: 0.7455\n",
      "Epoch 789/1000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0638 - auc: 1.0000 - val_loss: 1.8839 - val_auc: 0.7613\n",
      "Epoch 790/1000\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.0609 - auc: 1.0000 - val_loss: 1.9244 - val_auc: 0.7384\n",
      "Epoch 791/1000\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.0771 - auc: 1.0000 - val_loss: 1.9631 - val_auc: 0.7363\n",
      "Epoch 792/1000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0588 - auc: 1.0000 - val_loss: 1.9486 - val_auc: 0.7391\n",
      "Epoch 793/1000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0758 - auc: 0.9999 - val_loss: 1.9283 - val_auc: 0.7359\n",
      "Epoch 794/1000\n",
      "6/6 [==============================] - 0s 71ms/step - loss: 0.0580 - auc: 1.0000 - val_loss: 1.8790 - val_auc: 0.7370\n",
      "Epoch 795/1000\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0606 - auc: 1.0000 - val_loss: 1.8254 - val_auc: 0.7394\n",
      "Epoch 796/1000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0682 - auc: 1.0000 - val_loss: 1.7342 - val_auc: 0.7622\n",
      "Epoch 797/1000\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0577 - auc: 1.0000 - val_loss: 1.6541 - val_auc: 0.7620\n",
      "Epoch 798/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0633 - auc: 1.0000 - val_loss: 1.6497 - val_auc: 0.7519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0632 - auc: 1.0000 - val_loss: 1.6823 - val_auc: 0.7526\n",
      "Epoch 800/1000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0777 - auc: 0.9999 - val_loss: 1.8374 - val_auc: 0.7356\n",
      "Epoch 801/1000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0655 - auc: 1.0000 - val_loss: 1.7772 - val_auc: 0.7075\n",
      "Epoch 802/1000\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0679 - auc: 1.0000 - val_loss: 2.0798 - val_auc: 0.6479\n",
      "Epoch 803/1000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0756 - auc: 1.0000 - val_loss: 1.8418 - val_auc: 0.6876\n",
      "Epoch 804/1000\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.0613 - auc: 1.0000 - val_loss: 1.6036 - val_auc: 0.7466\n",
      "Epoch 805/1000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0592 - auc: 1.0000 - val_loss: 1.5633 - val_auc: 0.7762\n",
      "Epoch 806/1000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0616 - auc: 1.0000 - val_loss: 1.6337 - val_auc: 0.7700\n",
      "Epoch 807/1000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0670 - auc: 1.0000 - val_loss: 1.6310 - val_auc: 0.7684\n",
      "Epoch 808/1000\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 0.0570 - auc: 1.0000 - val_loss: 1.7004 - val_auc: 0.7803\n",
      "Epoch 809/1000\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0561 - auc: 1.0000 - val_loss: 1.6737 - val_auc: 0.7641\n",
      "Epoch 810/1000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0742 - auc: 0.9999 - val_loss: 1.6609 - val_auc: 0.7604\n",
      "Epoch 811/1000\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.0822 - auc: 0.9999 - val_loss: 1.6712 - val_auc: 0.7622\n",
      "Epoch 812/1000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0607 - auc: 1.0000 - val_loss: 1.6770 - val_auc: 0.7566\n",
      "Epoch 813/1000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0672 - auc: 1.0000 - val_loss: 1.7279 - val_auc: 0.7538\n",
      "Epoch 814/1000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0588 - auc: 1.0000 - val_loss: 1.7295 - val_auc: 0.7534\n",
      "Epoch 815/1000\n",
      "6/6 [==============================] - 1s 101ms/step - loss: 0.0539 - auc: 1.0000 - val_loss: 1.7689 - val_auc: 0.7786\n",
      "Epoch 816/1000\n",
      "6/6 [==============================] - 1s 116ms/step - loss: 0.0564 - auc: 1.0000 - val_loss: 1.7386 - val_auc: 0.7733\n",
      "Epoch 817/1000\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0866 - auc: 0.9999 - val_loss: 1.7248 - val_auc: 0.7447\n",
      "Epoch 818/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0628 - auc: 1.0000 - val_loss: 1.8473 - val_auc: 0.7326\n",
      "Epoch 819/1000\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0734 - auc: 0.9999 - val_loss: 1.9441 - val_auc: 0.7146\n",
      "Epoch 820/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0569 - auc: 1.0000 - val_loss: 1.9044 - val_auc: 0.7176\n",
      "Epoch 821/1000\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0752 - auc: 0.9999 - val_loss: 1.8567 - val_auc: 0.7248\n",
      "Epoch 822/1000\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.0611 - auc: 1.0000 - val_loss: 1.7853 - val_auc: 0.7422\n",
      "Epoch 823/1000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0589 - auc: 1.0000 - val_loss: 1.7020 - val_auc: 0.7701\n",
      "Epoch 824/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0642 - auc: 1.0000 - val_loss: 1.6790 - val_auc: 0.7714\n",
      "Epoch 825/1000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0668 - auc: 1.0000 - val_loss: 1.6774 - val_auc: 0.7612\n",
      "Epoch 826/1000\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.0865 - auc: 0.9999 - val_loss: 1.6951 - val_auc: 0.7592\n",
      "Epoch 827/1000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0648 - auc: 1.0000 - val_loss: 1.6913 - val_auc: 0.7665\n",
      "Epoch 828/1000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0619 - auc: 1.0000 - val_loss: 1.7920 - val_auc: 0.7705\n",
      "Epoch 829/1000\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.0629 - auc: 1.0000 - val_loss: 1.8859 - val_auc: 0.7637\n",
      "Epoch 830/1000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0660 - auc: 1.0000 - val_loss: 1.8221 - val_auc: 0.7609\n",
      "Epoch 831/1000\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.0591 - auc: 1.0000 - val_loss: 1.7432 - val_auc: 0.7565\n",
      "Epoch 832/1000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0555 - auc: 1.0000 - val_loss: 1.7316 - val_auc: 0.7490\n",
      "Epoch 833/1000\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.0603 - auc: 1.0000 - val_loss: 1.7332 - val_auc: 0.7473\n",
      "Epoch 834/1000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0554 - auc: 1.0000 - val_loss: 1.7770 - val_auc: 0.7501\n",
      "Epoch 835/1000\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0626 - auc: 1.0000 - val_loss: 1.8182 - val_auc: 0.7491\n",
      "Epoch 836/1000\n",
      "6/6 [==============================] - 0s 65ms/step - loss: 0.0613 - auc: 1.0000 - val_loss: 1.8238 - val_auc: 0.7534\n",
      "Epoch 837/1000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0612 - auc: 1.0000 - val_loss: 1.8306 - val_auc: 0.7425\n",
      "Epoch 838/1000\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0585 - auc: 1.0000 - val_loss: 1.7989 - val_auc: 0.7407\n",
      "Epoch 839/1000\n",
      "6/6 [==============================] - 0s 72ms/step - loss: 0.0646 - auc: 1.0000 - val_loss: 1.7667 - val_auc: 0.7680\n",
      "Epoch 840/1000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0605 - auc: 1.0000 - val_loss: 1.7420 - val_auc: 0.7809\n",
      "Epoch 841/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0605 - auc: 1.0000 - val_loss: 1.7450 - val_auc: 0.7729\n",
      "Epoch 842/1000\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.0583 - auc: 1.0000 - val_loss: 1.8200 - val_auc: 0.7573\n",
      "Epoch 843/1000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0616 - auc: 1.0000 - val_loss: 1.9135 - val_auc: 0.7463\n",
      "Epoch 844/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0598 - auc: 1.0000 - val_loss: 1.9965 - val_auc: 0.7296\n",
      "Epoch 845/1000\n",
      "6/6 [==============================] - 0s 65ms/step - loss: 0.0666 - auc: 1.0000 - val_loss: 2.0542 - val_auc: 0.7207\n",
      "Epoch 846/1000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0817 - auc: 0.9999 - val_loss: 2.0517 - val_auc: 0.7140\n",
      "Epoch 847/1000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0621 - auc: 1.0000 - val_loss: 2.0010 - val_auc: 0.7248\n",
      "Epoch 848/1000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0574 - auc: 1.0000 - val_loss: 1.9167 - val_auc: 0.7243\n",
      "Epoch 849/1000\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 0.0580 - auc: 1.0000 - val_loss: 1.8275 - val_auc: 0.7553\n",
      "Epoch 850/1000\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0634 - auc: 1.0000 - val_loss: 1.7765 - val_auc: 0.7579\n",
      "Epoch 851/1000\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0547 - auc: 1.0000 - val_loss: 1.7488 - val_auc: 0.7514\n",
      "Epoch 852/1000\n",
      "6/6 [==============================] - 0s 73ms/step - loss: 0.0642 - auc: 1.0000 - val_loss: 1.7602 - val_auc: 0.7590\n",
      "Epoch 853/1000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0612 - auc: 1.0000 - val_loss: 1.8111 - val_auc: 0.7623\n",
      "Epoch 854/1000\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0549 - auc: 1.0000 - val_loss: 1.8873 - val_auc: 0.7593\n",
      "Epoch 855/1000\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0839 - auc: 0.9999 - val_loss: 1.9825 - val_auc: 0.7345\n",
      "Epoch 856/1000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0607 - auc: 1.0000 - val_loss: 2.0203 - val_auc: 0.7296\n",
      "Epoch 857/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0547 - auc: 1.0000 - val_loss: 1.9845 - val_auc: 0.7285\n",
      "Epoch 858/1000\n",
      "6/6 [==============================] - 0s 76ms/step - loss: 0.0631 - auc: 1.0000 - val_loss: 1.9378 - val_auc: 0.7133\n",
      "Epoch 859/1000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0617 - auc: 1.0000 - val_loss: 2.0289 - val_auc: 0.6809\n",
      "Epoch 860/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0584 - auc: 1.0000 - val_loss: 2.0205 - val_auc: 0.6857\n",
      "Epoch 861/1000\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.0608 - auc: 1.0000 - val_loss: 1.8918 - val_auc: 0.7116\n",
      "Epoch 862/1000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0616 - auc: 1.0000 - val_loss: 1.8850 - val_auc: 0.7369\n",
      "Epoch 863/1000\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0573 - auc: 1.0000 - val_loss: 1.9132 - val_auc: 0.7512\n",
      "Epoch 864/1000\n",
      "6/6 [==============================] - 0s 68ms/step - loss: 0.0794 - auc: 0.9999 - val_loss: 1.8199 - val_auc: 0.7425\n",
      "Epoch 865/1000\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0736 - auc: 0.9999 - val_loss: 1.9397 - val_auc: 0.7190\n",
      "Epoch 866/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0580 - auc: 1.0000 - val_loss: 2.0202 - val_auc: 0.7114\n",
      "Epoch 867/1000\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.0565 - auc: 1.0000 - val_loss: 1.9837 - val_auc: 0.7174\n",
      "Epoch 868/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0705 - auc: 0.9999 - val_loss: 1.8957 - val_auc: 0.7392\n",
      "Epoch 869/1000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0714 - auc: 0.9999 - val_loss: 1.8395 - val_auc: 0.7519\n",
      "Epoch 870/1000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0528 - auc: 1.0000 - val_loss: 1.8133 - val_auc: 0.7448\n",
      "Epoch 871/1000\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.0834 - auc: 0.9999 - val_loss: 1.8049 - val_auc: 0.7432\n",
      "Epoch 872/1000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0535 - auc: 1.0000 - val_loss: 1.7783 - val_auc: 0.7494\n",
      "Epoch 873/1000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0558 - auc: 1.0000 - val_loss: 1.7678 - val_auc: 0.7381\n",
      "Epoch 874/1000\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.0590 - auc: 1.0000 - val_loss: 1.7620 - val_auc: 0.7346\n",
      "Epoch 875/1000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0581 - auc: 1.0000 - val_loss: 1.8769 - val_auc: 0.7244\n",
      "Epoch 876/1000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0544 - auc: 1.0000 - val_loss: 1.8902 - val_auc: 0.7208\n",
      "Epoch 877/1000\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.0573 - auc: 1.0000 - val_loss: 1.8185 - val_auc: 0.7382\n",
      "Epoch 878/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0605 - auc: 1.0000 - val_loss: 1.8511 - val_auc: 0.7422\n",
      "Epoch 879/1000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0633 - auc: 1.0000 - val_loss: 1.9048 - val_auc: 0.7371\n",
      "Epoch 880/1000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0596 - auc: 1.0000 - val_loss: 1.8954 - val_auc: 0.7332\n",
      "Epoch 881/1000\n",
      "6/6 [==============================] - 0s 70ms/step - loss: 0.0509 - auc: 1.0000 - val_loss: 1.9023 - val_auc: 0.7196\n",
      "Epoch 882/1000\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0543 - auc: 1.0000 - val_loss: 1.9404 - val_auc: 0.7148\n",
      "Epoch 883/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0522 - auc: 1.0000 - val_loss: 1.9642 - val_auc: 0.7153\n",
      "Epoch 884/1000\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0550 - auc: 1.0000 - val_loss: 1.9008 - val_auc: 0.7363\n",
      "Epoch 885/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0790 - auc: 0.9999 - val_loss: 1.8659 - val_auc: 0.7444\n",
      "Epoch 886/1000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0593 - auc: 1.0000 - val_loss: 1.8494 - val_auc: 0.7552\n",
      "Epoch 887/1000\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.0679 - auc: 0.9999 - val_loss: 1.8221 - val_auc: 0.7583\n",
      "Epoch 888/1000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0806 - auc: 0.9999 - val_loss: 1.7966 - val_auc: 0.7434\n",
      "Epoch 889/1000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0655 - auc: 1.0000 - val_loss: 1.7795 - val_auc: 0.7420\n",
      "Epoch 890/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0563 - auc: 1.0000 - val_loss: 1.8099 - val_auc: 0.7290\n",
      "Epoch 891/1000\n",
      "6/6 [==============================] - 1s 88ms/step - loss: 0.0532 - auc: 1.0000 - val_loss: 1.8177 - val_auc: 0.7270\n",
      "Epoch 892/1000\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.0497 - auc: 1.0000 - val_loss: 1.7970 - val_auc: 0.7298\n",
      "Epoch 893/1000\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0528 - auc: 1.0000 - val_loss: 1.8024 - val_auc: 0.7294\n",
      "Epoch 894/1000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0521 - auc: 1.0000 - val_loss: 1.8475 - val_auc: 0.7232\n",
      "Epoch 895/1000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0519 - auc: 1.0000 - val_loss: 1.8473 - val_auc: 0.7171\n",
      "Epoch 896/1000\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.0680 - auc: 1.0000 - val_loss: 1.8452 - val_auc: 0.7095\n",
      "Epoch 897/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0617 - auc: 1.0000 - val_loss: 2.0156 - val_auc: 0.6866\n",
      "Epoch 898/1000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0555 - auc: 1.0000 - val_loss: 2.0691 - val_auc: 0.6876\n",
      "Epoch 899/1000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0569 - auc: 1.0000 - val_loss: 2.0104 - val_auc: 0.7103\n",
      "Epoch 900/1000\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.0566 - auc: 1.0000 - val_loss: 1.9567 - val_auc: 0.7266\n",
      "Epoch 901/1000\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0568 - auc: 1.0000 - val_loss: 1.9422 - val_auc: 0.7272\n",
      "Epoch 902/1000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0505 - auc: 1.0000 - val_loss: 1.9581 - val_auc: 0.7486\n",
      "Epoch 903/1000\n",
      "6/6 [==============================] - 0s 68ms/step - loss: 0.0690 - auc: 0.9999 - val_loss: 1.9556 - val_auc: 0.7511\n",
      "Epoch 904/1000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0609 - auc: 1.0000 - val_loss: 1.9270 - val_auc: 0.7453\n",
      "Epoch 905/1000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0505 - auc: 1.0000 - val_loss: 1.8842 - val_auc: 0.7474\n",
      "Epoch 906/1000\n",
      "6/6 [==============================] - 0s 80ms/step - loss: 0.0552 - auc: 1.0000 - val_loss: 1.8699 - val_auc: 0.7371\n",
      "Epoch 907/1000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0601 - auc: 1.0000 - val_loss: 1.8685 - val_auc: 0.7149\n",
      "Epoch 908/1000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0551 - auc: 1.0000 - val_loss: 1.8695 - val_auc: 0.7172\n",
      "Epoch 909/1000\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.0600 - auc: 1.0000 - val_loss: 1.8915 - val_auc: 0.7174\n",
      "Epoch 910/1000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0620 - auc: 1.0000 - val_loss: 1.8380 - val_auc: 0.7195\n",
      "Epoch 911/1000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0778 - auc: 0.9999 - val_loss: 1.8006 - val_auc: 0.7308\n",
      "Epoch 912/1000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0531 - auc: 1.0000 - val_loss: 1.9173 - val_auc: 0.7469\n",
      "Epoch 913/1000\n",
      "6/6 [==============================] - 0s 82ms/step - loss: 0.0621 - auc: 1.0000 - val_loss: 1.7666 - val_auc: 0.7802\n",
      "Epoch 914/1000\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.0587 - auc: 1.0000 - val_loss: 1.6656 - val_auc: 0.7764\n",
      "Epoch 915/1000\n",
      "6/6 [==============================] - 0s 75ms/step - loss: 0.0540 - auc: 1.0000 - val_loss: 1.7613 - val_auc: 0.7592\n",
      "Epoch 916/1000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0624 - auc: 1.0000 - val_loss: 1.8870 - val_auc: 0.7408\n",
      "Epoch 917/1000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0714 - auc: 0.9999 - val_loss: 1.8994 - val_auc: 0.7421\n",
      "Epoch 918/1000\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 0.0633 - auc: 1.0000 - val_loss: 1.9087 - val_auc: 0.7473\n",
      "Epoch 919/1000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0546 - auc: 1.0000 - val_loss: 1.9262 - val_auc: 0.7495\n",
      "Epoch 920/1000\n",
      "6/6 [==============================] - 0s 72ms/step - loss: 0.0588 - auc: 1.0000 - val_loss: 1.8875 - val_auc: 0.7420\n",
      "Epoch 921/1000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0627 - auc: 1.0000 - val_loss: 1.8363 - val_auc: 0.7441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 922/1000\n",
      "6/6 [==============================] - 1s 91ms/step - loss: 0.0597 - auc: 1.0000 - val_loss: 1.7265 - val_auc: 0.7497\n",
      "Epoch 923/1000\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0584 - auc: 1.0000 - val_loss: 2.0661 - val_auc: 0.6742\n",
      "Epoch 924/1000\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0676 - auc: 1.0000 - val_loss: 2.1330 - val_auc: 0.6589\n",
      "Epoch 925/1000\n",
      "6/6 [==============================] - 0s 78ms/step - loss: 0.0784 - auc: 0.9999 - val_loss: 1.9935 - val_auc: 0.6948\n",
      "Epoch 926/1000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0631 - auc: 1.0000 - val_loss: 1.8776 - val_auc: 0.7367\n",
      "Epoch 927/1000\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0606 - auc: 1.0000 - val_loss: 1.8418 - val_auc: 0.7735\n",
      "Epoch 928/1000\n",
      "6/6 [==============================] - 0s 62ms/step - loss: 0.0573 - auc: 1.0000 - val_loss: 1.7483 - val_auc: 0.7592\n",
      "Epoch 929/1000\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0571 - auc: 1.0000 - val_loss: 1.8355 - val_auc: 0.7286\n",
      "Epoch 930/1000\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0592 - auc: 1.0000 - val_loss: 1.8440 - val_auc: 0.7289\n",
      "Epoch 931/1000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0507 - auc: 1.0000 - val_loss: 1.8197 - val_auc: 0.7295\n",
      "Epoch 932/1000\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0574 - auc: 1.0000 - val_loss: 1.7679 - val_auc: 0.7389\n",
      "Epoch 933/1000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0682 - auc: 0.9999 - val_loss: 1.6875 - val_auc: 0.7619\n",
      "Epoch 934/1000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0499 - auc: 1.0000 - val_loss: 1.7568 - val_auc: 0.7567\n",
      "Epoch 935/1000\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.0674 - auc: 1.0000 - val_loss: 1.7848 - val_auc: 0.7528\n",
      "Epoch 936/1000\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0543 - auc: 1.0000 - val_loss: 1.8044 - val_auc: 0.7479\n",
      "Epoch 937/1000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0668 - auc: 1.0000 - val_loss: 1.8220 - val_auc: 0.7372\n",
      "Epoch 938/1000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0631 - auc: 1.0000 - val_loss: 1.9187 - val_auc: 0.7157\n",
      "Epoch 939/1000\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.0637 - auc: 1.0000 - val_loss: 1.9626 - val_auc: 0.7137\n",
      "Epoch 940/1000\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.0680 - auc: 1.0000 - val_loss: 1.9647 - val_auc: 0.7186\n",
      "Epoch 941/1000\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.0633 - auc: 1.0000 - val_loss: 1.9710 - val_auc: 0.7232\n",
      "Epoch 942/1000\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 0.0611 - auc: 1.0000 - val_loss: 1.9438 - val_auc: 0.7253\n",
      "Epoch 943/1000\n",
      "6/6 [==============================] - 0s 76ms/step - loss: 0.0611 - auc: 1.0000 - val_loss: 1.8818 - val_auc: 0.7372\n",
      "Epoch 944/1000\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0548 - auc: 1.0000 - val_loss: 1.8348 - val_auc: 0.7477\n",
      "Epoch 945/1000\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0592 - auc: 1.0000 - val_loss: 1.8314 - val_auc: 0.7407\n",
      "Epoch 946/1000\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0520 - auc: 1.0000 - val_loss: 1.8190 - val_auc: 0.7445\n",
      "Epoch 947/1000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0536 - auc: 1.0000 - val_loss: 1.8105 - val_auc: 0.7601\n",
      "Epoch 948/1000\n",
      "6/6 [==============================] - 1s 94ms/step - loss: 0.0611 - auc: 1.0000 - val_loss: 1.8536 - val_auc: 0.7526\n",
      "Epoch 949/1000\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.0576 - auc: 1.0000 - val_loss: 1.8749 - val_auc: 0.7546\n",
      "Epoch 950/1000\n",
      "6/6 [==============================] - 0s 76ms/step - loss: 0.0618 - auc: 1.0000 - val_loss: 1.9459 - val_auc: 0.7459\n",
      "Epoch 951/1000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0667 - auc: 1.0000 - val_loss: 2.0370 - val_auc: 0.7537\n",
      "Epoch 952/1000\n",
      "6/6 [==============================] - 1s 110ms/step - loss: 0.0545 - auc: 1.0000 - val_loss: 2.3348 - val_auc: 0.6802\n",
      "Epoch 953/1000\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 0.0707 - auc: 0.9999 - val_loss: 2.2832 - val_auc: 0.7229\n",
      "Epoch 954/1000\n",
      "6/6 [==============================] - 1s 100ms/step - loss: 0.1078 - auc: 0.9945 - val_loss: 2.4881 - val_auc: 0.6842\n",
      "Epoch 955/1000\n",
      "6/6 [==============================] - 0s 62ms/step - loss: 0.1431 - auc: 0.9924 - val_loss: 2.6067 - val_auc: 0.6114\n",
      "Epoch 956/1000\n",
      "6/6 [==============================] - 1s 100ms/step - loss: 0.1110 - auc: 0.9996 - val_loss: 2.8835 - val_auc: 0.5983\n",
      "Epoch 957/1000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.1022 - auc: 0.9999 - val_loss: 2.6893 - val_auc: 0.6167\n",
      "Epoch 958/1000\n",
      "6/6 [==============================] - 1s 110ms/step - loss: 0.0823 - auc: 0.9999 - val_loss: 2.4528 - val_auc: 0.6716\n",
      "Epoch 959/1000\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.0682 - auc: 1.0000 - val_loss: 2.0879 - val_auc: 0.7223\n",
      "Epoch 960/1000\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 0.0572 - auc: 1.0000 - val_loss: 2.0212 - val_auc: 0.7563\n",
      "Epoch 961/1000\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0583 - auc: 1.0000 - val_loss: 1.9497 - val_auc: 0.7594\n",
      "Epoch 962/1000\n",
      "6/6 [==============================] - 0s 72ms/step - loss: 0.0569 - auc: 1.0000 - val_loss: 1.8383 - val_auc: 0.7652\n",
      "Epoch 963/1000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0540 - auc: 1.0000 - val_loss: 1.7502 - val_auc: 0.7724\n",
      "Epoch 964/1000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0589 - auc: 1.0000 - val_loss: 1.7363 - val_auc: 0.7757\n",
      "Epoch 965/1000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0520 - auc: 1.0000 - val_loss: 1.7080 - val_auc: 0.7880\n",
      "Epoch 966/1000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0636 - auc: 1.0000 - val_loss: 1.6996 - val_auc: 0.7760\n",
      "Epoch 967/1000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0668 - auc: 1.0000 - val_loss: 1.7147 - val_auc: 0.7757\n",
      "Epoch 968/1000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0549 - auc: 1.0000 - val_loss: 1.7260 - val_auc: 0.7617\n",
      "Epoch 969/1000\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 0.0552 - auc: 1.0000 - val_loss: 1.7503 - val_auc: 0.7470\n",
      "Epoch 970/1000\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0532 - auc: 1.0000 - val_loss: 1.7416 - val_auc: 0.7554\n",
      "Epoch 971/1000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0491 - auc: 1.0000 - val_loss: 1.8231 - val_auc: 0.7804\n",
      "Epoch 972/1000\n",
      "6/6 [==============================] - 0s 72ms/step - loss: 0.0559 - auc: 1.0000 - val_loss: 1.7845 - val_auc: 0.7839\n",
      "Epoch 973/1000\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0510 - auc: 1.0000 - val_loss: 1.6293 - val_auc: 0.7835\n",
      "Epoch 974/1000\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0489 - auc: 1.0000 - val_loss: 1.5954 - val_auc: 0.7653\n",
      "Epoch 975/1000\n",
      "6/6 [==============================] - 0s 62ms/step - loss: 0.0557 - auc: 1.0000 - val_loss: 1.6232 - val_auc: 0.7560\n",
      "Epoch 976/1000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0521 - auc: 1.0000 - val_loss: 1.6180 - val_auc: 0.7569\n",
      "Epoch 977/1000\n",
      "6/6 [==============================] - 0s 77ms/step - loss: 0.0749 - auc: 0.9999 - val_loss: 1.6382 - val_auc: 0.7706\n",
      "Epoch 978/1000\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0545 - auc: 1.0000 - val_loss: 1.6271 - val_auc: 0.7781\n",
      "Epoch 979/1000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0563 - auc: 1.0000 - val_loss: 1.7223 - val_auc: 0.7559\n",
      "Epoch 980/1000\n",
      "6/6 [==============================] - 0s 76ms/step - loss: 0.0524 - auc: 1.0000 - val_loss: 2.5312 - val_auc: 0.6097\n",
      "Epoch 981/1000\n",
      "6/6 [==============================] - 1s 172ms/step - loss: 0.0638 - auc: 1.0000 - val_loss: 2.2432 - val_auc: 0.6608\n",
      "Epoch 982/1000\n",
      "6/6 [==============================] - 1s 102ms/step - loss: 0.0505 - auc: 1.0000 - val_loss: 2.0492 - val_auc: 0.6975\n",
      "Epoch 983/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 79ms/step - loss: 0.0594 - auc: 1.0000 - val_loss: 2.0268 - val_auc: 0.7128\n",
      "Epoch 984/1000\n",
      "6/6 [==============================] - 0s 62ms/step - loss: 0.0666 - auc: 0.9999 - val_loss: 2.1282 - val_auc: 0.7190\n",
      "Epoch 985/1000\n",
      "6/6 [==============================] - 1s 92ms/step - loss: 0.0677 - auc: 0.9999 - val_loss: 2.0879 - val_auc: 0.7324\n",
      "Epoch 986/1000\n",
      "6/6 [==============================] - 1s 124ms/step - loss: 0.0620 - auc: 1.0000 - val_loss: 1.8239 - val_auc: 0.7657\n",
      "Epoch 987/1000\n",
      "6/6 [==============================] - 1s 110ms/step - loss: 0.0528 - auc: 1.0000 - val_loss: 1.7464 - val_auc: 0.7759\n",
      "Epoch 988/1000\n",
      "6/6 [==============================] - 0s 77ms/step - loss: 0.0572 - auc: 1.0000 - val_loss: 1.7917 - val_auc: 0.7806\n",
      "Epoch 989/1000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0508 - auc: 1.0000 - val_loss: 1.7025 - val_auc: 0.7746\n",
      "Epoch 990/1000\n",
      "6/6 [==============================] - 0s 77ms/step - loss: 0.0488 - auc: 1.0000 - val_loss: 1.6596 - val_auc: 0.7826\n",
      "Epoch 991/1000\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0512 - auc: 1.0000 - val_loss: 1.6592 - val_auc: 0.7811\n",
      "Epoch 992/1000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0510 - auc: 1.0000 - val_loss: 1.6587 - val_auc: 0.7725\n",
      "Epoch 993/1000\n",
      "6/6 [==============================] - 0s 80ms/step - loss: 0.0511 - auc: 1.0000 - val_loss: 1.6786 - val_auc: 0.7596\n",
      "Epoch 994/1000\n",
      "6/6 [==============================] - 1s 133ms/step - loss: 0.0505 - auc: 1.0000 - val_loss: 1.7153 - val_auc: 0.7580\n",
      "Epoch 995/1000\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0570 - auc: 1.000 - 0s 65ms/step - loss: 0.0570 - auc: 1.0000 - val_loss: 1.7482 - val_auc: 0.7595\n",
      "Epoch 996/1000\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.0484 - auc: 1.0000 - val_loss: 1.7478 - val_auc: 0.7616\n",
      "Epoch 997/1000\n",
      "6/6 [==============================] - 0s 70ms/step - loss: 0.0800 - auc: 0.9999 - val_loss: 1.7412 - val_auc: 0.7713\n",
      "Epoch 998/1000\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0474 - auc: 1.0000 - val_loss: 1.7320 - val_auc: 0.7771\n",
      "Epoch 999/1000\n",
      "6/6 [==============================] - 0s 81ms/step - loss: 0.0505 - auc: 1.0000 - val_loss: 1.7265 - val_auc: 0.7797\n",
      "Epoch 1000/1000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0498 - auc: 1.0000 - val_loss: 1.7324 - val_auc: 0.7948\n"
     ]
    }
   ],
   "source": [
    "# as dataset is very samll tried for more epochs.\n",
    "model.train(xtr_transformed, ytr_encoded,\n",
    "           0.2, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           buyer       0.84      0.95      0.89        62\n",
      "buyer and seller       0.92      0.92      0.92        12\n",
      "         neutral       0.88      0.86      0.87        43\n",
      "          seller       1.00      0.92      0.96        86\n",
      "\n",
      "        accuracy                           0.92       203\n",
      "       macro avg       0.91      0.91      0.91       203\n",
      "    weighted avg       0.92      0.92      0.92       203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report.\n",
    "# seems good on training data small amount of data.\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "prediction= y_encoder.inverse_transform(model.predict(xtr_transformed))\n",
    "print(classification_report(data1.intent, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving model\n",
    "from keras.models import load_model\n",
    "model = load_model('my_model.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           buyer       0.29      0.57      0.38         7\n",
      "buyer and seller       1.00      1.00      1.00         4\n",
      "         neutral       0.40      0.25      0.31         8\n",
      "          seller       0.83      0.50      0.62        10\n",
      "\n",
      "        accuracy                           0.52        29\n",
      "       macro avg       0.63      0.58      0.58        29\n",
      "    weighted avg       0.60      0.52      0.53        29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model predicting well on training data\n",
    "#and average on test data\n",
    "#The reason is that the model is not as generalized.\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "prediction= y_encoder.inverse_transform(model.predict(xts_transformed))\n",
    "print(classification_report(test_data.intent, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5172413793103449"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_data.intent, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
